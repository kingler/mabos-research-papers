MultiTool-CoT: GPT-3 Can Use Multiple External Tools with Chain of
Thought Prompting
Tatsuro Inaba1Hirokazu Kiyomaru1Fei Cheng1Sadao Kurohashi1,2
1Kyoto University, Japan
2National Institute of Informatics, Japan
{inaba, kiyomaru, feicheng, kuro}@nlp.ist.i.kyoto-u.ac.jp
Abstract
Large language models (LLMs) have achieved
impressive performance on various reasoning
tasks. To further improve the performance,
we propose MultiTool-CoT, a novel frame-
work that leverages chain-of-thought (CoT)
prompting to incorporate multiple external
tools, such as a calculator and a knowledge
retriever, during the reasoning process. We
apply MultiTool-CoT to the Task 2 dataset
of NumGLUE, which requires both numeri-
cal reasoning and domain-specific knowledge.
The experiments show that our method sig-
nificantly outperforms strong baselines and
achieves state-of-the-art performance.1
1 Introduction
Reasoning refers to the logical process of infer-
ring unknown facts from known facts. Solving
reasoning problems requires language understand-
ing, real-world knowledge, arithmetic calculation,
and symbolic processing. Improving the reason-
ing capability of artificial intelligence has been a
long-standing challenge and remains an active re-
search topic to this day (Gordon et al., 2012; Sap
et al., 2020).
Recently, large language models (LLMs) have
achieved amazing performance on various reason-
ing tasks (Brown et al., 2020; Lewkowycz et al.,
2022; Zhang et al., 2022; Chowdhery et al., 2022).
However, the amount of real-world knowledge
learned by LLMs is still constrained by the size
of model parameters and the training data. This
problem could be more severe in the case of sparse
domain-specific knowledge. Furthermore, LLMs
are based on the computation among continuous
token representations, which cannot ensure accu-
rate arithmetic calculations.
To solve these problems, previous studies pro-
pose to complement the capabilities of LLMs with
1Our code is publicly available at https://github.com/
InabaTatsuro/MultiTool-CoT .an external tool, such as a web browser or a cal-
culator (Nakano et al., 2021; Cobbe et al., 2021;
Yao et al., 2022). This is performed by invok-
ing an external tool during reasoning with LLMs
and injecting the results into the reasoning pro-
cess. However, previous studies have focused on
using a single external tool to solve a single prob-
lem with LLMs and have not addressed different
problems together.
This paper proposes MultiTool-CoT, an inter-
active framework that allows LLMs to use multi-
ple external tools during reasoning. Figure 1 pro-
vides an overview. In MultiTool-CoT, LLMs solve
reasoning problems by generating reasoning pro-
cesses including tool triggers to invoke external
tools. We let LLMs learn to invoke multiple ex-
ternal tools at proper reasoning steps by chain-of-
thought (CoT) prompting based on few-shot learn-
ing (Wei et al., 2022).
As a proof of concept, we apply MultiTool-
CoT to the Task 2 dataset of NumGLUE (Mishra
et al., 2022), which requires both numerical rea-
soning and domain-specific knowledge. Experi-
ments show that MultiTool-CoT significantly out-
performs strong baselines and achieves state-of-
the-art performance.
2 Related Work
Large language models (LLMs) can perform vari-
ous tasks by prompting (Liu et al., 2022). As for
reasoning tasks, chain-of-thought (CoT) prompt-
ing (Wei et al., 2022; Kojima et al., 2022) is known
for its effectiveness, which elicits the answer with
intermediate reasoning steps from LLMs.
There is a growing body of work on using an
external tool to improve reasoning with LLMs.
Cobbe et al. (2021) use a calculator to process
mathematical formulas that appear in reasoning
processes by fine-tuning LLMs to generate mathe-
matical formulas with a tool trigger to call the cal-
culator. Nakano et al. (2021) allow LLMs to use aarXiv:2305.16896v1  [cs.CL]  26 May 2023
A: First, use the chemical reaction predictor to determine the chemical equation for the reaction.Reactants: ?Ca(OH)2, 2CO2Products: 2CaCO3, 2H2O<< Chemical reaction predictor >>2Ca(OH)2 + 2CO2 → 2CaCO3 + 2H2OSecond, use the molar mass list to determine the molar mass of Calcium hydroxide.Ca(OH)2 << Molar mass list >>74 g/molThird, use the calculator to calculate the amount of 2 moles of Calcium hydroxide.2 x 74 = << Calculator >>148Therefore, 148 g of Calcium hydroxide is required.Model OutputUse the following tools at your disposal and answer some questions:・<< Calculator >>・<< Chemical reaction predictor >>・<< Molar mass list >>Instruction
Q: Find the amount of H2CO3 formed on combining 2 moles of CO2 and 2 moles of H2O. A: First, use the chemical reaction predictor to determine the chemical equation for the reaction.Reactants: 2CO2, 2H2OProducts: ?H2CO3<< Chemical reaction predictor >>2CO2 + 2H2O → 2H2CO3Second, use the molar mass list to determine the molar mass of H2CO3.H2CO3 << Molar mass list >> 62 g/molThird, use the calculator to calculate the amount of 2 moles of H2CO3.2 x 62 = << Calculator >> 124Therefore, 124 g of H2CO3 is formed. Q: …A: …Few-Shot Examples
Other Few-Shot examplesQ: Find the amount of Calcium hydroxide that is required to react with 2 moles of Carbon dioxide to form 2 moles of Calcium carbonate along with 2 moles of Water.QuestionExternal ToolsCalculatorChemical reaction predictorMolar mass listGPT-3Figure 1: Overview of the MultiTool-CoT. The output of GPT-3, the calculator, the chemical reaction predictor,
and the molar mass list are highlighted in green, yellow, orange, and purple, respectively.
web browser by fine-tuning LLMs to generate ac-
tion codes to operate the browser. Previous studies
focus on a single problem of LLMs, namely, error-
prone arithmetic calculation or incomplete real-
world knowledge, and address it by fine-tuning
LLMs so that they can call a single external tool.
In contrast, this study addresses multiple problems
together by allowing LLMs to use multiple exter-
nal tools. Besides, this study presents a few-shot
learning-based framework (Brown et al., 2020) for
doing this, which does not require fine-tuning.
A very recent study (Yao et al., 2022) proposes
a few-shot learning-based method for invoking a
Wikipedia API to perform knowledge-intensive
reasoning tasks. However, this study has not inves-
tigated the effectiveness of using multiple external
tools. A Python library named LangChain2im-
plements a framework for allowing LLMs to use
multiple external tools based on Yao et al. (2022),
which is similar to ours. However, its effective-
ness has not been investigated in any benchmark
datasets as of this submission.
3 Method
We propose MultiTool-CoT, an interactive frame-
work that allows LLMs to use multiple external
2https://langchain.readthedocs.io/en/latesttools during reasoning. Figure 1 illustrates an
overview.
MultiTool-CoT leverages chain-of-thought
(CoT) prompting based on few-shot learning (Wei
et al., 2022). Our prompt consists of an instruction
specifying the available external tools, few-shot
examples demonstrating several question-answer
pairs with reasoning processes, and a question to
be solved. We manually annotate the reasoning
processes shown as few-shot examples with tool
triggers marked with corresponding input data,
adhering to a specific format. In this study, we let
the string <<External tool name >>be a tool
trigger. For example, if we use a calculator as an
external tool, we annotate the reasoning processes
with the tool trigger <<Calculator >> after
input formulas like 2×62.
When reasoning, GPT-3 follows the prompt and
generates a reasoning process including tool trig-
gers. If a tool trigger is generated, we stop text
generation. We then extract the name of the exter-
nal tool and the input for the tool from the reason-
ing process, execute the tool with the input, and
append the result to the end of the reasoning pro-
cess. After that, we restart text generation.
If we cannot execute an external tool for some
reason (e.g., invalid tool input is generated), we
fall back on GPT-3 and let it generate the output
of the tool.
We observe that the final answer value is nearly
always contained in the last sentence of the rea-
soning process. Therefore, we apply an additional
GPT-3 few-shot learning process for mapping the
last sentence to the answer value by prompting
several sentence-answer pairs.
4 Experiment
As a proof of concept, we applied MultiTool-CoT
to solve a knowledge-based numerical reasoning
task.
4.1 Dataset
We used the Task 2 dataset of NumGLUE (Mishra
et al., 2022), which requires both numerical rea-
soning and domain-specific knowledge, mainly re-
lated to chemistry. Example (1) shows a question
in the dataset.
(1) Find the amount of Calcium hydroxide re-
quired to react with 2 moles of Carbon
dioxide to form 2 moles of Calcium car-
bonate along with 2 moles of Water.
All the answers are given as numbers. We used
325 questions in the test split for evaluation. We
evaluated the accuracy.
4.2 External Tools
We implemented the following external tools and
used them in the proposed framework.
•Calculator (C AL): The calculator is given a
mathematical formula and outputs the calcu-
lation result. The calculator is implemented
using Python’s eval function3. Operators in
mathematical formulas are replaced accord-
ing to Python’s syntax. We prompt GPT-3 to
output the tool trigger, <<Calculator >>,
with a mathematical formula on the same
line.
•Chemical reaction predictor (C RP): The
chemical reaction predictor is given the
chemical formula of reactants and products
and outputs the chemical reaction equation
by adjusting the coefficients so that the re-
actants and products have the same number
of each atom. We prompt GPT-3 to out-
put the tool trigger, <<Chemical reaction
3https://docs.python.org/3/library/functions.
html#evalMethod
Zero-Shot†1
Zero-Shot+CoT 32.62
Few-Shot†42
Few-Shot+CoT 57.85
MultiTool-CoT (C ALonly) 62.77
MultiTool-CoT (C RPonly) 64.31
MultiTool-CoT (M MLonly) 69.23
MultiTool-CoT ( Ours ) 85.85
Table 1: Performance in the Task 2 dataset of
NumGLUE. The best result is shown in bold . (†) is
cited from Mishra et al. (2022).
predictor >>, with the reactants and prod-
ucts on the previous two lines.
•Molar mass list (M ML): The molar mass list
is given a chemical formula and outputs its
molar mass. The molar mass of the chemi-
cal formula is calculated from the atoms and
their number in the formula. The molar mass
of the atoms is obtained from the knowl-
edge base listing the weight of all atoms.
We prompt GPT-3 to output the tool trigger,
<<Molar mass list >>, with a chemical
formula on the same line.
4.3 Methods for Comparison
We used GPT-3 ( text-davinci-003 ; 175B pa-
rameters) via OpenAI API4and compared the fol-
lowing methods.
Zero-Shot We fed only the question into GPT-3
and considered the generated text as the answer.
Zero-Shot+CoT (Kojima et al., 2022) We fed
the question with the sentence “Let’s think step by
step.” into GPT-3 and obtained the answer with the
intermediate reasoning steps. We then added the
sentence fragment “Therefore, the answer (Arabic
numerals) is ” after the generated text and fed it
into GPT-3 to get the final answer.
Few-Shot We fed the question with few-shot ex-
amples of question-answer pairs into GPT-3 and
obtained the generated text as the answer.
Few-Shot+CoT We performed the proposed
method without invoking any external tools. If
the tool triggers were generated, we used GPT-3
to output the result.
4https://openai.com/api/
Figure 2: An improved example. The green lines indicate correct reasoning processes. The red lines indicate errors
related to knowledge or arithmetic calculation.
MultiTool-CoT ( {CAL|CRP|MML}only) We
performed the proposed method with one of the
external tools introduced in Section 4.2. As for
the other external tools, we let GPT-3 generate the
result.
MultiTool-CoT (Ours) We performed the pro-
posed method with all the external tools intro-
duced in Section 4.2.
In few-shot settings, we used 20 questions in the
training split as few-shot examples. The questions
were manually selected to avoid bias in the num-
ber of external tool calls. In order to annotate the
questions with reasoning processes with tool trig-
gers, we followed a two-step process. First, we
employed GPT-3 to generate the reasoning pro-
cesses for solving these questions using zero-shot
chain-of-thought prompting (Kojima et al., 2022),
aiming to obtain reasoning processes that GPT-3
can easily follow. Then, we manually annotated
the reasoning processes with tool triggers and the
input and output for the corresponding external
tools.
We set the temperature parameter of GPT-3 as
0 to generate constant predictions. Therefore, we
report the results of single runs of the methods.
4.4 Results
Table 1 shows the results. The proposed method
achieved an accuracy of 85.85, a state-of-the-art
performance. We observed a significant perfor-mance improvement compared to methods that did
not use external tools and methods that used only
one external tool. Note that the performance im-
provement from using multiple external tools is
larger than the sum of the performance improve-
ments from using each tool individually. This is
because GPT-3 can fail to provide accurate an-
swers due to a combination of different types of
errors, such as incorrect arithmetic calculation and
knowledge. The use of multiple external tools ad-
dressed such cases effectively, thereby improving
the overall accuracy.
4.5 Case Study
Figure 2 shows an improved example. Zero-
Shot and Few-Shot generated wrong answers.
Zero-Shot+CoT and Few-Shot+CoT performed
reasoning based on the incorrect molar mass of
Al2(CO3)3, resulting in incorrect answers. Be-
sides, Few-Shot+CoT failed to calculate 12×
3/342×100. Our method, MultiTool-CoT, was
able to answer correctly based on correct knowl-
edge and calculation, relying on external tools.
More examples are presented in Figure 3 and Fig-
ure 4 in Appendix.
Despite the excellent results, there were 46 in-
stances in which the proposed method failed to de-
liver accurate answers. Upon manual investiga-
tion of all the errors, we identified that the ma-
jority of them were caused by incorrect reason-
ing processes (39%) and invalid tool inputs (35%).
The remaining errors were categorized into incor-
rect gold answers (15%) and variations in answer
formats (11%). Examples can be found in Ap-
pendix B. These errors are beyond the scope of
what external tools can assist with.
5 Conclusion
We proposed MultiTool-CoT, a framework that al-
lows LLMs to use multiple external tools, such as
a knowledge retriever and a calculator, during rea-
soning. We applied MultiTool-CoT to a numerical
reasoning task that requires knowledge of chem-
istry and confirmed its effectiveness. The pro-
posed framework is general and can be applied to
various tasks by changing and extending external
tools. We plan to verify the effectiveness of the
proposed method in other tasks in the future.
Limitations
The major limitation of the present study is that
the effectiveness of the proposed method has been
confirmed only for a single task. This is because
most existing reasoning tasks are relatively simple
that they can be solved by a single external tool at
most. For example, most existing numerical rea-
soning tasks provide self-contained questions; that
is, all the required knowledge is included in the
questions. In such tasks, a calculator is all that is
needed as an external tool. However, it would be
rare for a single external tool to be sufficient in
real-world applications such as medical text anal-
ysis. It is crucial for future work to validate the
effectiveness in such realistic scenarios that neces-
sitate the use of multiple external tools.
References
Tom Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared D Kaplan, Prafulla Dhariwal,
Arvind Neelakantan, Pranav Shyam, Girish Sastry,
Amanda Askell, Sandhini Agarwal, Ariel Herbert-
V oss, Gretchen Krueger, Tom Henighan, Rewon
Child, Aditya Ramesh, Daniel Ziegler, Jeffrey
Wu, Clemens Winter, Chris Hesse, Mark Chen,
Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin
Chess, Jack Clark, Christopher Berner, Sam Mc-
Candlish, Alec Radford, Ilya Sutskever, and Dario
Amodei. 2020. Language models are few-shot
learners. In Advances in Neural Information Pro-
cessing Systems , volume 33, pages 1877–1901. Cur-
ran Associates, Inc.
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,Paul Barham, Hyung Won Chung, Charles Sutton,
Sebastian Gehrmann, Parker Schuh, Kensen Shi,
Sasha Tsvyashchenko, Joshua Maynez, Abhishek
Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-
odkumar Prabhakaran, Emily Reif, Nan Du, Ben
Hutchinson, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng
Yin, Toju Duke, Anselm Levskaya, Sanjay Ghe-
mawat, Sunipa Dev, Henryk Michalewski, Xavier
Garcia, Vedant Misra, Kevin Robinson, Liam Fedus,
Denny Zhou, Daphne Ippolito, David Luan, Hyeon-
taek Lim, Barret Zoph, Alexander Spiridonov, Ryan
Sepassi, David Dohan, Shivani Agrawal, Mark
Omernick, Andrew M. Dai, Thanumalayan Sankara-
narayana Pillai, Marie Pellat, Aitor Lewkowycz,
Erica Moreira, Rewon Child, Oleksandr Polozov,
Katherine Lee, Zongwei Zhou, Xuezhi Wang, Bren-
nan Saeta, Mark Diaz, Orhan Firat, Michele Catasta,
Jason Wei, Kathy Meier-Hellstern, Douglas Eck,
Jeff Dean, Slav Petrov, and Noah Fiedel. 2022.
PaLM: Scaling Language Modeling with Pathways.
arXiv preprint arXiv:2204.02311 .
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias
Plappert, Jerry Tworek, Jacob Hilton, Reiichiro
Nakano, Christopher Hesse, and John Schulman.
2021. Training verifiers to solve math word prob-
lems. arXiv preprint arXiv:2110.14168 .
Andrew Gordon, Zornitsa Kozareva, and Melissa
Roemmele. 2012. SemEval-2012 task 7: Choice
of plausible alternatives: An evaluation of common-
sense causal reasoning. In *SEM 2012: The First
Joint Conference on Lexical and Computational Se-
mantics – Volume 1: Proceedings of the main con-
ference and the shared task, and Volume 2: Pro-
ceedings of the Sixth International Workshop on Se-
mantic Evaluation (SemEval 2012) , pages 394–398,
Montréal, Canada. Association for Computational
Linguistics.
Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid,
Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large
language models are zero-shot reasoners. In Ad-
vances in Neural Information Processing Systems ,
volume 35, pages 22199–22213. Curran Associates,
Inc.
Aitor Lewkowycz, Anders Johan Andreassen,
David Dohan, Ethan Dyer, Henryk Michalewski,
Vinay Venkatesh Ramasesh, Ambrose Slone, Cem
Anil, Imanol Schlag, Theo Gutman-Solo, Yuhuai
Wu, Behnam Neyshabur, Guy Gur-Ari, and Vedant
Misra. 2022. Solving quantitative reasoning prob-
lems with language models. In Advances in Neural
Information Processing Systems , volume 35, pages
3843–3857. Curran Associates, Inc.
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang,
Hiroaki Hayashi, and Graham Neubig. 2022. Pre-
train, prompt, and predict: A systematic survey of
prompting methods in natural language processing.
ACM Computing Surveys , 55(9).
Swaroop Mishra, Arindam Mitra, Neeraj Varshney,
Bhavdeep Sachdeva, Peter Clark, Chitta Baral, and
Ashwin Kalyan. 2022. NumGLUE: A suite of fun-
damental yet challenging mathematical reasoning
tasks. In Proceedings of the 60th Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 1: Long Papers) , pages 3505–3523, Dublin,
Ireland. Association for Computational Linguistics.
Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff
Wu, Long Ouyang, Christina Kim, Christopher
Hesse, Shantanu Jain, Vineet Kosaraju, William
Saunders, Xu Jiang, Karl Cobbe, Tyna Eloundou,
Gretchen Krueger, Kevin Button, Matthew Knight,
Benjamin Chess, and John Schulman. 2021. We-
bgpt: Browser-assisted question-answering with hu-
man feedback. arXiv preprint arXiv:2112.09332 .
Maarten Sap, Vered Shwartz, Antoine Bosselut, Yejin
Choi, and Dan Roth. 2020. Commonsense reason-
ing for natural language processing. In Proceed-
ings of the 58th Annual Meeting of the Association
for Computational Linguistics: Tutorial Abstracts ,
pages 27–33, Online. Association for Computational
Linguistics.
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, brian ichter, Fei Xia, Ed Chi, Quoc V Le,
and Denny Zhou. 2022. Chain-of-thought prompt-
ing elicits reasoning in large language models. In
Advances in Neural Information Processing Sys-
tems, volume 35, pages 24824–24837. Curran As-
sociates, Inc.
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran, Karthik Narasimhan, and Yuan Cao. 2022.
React: Synergizing reasoning and acting in language
models. arXiv preprint arXiv:2210.03629 .
Susan Zhang, Stephen Roller, Naman Goyal, Mikel
Artetxe, Moya Chen, Shuohui Chen, Christopher
Dewan, Mona Diab, Xian Li, Xi Victoria Lin, Todor
Mihaylov, Myle Ott, Sam Shleifer, Kurt Shuster,
Daniel Simig, Punit Singh Koura, Anjali Sridhar,
Tianlu Wang, and Luke Zettlemoyer. 2022. OPT:
Open Pre-trained Transformer Language Models.
arXiv preprint arXiv:2205.01068 .
Few-Shot Examples Acc.
CoT 5 55.38
CoT 10 56.31
CoT 20 57.85
MultiTool-CoT 5 83.69
MultiTool-CoT 10 84.00
MultiTool-CoT 20 85.85
Table 2: Performance for the different number of few-
shot examples in the Task 2 dataset of NumGLUE. The
best result is shown in bold .
A Effect of the Number of Few-shot
Examples on Performance
We investigated the effect of the number of few-
shot examples on performance. Table 2 shows the
results. Reducing the number of few-shot exam-
ples decreased accuracy, regardless of whether ex-
ternal tools were used. Surprisingly, however, the
drop in performance was not drastic, suggesting
the strong generalization ability of GPT-3. Note
that it is hopeless to further improve the perfor-
mance by simply increasing the number of few-
shot examples because the total number of tokens
in the 20 few-shot examples is nearly 3,000 while
the number of tokens that GPT-3 can process is
4,000.
B Analysis of Error Types
We manually investigated all 46 errors as de-
scribed in Section 4.5. There were four types of er-
rors: incorrect reasoning processes (39%), invalid
tool inputs (35%), incorrect gold answers (15%),
and variations in answer formats (11%).
Incorrect Reasoning Processes Figure 5 shows
an error due to an incorrect reasoning process.
GPT-3 generated an incorrect mathematical for-
mula (underlined in red), which was expected to
be3×16/160×100. Consequently, even though
the calculation was performed correctly using the
calculator, the final answer turned out to be incor-
rect.
Invalid Tool Inputs Figure 6 shows an error
caused by an invalid tool input. GPT-3 generated
an invalid product, CH2Cl2 (underlined in red),
which was expected to be CCl4. Thus, the chem-
ical reaction predictor encountered a run-time er-
ror, resulting in an incorrect final answer.Incorrect Gold Answers Figure 7 shows an er-
ror resulting from an incorrect gold answer. The
answer predicted by the proposed method was “85
g/mol,” whereas the gold answer was “90 g/mol.”
Variations in Answer Formats Figure 8 shows
an error attributed to a variation in the answer
format. The answer predicted by the proposed
method was “1 mole,” while the gold answer was
“18 g”. Since 1 mole of water is 18g, they both
represent the same quantity. However, due to the
difference in the answer formats, it is considered
an error.
Figure 3: An improved example. The red line indicates an error in chemical reaction understanding. The green
line indicates the correct reasoning process by using the chemical reaction predictor as an external tool.
Figure 4: An improved example. The red line indicates errors in arithmetic calculation. The green line indicates
the correct reasoning process by using the calculator as an external tool.
Figure 5: An example of incorrect reasoning processes.
Figure 6: An example of the invalid tool inputs.
Figure 7: An example of incorrect gold answers.
Figure 8: An example of variations in answer formats
