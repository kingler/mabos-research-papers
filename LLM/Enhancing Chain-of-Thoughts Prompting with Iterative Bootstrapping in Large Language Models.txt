Enhancing Chain-of-Thoughts Prompting with Iterative Bootstrapping in
Large Language Models
Jiashuo Sun*
Xiamen UniversityYi Luo*
Xiamen UniversityYeyun Gong
Microsoft Research Asia
Chen Lin†
Xiamen UniversityYelong Shen
MicrosoftJian Guo
IDEA ResearchNan Duan
Microsoft Research Asia
Abstract
Large language models (LLMs) can achieve
impressive performance on various reasoning
tasks by incorporating chain-of-thought (CoT)
prompting, where step-by-step reasoning is pro-
vided to guide LLMs to generate answers to
questions, and the question-rationale-answer
triplets are utilized as demonstration exemplars.
However, the reasoning chains of demonstra-
tions generated by LLMs are observed to be
prone to errors, which can subsequently lead
to incorrect reasoning during inference. Fur-
thermore, inappropriate exemplars, e.g., overly
simplistic or complex exemplars depending on
the question’s difficulty level, can affect the
LLM’s performance. To address these issues,
we introduce Iter-CoT ( Iterative bootst rapping
inChain- of-Thoughts prompting). Iter-CoT
has two advantages: (1) it adopts iterative boot-
strapping that enables LLMs to rectify errors
autonomously, resulting in more precise and
comprehensive reasoning chains. (2) it se-
lects exemplars of challenging yet answerable
(i.e., the LLM has the potential to answer cor-
rectly) questions, enhancing the LLMs’ gen-
eralizability to answer questions with varying
difficulty levels. Experimental results exhibit
Iter-CoT superior performance on three dis-
tinct reasoning tasks on ten datasets. Our code
is publicly available at https://github.com/
GasolSun36/Iter-CoT .
1 Introduction
Chain-of-Thought (CoT) (Wei et al., 2022) prompt-
ing is a technique to enhance the reasoning abilities
of Large language models (LLMs) by generating
a series of reasoning steps to obtain the answer,
and the reasoning chains are utilized as exemplars
to demonstrate the task and provide In-Context
Learning (ICL) (Brown et al., 2020) to LLMs. Re-
cently, LLMs (Chowdhery et al., 2022; Thoppilan
*Equal contribution.
†Corresponding author, chenlin@xmu.edu.cn
Figure 1: Effect of different demonstrations (Simple-
CoT v.s., Complex-CoT) on different questions (diffi-
culty from 2-hop to 9-hop) on GSM8K dataset.
12.5% 25.0% 37.5% 50.0% 62.5% 75.0% 87.5%
Percentage of Wrong Exemplars65.566.066.567.067.568.0Accuracy(%)
75.075.576.076.577.077.5
50.052.555.057.560.062.565.067.5
GSM8K
CSQA
Letter
Figure 2: Impact of wrong exemplars on three different
benchmarks (GSM8K, CSQA and Letter).
et al., 2022; Rae et al., 2021; Smith et al., 2022;
Scao et al., 2022) with CoT prompting have demon-
strated remarkable performance in complex reason-
ing tasks, including arithmetic (Cobbe et al., 2021;
Ling et al., 2017; Hosseini et al., 2014; Koncel-
Kedziorski et al., 2015; Patel et al., 2021; Miao
et al., 2020), commonsense (Talmor et al., 2019;
Geva et al., 2021; Kojima et al., 2022; Wei et al.,
2022), and symbolic reasoning (Wei et al., 2022).
Existing studies on CoT prompting can be clas-
sified into two categories. The first category is
manually constructed CoT prompting((Wei et al.,arXiv:2304.11657v3  [cs.CL]  15 Mar 2024
2022; Diao et al., 2023; Fu et al., 2022; Wang et al.,
2022; Li et al., 2022; Zhou et al., 2022; Press et al.,
2023)), where human annotators manually craft a
collection of question-rationale-answer exemplars
to guide the model’s reasoning process. However,
human annotations’ inherent subjectivity and limi-
tations make these approaches costly, sub-optimal,
and highly inconsistent. The second category is
automatically generated CoT prompting((Kojima
et al., 2022; Zhang et al., 2022; Shum et al., 2023;
Shao et al., 2023)), where LLM-generated CoT is
utilized. In practice, reasoning chains generated
by LLMs have demonstrated superior performance
compared with human annotations.
However, three issues remain under-explored in
the literature. (1) Difficulty of questions . It is re-
garded that questions of mediate difficulty level can
best guide the LLMs (Diao et al., 2023). As shown
in Figure 1, it is observed that simplistic examples
(Simple-CoT) perform poorly in solving complex
questions of more hops1, while excessively com-
plex exemplars (Complex-CoT (Fu et al., 2022))
are unsatisfying on simpler questions. (2) Cor-
rectness of demonstration . Reasoning chains of
demonstrations generated by LLMs are prone to
errors (Zhang et al., 2022; Diao et al., 2023), which
can significantly reduce overall performance. As
shown in Figure 2, accuracy on various datasets
decreases as incorrect exemplars increase. (3)
Missing contextual information . Previous works
merely combine the question and the "let’s think
step by step" prompt (Kojima et al., 2022) during
the generation of demonstrations without incorpo-
rating contextual information (such as incorrect
reasoning chains and feedback answers generated
by LLMs). Missing contextual information limits
the LLM’s capability to learn from previous rea-
soning errors and avoid making similar errors.
In order to address the issues above, we pro-
pose Iter-CoT ( Iterative bootst rapping in Chain-
of-Thoughts Prompting). Iter-CoT allows LLMs
to self-correct and summarize the more precise
and comprehensive reasoning chains, which iden-
tify challenging yet answerable (i.e., LLM has the
potential to answer correctly) questions as demon-
strations in order to enhance the LLMs’ generaliz-
ability to answer questions with varying difficulty
levels. We evaluate Iter-CoT on three distinct rea-
1Following (Shum et al., 2023; Fu et al., 2022), we measure
the question’s difficulty by the number of hops in the rationale,
with fewer hops indicating simpler questions and more hops
indicating more complex questions.soning tasks (arithmetic, commonsense, and sym-
bolic) across ten datasets. The experimental results
show that Iter-CoT significantly outperforms exist-
ing prompting approaches.
Our contributions are summarized as follows: (1)
We propose a new paradigm for CoT, which gener-
ates precise and comprehensive reasoning chains
during interaction with LLMs. To our knowledge,
our work is the first to illustrate the importance
of iterative interaction with the LLMs to generate
high-quality demonstrations. (2) We propose Iter-
CoT, an approach that generates self-corrected and
summarized reasoning chains on exemplars with
intermediate difficulty levels, which are utilized
as demonstrations to enhance the LLMs’ perfor-
mance. (3) We implement Iter-CoT under both
labeled and unlabeled conditions, achieving state-
of-the-art (SOTA) results in both scenarios across
ten datasets within three distinct tasks.
2 Motivation
We propose Iter-CoT, which enhances LLMs’ rea-
soning performance by integrating iterative boot-
strapping to self-correct the reasoning chains in
demonstrations.
2.1 The Self-Correction Ability of LLMs
LLMs have the potential to self-correct. Wang et al.
(2022) demonstrated the ability of LLMs to gen-
erate multiple diverse answers for the same ques-
tion. We conduct an empirical experiment on the
GSM8K dataset to show that LLMs have the poten-
tial to generate the correct reasoning chain for ques-
tions that are initially answered erroneously. The
GSM8K dataset contains groundtruth answers for
7473 questions in training set. For each question
0 1 2 3 4 5 6
Number of Iterations01000200030004000500060007000
40894898530655145623 5692 5726
012345
Ratio of Correct and Incorrect Samples
Number of Correct Samples
Figure 3: Effect of re-answering the question based on
the hint and previous rationales.
Q: This is the last day of 1899. 
What is the date one year ago from 
today in MM/DD/YYYY? 
A: Let's think step by step, 1. One 
year ago …Based on these steps, 
the correct answer is 12/25/1898.
Hint: the answer is wrong.
A: 1. We know that this is the last day 
of 1899 … Therefore, the answer is 
12/31/1898. Q: Jane is celebrating the last day of Jan 2012. What is 
the date tomorrow in MM/DD/YYYY? 
A: Today is the last day 
of ...so the answer is 
02/01/2012.Q: Yesterday was April 30, 2021. What 
is the date today in MM/DD/YYYY? 
A: Let's think step by step, April 
30th is the last day of April… so the 
correct answer is 05/01/2021.
A: Let's think step by step,
... is 02/02/2012.Zero-shot-CoT Zero-shot-CoT
Demonstration
Re-answer
Correctable Question Test Question Randomly Sampled Question
Large Language ModelsFigure 4: The illustration of the value of revised examples. Challenging yet answerable exemplars as demonstrations
can enhance the model’s reasoning performance.
in training set, we first apply the zero-shot-CoT to
generate answers. For questions that are answered
incorrectly, we prompt the LLM with a hint "the
answer is incorrect" to re-answer. The process is
repeated for six iterations until the number of cor-
rectly answered questions no longer increases.
As shown in Figure 3, the performance of the
LLMs is improved (i.e., increasing from 4089
(54.7%) to 4898 (59.1%) after the first iteration,
and the improvement sustains in subsequent itera-
tions, ultimately reaching a peak of 5726 (76.6%).
This observation suggests that LLMs can au-
tonomously rectify errors with hints and contextual
information.
2.2 The Value of Revised Examples
Examples containing erroneous rationales were ig-
nored or screened out to prevent their adverse ef-
fects in previous studies (Zhang et al., 2022; Shum
et al., 2023). However, inspired by the idea that
students can improve their problem-solving abili-
ties by learning from a collection of mistakes, we
believe that allowing the model to learn from exam-
ples that have been answered incorrectly and then
corrected can also effectively enhance the model’s
inference performance. Figure 4 is a case study of
the value of revised examples on the Date Under-
standing (Wei et al., 2022) dataset. It shows the
different effects of two distinct demonstrations on
the same test question. Using a randomly sampled
exemplar as a demonstration is not beneficial (right
side), even though it is already correctly answered.
On the contrary, using the revised example’s rea-
soning chain (left side), where the reasoning chain
is self-corrected by the LLM with the approach in
Section 2.1, improves LLM’s reasoning ability.3 Iter-CoT: Iterative Bootstrapping in
Chain-of-Thought Prompting
Motivated by the observations in Section 2, we pro-
pose Iter-CoT ( Iterative bootst rapping in Chain- of-
Thoughts prompting), which generates the chain-
of-thought demonstrations by guiding the LLM to
rectify errors and summarize the reasoning chains
on questions with appropriate difficulty levels. Fol-
lowing that, we put these exemplars into the demon-
stration pool. During the inference, we sampling
and fixed the exemplars as the demonstration.
As shown in Figure 5, Iter-CoT consists of two
stages, the construction stage of the demonstra-
tion pool and the inference stage. Moreover, the
construction of the demonstration pool consists of
three phases:
Initialization The Zero-Shot-CoT (Kojima et al.,
2022) method is employed on the training set to
prompt the LLM to generate reasoning chains and
answers. Error examples are recorded for the sub-
sequent phases.
Bootstrapping For each erroneous example, the
Revise-Prompt ("Your answer is not right; can
you think more carefully and give me the final an-
swer?") is utilized to guide the LLM to self-correct
until the correct answer is generated. In the ab-
sence of a prompted reference answer, the correct
answer often corresponds to the correct reasoning
chains.
Summarization Once the correct answers are ob-
tained, the Summary-Prompt ("Can you give me a
complete solution reasoning process and final an-
swer again?") is employed to guide the LLM in
reviewing the previous rationales and summarizing
the final reasoning chains. We reconfirm the cor-
First we need to find out how many kids from
Riverside High were denied entry… 24 kids +
63 kids + 25 kids = <<24+63+25=112>>112
kids. The answer is: 112.User:Q: Fern is checking IDs to
get into an R-rated movie…How
many kids got into the movie?Zero-shot-CoT WrongCoT
Assistant : Let’s think step by step.
Revise-Prompt
User:Can you give me a com-
plete solution reasoning process
andfinal answer again?Summary-PromptUser:The answer is not right ,
can you think more carefully and
give me the final answer?Assistant : After thinking more carefully, I
realized that Iwas not solving for the
number of kids who got into the movie, but
rather… 260 kids – 112 kids = 148 kids. The
answer is: 148.Revise-Prompt
User:The answer is not right …WrongCoT
Assistant : ……
Final CoT
Assistant : Reasoning Process:
1. We know that 20% of the 120 kids from…
2. We also know that 70% of the 90 kids from...
...
6. Now that we know …… 260 kids - 112 kids
= <<260-112=148>>148 kids.
Final answer: 148.
……
(1)Initialization
(2)Bootstrapping
(3)SummarizationDemonstration
Pool
Q1: Fern is checking IDs to get into...
A: Reasoning process: Step 1: Calculate the…
Qn: …
A: Reasoning process: ...Demonstration
Q: Fern is checking IDs to get into an R-rated
movie… How many kids got into the movie?
A: Reasoning process:
1. We know that 20% of the 120 kids from…
2. Wealso know that 70% of the 90 kids…
...
6. Now that we know … 260 kids - 112 kids =
<<260-112=148>>148 kids.
Final answer: 148.
Sampling 
N-Exemplars CorrectCoT
Fixed-Demonstrations
New Question InferenceFigure 5: The workflow of Iter-CoT: 1. The construction of the demonstration pool : 1)Initialization : we query
the LLMs to generate reasoning chain and answer with Zero-Shot-CoT (Kojima et al., 2022). 2) Bootstrapping : we
useRevise-Prompt to guide LLMs to revise the reasoning chain repeatedly until the generated CoT is completely
accurate. 3) Summarization : we prompt LLMs with Summary-Prompt to generate the final reasoning chain (referred
to as Final CoT) based on the contextual information provided within the overall process. Then, we add the Final
CoT where the answer is correct with the corresponding question as an example to the demonstration pool. 2.
Inference : LLMs generate answers for the test questions with the demonstrations sampled from the constructed
demonstration pool.
rectness of the answer and retain only the correct
ones. This process enables the LLM to capture rich
contextual information from multi-turn conversa-
tions, resulting in more precise and comprehensive
reasoning chains.
Upon completion of the aforementioned process,
the final generated reasoning chain is combined
with the corresponding question and added to the
demonstration pool until the sample size fulfills the
requirements. The requirement is flexible, yet at
least satisfies differences in various datasets shown
in Table 7.
Our approach works in both label-available and
non-available scenarios. We use a rule-based ap-
proach to determine the correctness of the answers
when labels are available in the construction stage
of the demonstration pool. In contrast, when labels
are unavailable, we use a more powerful model
(e.g., GPT-4 (OpenAI, 2023)) as an evaluator to
assess the correctness of the answers.
Inference : During the inference stage, a random
sampling approach (Iter-CoT can also use othersampling methods, which are shown in Session
4.8.) is used to select Nexemplars from the demon-
stration pool, which served as fixed demonstrations
for the entire test set.
4 Experiment
4.1 Datasets and Evaluation Metrics
We evaluate our methods on ten datasets
across three categories of different reason-
ing tasks, including (1) six arithmetic reason-
ing datasets: GSM8k (Cobbe et al., 2021),
AQuA (Ling et al., 2017), AddSub (Hosseini et al.,
2014), SingleEq (Koncel-Kedziorski et al., 2015),
SV AMP (Patel et al., 2021) and ASDiv (Miao et al.,
2020); (2) three commonsense reasoning datasets:
CSQA (Talmor et al., 2019), StrategyQA (Geva
et al., 2021) and Date Understanding (Wei et al.,
2022); (3) one symbolic reasoning datasets: Letter
Concatenation (Wei et al., 2022). Examples of each
reasoning task and a detailed description of each
dataset are shown in Table 7 and Table 8.
MethodAnnotation/Label
NeededArithmetic Commonsense SymbolicAvg
GSM8K AQuA AddSub SingleEq SV AMP ASDiv CSQA STQA Date Letter
UL2-20B∗Annotation 4.4 23.6 18.2 20.2 12.5 16.9 51.4 53.3 - 0.0 -
LaMDA-137B∗Annotation 14.3 20.6 51.9 58.7 37.5 46.6 57.9 65.4 - 13.5 -
PaLM-540B∗Annotation 56.9 35.8 91.9 92.3 79.0 73.9 79.9 77.8 - 63.0 -
GPT-3.5-turbo
Random-CoT No 72.6 53.8 89.9 95.9 82.0 88.6 74.8 58.7 64.5 73.2 75.4
Auto-CoT No 78.1 56.7 94.7 96.4 83.6 - 72.3 62.8 - 78.2 -
Iter-CoT(w/o label) No 80.5 58.7 92.7 97.2 85.0 90.4 76.1 63.5 78.3 88.6 81.1
Manual-CoT Annotation 74.9 55.5 93.4 96.4 82.4 89.5 75.0 66.1 70.0 74.2 77.7
Complex-CoT Annotation 82.0 57.4 93.2 96.5 81.9 - - - - - -
Iter-CoT(w/ label) Label 80.9 62.2 94.9 96.9 84.3 91.0 75.9 64.5 78.6 85.2 81.5
Manual-CoT-SC Annotation 80.8 60.6 94.2 96.6 82.7 89.6 80.1 67.8 73.0 78.6 80.4
Iter-CoT(w/o label)-SC No 86.8 69.2 94.4 97.8 84.7 91.8 79.5 64.3 82.1 88.1 83.9
Iter-CoT(w/ label)-SC Label 89.1 72.4 94.9 97.3 85.2 91.2 80.6 66.7 80.7 89.6 84.8
Table 1: Accuracy on ten datasets from arithmetic, commonsense and symbolic reasoning tasks. * denotes all three
LLMs use Manual-CoT. The content in the "Annotation/Label Needed" column indicates whether the corresponding
method requires annotation of the complete reasoning chain or label of the final answer. Iter-CoT(w/o label) is
implemented with GPT-4 as the evaluator. The best results without Self-Consistency (SC) on GPT-3.5-turbo are
highlighted with green color, and the best results with SC on GPT-3.5-turbo are highlighted with blue color.
In the inference stage, we report the exact match
accuracy as our evaluation metric following previ-
ous works (Wei et al., 2022; Kojima et al., 2022).
4.2 Baselines
We compare our methods with five baseline
approaches: Manual-CoT (Wei et al., 2022),
Random-CoT ,Complex-CoT (Fu et al., 2022),
Auto-CoT (Zhang et al., 2022) and Self-
Consistency (SC) (Wang et al., 2022). Manual-
CoT involves using manually constructed reason-
ing chains as exemplars, listed in the appendix of
Wei et al. (2022). Random-CoT randomly selects
nquestions from the training set and generates
chains using the "let’s think step by step" prompt.
Complex-CoT selects most complex exemplars,
such as exemplars with most complex rationales or
longest questions from the training set, as demon-
strations. Auto-CoT utilizes clustering techniques
to sample questions and generate chains with the
same approach. Specifically, we implement Auto-
CoT by generating reasoning chains for the ques-
tions provided in their appendix as demonstrations.
Self-Consistency generates multiple answers for a
question and uses a majority voting mechanism to
select the final answer.
4.3 Implementation Details
We implement Iter-CoT on GPT-3.5-turbo (Ouyang
et al., 2022) and GPT-4 (OpenAI, 2023), using theOpenAI API2. We implement Iter-CoT on open-
source models using 8 A100-40Gs for inference us-
ing Llama-2-70B-Chat and Llama-2-70B (Touvron
et al., 2023) without quantization in our experi-
ments. During the construction stage of the demon-
stration pool, we utilize a temperature setting of 0.7,
whereas during the inference stage, we fix the tem-
perature to 0 for reproducibility. Moreover, we set
temperature = 0.7 and n = 40 for evaluation under
self-consistency as (Wang et al., 2022). We adopt
the number of exemplars for each dataset based
on the experimental configuration of prior work
(Zhang et al., 2022; Fu et al., 2022). Specifically,
for datasets lacking test sets and without compara-
ble datasets for transfer (e.g., Date Understanding),
we randomly select a small portion as the training
set and reserve the remaining portion for evalua-
tion as the test set. In addition, We conducted three
trials and averages for each experiment requiring
random sampling to obtain final results. The size
of each dataset and the partitioning of train and test
sets are shown in Table 7.
4.4 Main Results
As Iter-CoT can be applied with and without
groundtruth labels, we implement two versions:
Iter-CoT(w/ label) and Iter-CoT(w/o label). The
latter is implemented with GPT-4 as the evaluator.
The experimental results are presented in Table 1.
2https://platform.openai.com/
Method GSM8K CSQA Date Letter Avg.
Llama-2-70B-Chat
Manual-CoT 50.7 69.6 42.3 22.6 46.3
Iter-CoT(w/o label) 58.2 66.2 65.3 46.7 59.1
Iter-CoT(w/ label) 59.1 67.6 68.2 49.8 61.2
Llama-2-70B
Manual-CoT 56.8 68.4 73.3 22.4 55.2
Iter-CoT(w/o label) 61.1 73.1 75.6 37.2 61.8
Iter-CoT(w/ label) 62.3 71.1 77.3 40.6 62.8
GPT-4
Manual-CoT 92.0 83.0 90.1 92.9 89.5
Iter-CoT(w/o label) 94.3 83.5 93.5 95.1 91.6
Iter-CoT(w/ label) 95.2 85.7 94.7 96.6 93.1
Table 2: Different Approaches’ Performance with
Llama-2-70B-Chat, Llama-2-70B and GPT-4 on Four
Datasets. Iter-CoT(w/o label) is implemented with GPT-
4 as the evaluator.
We have the following observations:
Iter-CoT achieves superior performance on dif-
ferent tasks. Without using annotations/labels,
Iter-CoT achieves superior performance on dif-
ferent tasks, and its performance is compara-
ble or even superior than methods with annota-
tions/labels. When examining the results on the
first five arithmetic reasoning tasks in Table 1,
we observe that Iter-CoT(w/o label) outperforms
Complex-CoT with its average scores surpassing
those of Complex-CoT 0.4%. When labels are
available, Iter-CoT can achieves the best average
score(81.5%) on all ten datasets across three tasks
with GPT-3.5-turbo, surpassing Manual-CoT by
3.8% and Random-CoT by 6.1%. Notably, on the
Letter Concatenation dataset, Iter-CoT(w/ label)
achieved remarkable improvements of 7% com-
pared to the previous highest scores. On the first
five arithmetic reasoning tasks in Table 1, Iter-CoT
(w/ labels) continues to exhibit the best perfor-
mance, at 83.8%, surpassing Complex-CoT, where
the annotations of reasoning chains in demonstra-
tions are needed, by 1.6%. In conclusion, our
approach outperforms existing approaches and
achieves state-of-the-art results across various
tasks.
Iter-CoT(w/o label) share comparable perfor-
mance with Iter-CoT(w/ label). Iter-CoT(w/o
label) demonstrates a marginal superiority over
Iter-CoT(w/ label) on the Singleeq and SV AMP
datasets, with improvements of 0.3% and 0.7%,
respectively. However, it registers slightly lower
performance compared to Iter-CoT(w/ label) onMethod GSM8K Date Letter Avg.
Init-Wrong-CoT 71.9 61.2 72.1 68.4
Random-CoT 72.6 64.5 73.2 70.1
Init-Correct-CoT 72.5 63.0 78.6 71.4
Best-of-N-CoT 76.3 66.7 77.4 73.5
Correct-CoT 79.2 67.0 82.6 76.3
Iter-CoT 80.9 71.3 85.2 79.1
Table 3: Accuracy with different methods on GPT-3.5-
turbo. Init-Wrong-CoT : only take the wrong exem-
plars after initialization; Init-Correct-CoT : only take the
correct exemplars after initialization; Best-of-N-CoT :
prompt the LLM to generate multiple responses for the
questions initially answered incorrectly and choose the
correct answer as the exemplar; Correct-CoT : Iter-CoT
without summarization step; Iter-CoT : Our method with
label.
all other datasets, resulting in the average score
that is 0.6% lower than that of Iter-CoT(w/ label).
The performance gap between Iter-CoT(w/o la-
bel) and Iter-CoT(w/ label) can be attributed to
the inherent challenge of using GPT-4 for eval-
uating the correctness of responses. The errors
generated during the evaluation would cause the
selected demonstrations to be answered incorrectly
initially or not with the correct reasoning chains.
Nonetheless, the impact of these errors on the over-
all results remains acceptable. Statistically, GPT-4
demonstrates an 87.5% accuracy in determining the
correctness of responses during the demonstration
pool construction stage. Consequently, the propor-
tion of non-compliant samples in the final selected
demonstrations remains acceptable. Furthermore,
the incorrectly evaluated demonstrations tend to be
challenging, thereby offering valuable insights to
LLMs.
Self-consistency (SC) consistently augments the
efficacy of all methodologies. Notably, on the
GSM8K and AQuA datasets, SC significantly im-
proves model inference performance, resulting in
respective enhancements of 5.9%, 7.2%, and 8.2%
for the Manual-CoT, Iter-CoT(w/o label), and Iter-
CoT(w/ label) methods on GSM8K, and 5.1%,
10.5%, and 10.2% on AQuA. On other datasets,
SC has also demonstrated consistent improvements.
Ultimately, across the ten datasets, the three meth-
ods exhibit average performance enhancements
of 2.7%, 3.1%, and 3.4%, respectively. More-
over, With the inclusion of SC, Iter-CoT(w/ label)
and Iter-CoT(w/o label) continue to exhibit consis-
tent superiority over Manual-CoT, with an average
(a) Llama-2-70B-Chat
 (b) GPT-3.5-turbo
 (c) GPT-4
Figure 6: The influence of evaluator accuracy on model inference performance. Each subfigure corresponds to a
foundation model and three evaluators.
score advantage of 4.4% and 3.5%, respectively.
4.5 Performance on Different Foundation
Models
To validate the feasibility of our approach across
various diverse models, we conduct experiments
on GPT-4 and two open source models: Llama-2-
70B and Llama-2-70B-Chat (Touvron et al., 2023),
as shown in Table 2. When comparing the results
of different methods within three distinct founda-
tion models, we observe that our approach con-
sistently outperforms Manual-CoT across varying
models. Specifically, on the Llama-2-70B-Chat,
Llama-2-70B, and GPT-4 models, the average im-
provement of Iter-CoT(w/ label) over Manual-CoT
is 14.9%, 7.6%, and 3.6%, respectively. Further-
more, Iter-CoT(w/o label) exhibits performance
closely aligned with Iter-CoT(w/ label) across di-
verse models, with an average score difference of
merely 2.1%, 1%, and 2.5% within the three mod-
els.
4.6 Ablation Studies
During the construction stage of the demonstration
pool, both bootstrapping and summarization phases
play crucial roles in generating the final exemplars.
We conduct a series of ablation experiments to in-
vestigate the impact of these two phases on the
results. Explanations for all the methods employed
in this section of ablation experiments can be found
in the caption of Table 3.
In addition, for Iter-CoT(w/o label), we also in-
vestigate the accuracy of LLM evaluators and their
impact on the results.4.6.1 Impact of Bootstrapping and
Summarization phase
Comparison of Methods with and without a
Bootstrapping Phase To investigate the impact
of bootstrapping phase on model’s performance,
We contrast Correct-CoT, the method only uses
the bootstrapping process, with many methods
that do not modify the reasoning chains when
generating demonstrations. These methods in-
clude Init-Wrong-CoT, Random-CoT, Init-Correct-
CoT and Best-of-N-CoT. The outcomes are pre-
sented in Table 3. The presence of incorrect ex-
amples exerts a deleterious influence on model
reasoning, as evidenced by the performance de-
cline observed in Init-Wrong-CoT (68.4%) and
Random-CoT (70.1%). Moreover, a direct com-
parison between Init-Wrong-CoT, Best-of-N-CoT
and Correct-CoT, wherein the examples share iden-
tical questions, accentuates the efficacy of the boot-
strapping phase. The comparison between Init-
correct-CoT and Correct-CoT also illustrates that
the bootstrapping phase facilitates the selection of
questions with appropriate difficulty levels.
4.7 The Effect of Iterations in the
Bootstrapping Phase
We posit that questions requiring multiple times
of bootstrapping are more challenging. Conse-
quently, we conduct experiments for Iter-CoT on
three datasets with iterative bootstrapping, where
the iterations are the number of times the bootstrap-
ping phase is invoked. The results are depicted in
Figure 7.
We observed that the performance of Iter-
CoT(w/ label) tends to initially rise and then fall
as the number of bootstrapping steps increases. In
contrast, Iter-CoT(w/o label) shows a steady im-
Figure 7: The Iter-CoT’s overall performance with iter-
ative bootstrapping on three datasets.
provement (except for GSM8K, which exhibits an
initial increase followed by a decrease, likely due
to the challenge and difficulty of the GSM8K com-
pared to the other two datasets.). However, even
as accuracy decreases with increasing iterations,
the post-decline accuracy still outperforms most
baselines.
In Table 1, for GSM8K, CSQA, Letter Concate-
nation and other datasets sharing the same exem-
plars with GSM8K (AddSub, SingleEq, SV AMP,
and ASDiv), we utilize the best exemplars in this
section. In future work, further iterations can be
explored to generate exemplars of higher quality
for other datasets.
Impact of Summarization phase To investigate
the impact of the summarization phase on the
model’s inference capability, similar to the previous
section, we compare Iter-CoT with Correct-CoT,
which excludes the utilization of the summariza-
tion phase. Table 3 demonstrates that the former
outperforms the latter by 2.8%. We attribute this
performance difference to the role of the summa-
rization phase, which encourages the model to in-
corporate extensive contextual information, thereby
facilitating the generation of more intricate and
comprehensive reasoning chains.
4.8 Sampling Strategies
After establishing the demonstration pool, we can
employ various sampling methods to select exam-
ples for inference. We utilized three sampling tech-
niques: random sampling, similarity-based sam-
pling (retrieves the most similar examples accord-
ing to BM25 similarity), and complexity-based
sampling (selects the examples with the most com-Method GSM8K Date Avg.
Random 80.9 78.6 79.8
Similarity 79.8 79.1 79.5
Complexity 81.3 79.7 80.5
Table 4: Performance of Iter-CoT(w/ label) utilizing
various sampling methods.
plex reasoning steps). While other sampling meth-
ods are also applicable, they are not the subject
of discussion here. The performance is shown in
Table 4.
The results show that employing effective sam-
pling methods can further enhance performance.
However, introducing complexity-based sampling
incurs additional overhead (as it requires manually
annotated reasoning chains), thus in our main exper-
iment, we report results based on random sampling,
which represents the simplest sampling method,
requiring no additional expenditure.
4.8.1 Impact of LLM evaluators’ Accuracy in
Iter-CoT
In Section 4.4, we mentioned the potential errors
when using GPT-4 as an evaluator, which could
impact the results. To investigate the influence of
evaluators’ accuracy on model inference capabil-
ity in Iter-CoT(w/o label), we select three distinct
LLMs and employ them as both the foundation
model and evaluator. For each experiment, we
compute the evaluator’s accuracy along with the fi-
nal inference performance of the foundation model.
The experimental results are presented in Figure 6.
All three subplots exhibit a common trend: the
performance of the foundation model improves as
the evaluator’s accuracy increases. As the evalua-
tor’s accuracy rises, the quality of generated exem-
plars is close to that of Iter-CoT (w/ label). Further-
more, by comparing the three subplots, we observe
that the evaluator tends to achieve higher accuracy
in judging the generated answers of weaker foun-
dation models. For example, utilizing GPT-4 as
an evaluator to assess the accuracy of Llama-2-
70B-Chat yields a precision of 89.2%. In contrast,
when evaluated by ChatGPT, the accuracy stands
at 73.4%. Llama’s self-assessment, however, indi-
cates a modest 54.8% accuracy.
Due to the page limit, experiments and analysis
on the performance across different levels of diffi-
culty, the effectiveness of different numbers of seed
examples, the comparison between Iter-CoT and
other methods, and the length of generated reason-
ing chains are not included in this section. Details
of these experiments and analysis are discussed in
Section B.1, A.2, A.3, A.4, A.5 and A.6.
5 Related Work
5.1 Chain-of-thought Prompting
5.1.1 Manually Constructed CoT Prompts
Wei et al. (2022) proposed Manual-CoT, an ap-
proach that employs manually-crafted demonstra-
tions as prompts. In subsequent work, Wang et al.
(2022) introduced a novel decoding strategy "Self-
Consistency", which generates multiple answers
from LLMs and aggregates them through a major-
ity voting mechanism. Li et al. (2022) increased
the randomness of the prompts to enhance the di-
versity of generated reasoning paths (Huang et al.,
2024; Li et al., 2023; Liu et al., 2020). Diao et al.
(2023) annotated the reasoning chain manually for
the most uncertain questions. Although these ap-
proaches have shown remarkable performance in
enhancing the model’s reasoning capability, they
are expensive, suboptimal and highly sensitive.
5.1.2 Automatically Generated CoT Prompts
Kojima et al. (2022) proposed "Let’s think step by
step" prompt that guides LLMs to generate reason-
ing steps without manually constructed demonstra-
tions. Following this work, Zhang et al. (2022) and
Shum et al. (2023) employed zero-shot-cot Kojima
et al. (2022) to generate the reasoning process. In
contrast, Shao et al. (2023) employed seed demon-
strations to synthesize examples by automatically
repeating forward and backward processes.
We propose a novel approach to generate rea-
soning chains by allowing LLMs to retrace their
reasoning process after inferring the answer.
5.2 In-Context Learning
In-Context Learning (ICL) is a technique that al-
lows LLMs to complete target tasks during infer-
ence by using a few tasks-specific examples as
demonstrations, without modifying the model pa-
rameters (Shao et al., 2023; Brown et al., 2020;
Zhang et al., 2023b, 2021, 2023a). Zhao et al.
(2021) underscored that the accuracy of LLMs in
ICL depends heavily on the selection and permu-
tation of exemplars. Therefore, significant efforts
have been invested in developing approaches to
select appropriate few-shot demonstrations.Zhang et al. (2022) adopted a clustering-based
method to select demonstrations. Fu et al. (2022)
selected the demonstrations with the most reason-
ing steps. Similarly, Diao et al. (2023) chose the
demonstrations with most uncertain questions. Ad-
ditionally, Shum et al. (2023) added the demonstra-
tions with the correct answer to the samples pool
and sampled the exemplars with a trained model.
These studies all strive to minimize the use of incor-
rect exemplars. Contrarily, Zelikman et al. (2022)
handled erroneous examples by hinting the model
with the correct answers to generate results again.
We conduct a comparative analysis with their ap-
proach, which is presented in Section A.5.
Through iterative bootstrapping, our approach
selects challenging yet answerable exemplars, en-
hancing the LLMs’ generalizability across varying
difficulty levels.
6 Conclusion
This paper proposes Iter-CoT, an iterative boot-
strapping in chain-of-thoughts prompting for LLM
reasoning. Unlike previous work, our method
prompts LLMs to self-correct their errors in reason-
ing chains by leveraging iterative bootstrapping and
obtaining more precise and comprehensive reason-
ing chains. Experimental results on ten reasoning
datasets among three different tasks demonstrate
that our approach significantly outperforms the pre-
vious methods, achieving new state-of-the-art.
7 Limitations
Cost of Iter-CoT Iter-CoT incurs the same cost
during the inference stage as other baselines, as
all additional expenses are only incurred during
the construction phase of the demonstration pool.
The demonstration pool has both a maximum and
minimum size. The maximum size is obtained by
applying Iter-CoT on the entire training set, while
the minimum size corresponds to the required ex-
emplars during inference.
Accuracy of Evaluator In Iter-CoT(w/o label),
the model’s performance relies significantly on the
accuracy of the evaluator. Therefore, a more pow-
erful and robust model than the primary one is
required to serve as the evaluator. Moreover, the in-
troduction of the evaluator also results in increased
overhead.
References
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie
Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind
Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, Sandhini Agarwal, Ariel Herbert-V oss,
Gretchen Krueger, Tom Henighan, Rewon Child,
Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,
Clemens Winter, Christopher Hesse, Mark Chen, Eric
Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,
Jack Clark, Christopher Berner, Sam McCandlish,
Alec Radford, Ilya Sutskever, and Dario Amodei.
2020. Language models are few-shot learners. In Ad-
vances in Neural Information Processing Systems 33:
Annual Conference on Neural Information Process-
ing Systems 2020, NeurIPS 2020, December 6-12,
2020, virtual .
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
Maarten Bosma, Gaurav Mishra, Adam Roberts,
Paul Barham, Hyung Won Chung, Charles Sutton,
Sebastian Gehrmann, Parker Schuh, Kensen Shi,
Sasha Tsvyashchenko, Joshua Maynez, Abhishek
Rao, Parker Barnes, Yi Tay, Noam Shazeer, Vin-
odkumar Prabhakaran, Emily Reif, Nan Du, Ben
Hutchinson, Reiner Pope, James Bradbury, Jacob
Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,
Toju Duke, Anselm Levskaya, Sanjay Ghemawat,
Sunipa Dev, Henryk Michalewski, Xavier Garcia,
Vedant Misra, Kevin Robinson, Liam Fedus, Denny
Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim,
Barret Zoph, Alexander Spiridonov, Ryan Sepassi,
David Dohan, Shivani Agrawal, Mark Omernick, An-
drew M. Dai, Thanumalayan Sankaranarayana Pil-
lai, Marie Pellat, Aitor Lewkowycz, Erica Moreira,
Rewon Child, Oleksandr Polozov, Katherine Lee,
Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark
Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathy
Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov,
and Noah Fiedel. 2022. Palm: Scaling language mod-
eling with pathways. arXiv Preprint .
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian,
Jacob Hilton, Reiichiro Nakano, Christopher Hesse,
and John Schulman. 2021. Training verifiers to solve
math word problems. arXiv Preprint .
Shizhe Diao, Pengcheng Wang, Yong Lin, and Tong
Zhang. 2023. Active prompting with chain-of-
thought for large language models. arXiv Preprint .
Yao Fu, Hao Peng, Ashish Sabharwal, Peter Clark, and
Tushar Khot. 2022. Complexity-based prompting for
multi-step reasoning. arXiv Preprint .
Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,
Dan Roth, and Jonathan Berant. 2021. Did aristotle
use a laptop? A question answering benchmark with
implicit reasoning strategies. Trans. Assoc. Comput.
Linguistics , 9:346–361.
Mohammad Javad Hosseini, Hannaneh Hajishirzi, Oren
Etzioni, and Nate Kushman. 2014. Learning to solve
arithmetic word problems with verb categorization.
InProceedings of the 2014 Conference on EmpiricalMethods in Natural Language Processing, EMNLP
2014, October 25-29, 2014, Doha, Qatar, A meeting
of SIGDAT, a Special Interest Group of the ACL ,
pages 523–533. ACL.
Rikui Huang, Wei Wei, Xiaoye Qu, Wenfeng Xie, Xi-
anling Mao, and Dangyang Chen. 2024. Joint multi-
facts reasoning network for complex temporal ques-
tion answering over knowledge graph. arXiv preprint
arXiv:2401.02212 .
Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-
taka Matsuo, and Yusuke Iwasawa. 2022. Large
language models are zero-shot reasoners. arXiv
Preprint .
Rik Koncel-Kedziorski, Hannaneh Hajishirzi, Ashish
Sabharwal, Oren Etzioni, and Siena Dumas Ang.
2015. Parsing algebraic word problems into equa-
tions. Trans. Assoc. Comput. Linguistics , 3:585–597.
Wendi Li, Wei Wei, Xiaoye Qu, Xian-Ling Mao,
Ye Yuan, Wenfeng Xie, and Dangyang Chen. 2023.
Trea: Tree-structure reasoning schema for conversa-
tional recommendation. In Proceedings of the 61st
Annual Meeting of the Association for Computational
Linguistics (Volume 1: Long Papers) , pages 2970–
2982.
Yifei Li, Zeqi Lin, Shizhuo Zhang, Qiang Fu, Bei Chen,
Jian-Guang Lou, and Weizhu Chen. 2022. On the
advance of making language models better reasoners.
arXiv Preprint .
Wang Ling, Dani Yogatama, Chris Dyer, and Phil Blun-
som. 2017. Program induction by rationale genera-
tion: Learning to solve and explain algebraic word
problems. In Proceedings of the 55th Annual Meet-
ing of the Association for Computational Linguistics,
ACL 2017, Vancouver, Canada, July 30 - August 4,
Volume 1: Long Papers , pages 158–167.
Daizong Liu, Xiaoye Qu, Jianfeng Dong, and Pan
Zhou. 2020. Reasoning step-by-step: Temporal sen-
tence localization in videos via deep rectification-
modulation network. In Proceedings of the 28th
International Conference on Computational Linguis-
tics, pages 1841–1851.
Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler
Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon,
Nouha Dziri, Shrimai Prabhumoye, Yiming Yang,
Sean Welleck, Bodhisattwa Prasad Majumder,
Shashank Gupta, Amir Yazdanbakhsh, and Peter
Clark. 2023. Self-refine: Iterative refinement with
self-feedback. CoRR , abs/2303.17651.
Shen-Yun Miao, Chao-Chun Liang, and Keh-Yih Su.
2020. A diverse corpus for evaluating and developing
english math word problem solvers. In Proceedings
of the 58th Annual Meeting of the Association for
Computational Linguistics, ACL 2020, Online, July
5-10, 2020 , pages 975–984.
OpenAI. 2023. GPT-4 technical report. CoRR ,
abs/2303.08774.
Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car-
roll L. Wainwright, Pamela Mishkin, Chong Zhang,
Sandhini Agarwal, Katarina Slama, Alex Ray, John
Schulman, Jacob Hilton, Fraser Kelton, Luke Miller,
Maddie Simens, Amanda Askell, Peter Welinder,
Paul F. Christiano, Jan Leike, and Ryan Lowe. 2022.
Training language models to follow instructions with
human feedback. arXiv Preprint .
Arkil Patel, Satwik Bhattamishra, and Navin Goyal.
2021. Are NLP models really able to solve simple
math word problems? In Proceedings of the 2021
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2021, Online,
June 6-11, 2021 , pages 2080–2094.
Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt,
Noah A. Smith, and Mike Lewis. 2023. Measuring
and narrowing the compositionality gap in language
models. In Findings of the Association for Compu-
tational Linguistics: EMNLP 2023, Singapore, De-
cember 6-10, 2023 , pages 5687–5711. Association
for Computational Linguistics.
Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie
Millican, Jordan Hoffmann, H. Francis Song, John
Aslanides, Sarah Henderson, Roman Ring, Susan-
nah Young, Eliza Rutherford, Tom Hennigan, Ja-
cob Menick, Albin Cassirer, Richard Powell, George
van den Driessche, Lisa Anne Hendricks, Mari-
beth Rauh, Po-Sen Huang, Amelia Glaese, Jo-
hannes Welbl, Sumanth Dathathri, Saffron Huang,
Jonathan Uesato, John Mellor, Irina Higgins, Antonia
Creswell, Nat McAleese, Amy Wu, Erich Elsen, Sid-
dhant M. Jayakumar, Elena Buchatskaya, David Bud-
den, Esme Sutherland, Karen Simonyan, Michela Pa-
ganini, Laurent Sifre, Lena Martens, Xiang Lorraine
Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena
Gribovskaya, Domenic Donato, Angeliki Lazaridou,
Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsim-
poukelli, Nikolai Grigorev, Doug Fritz, Thibault Sot-
tiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong,
Daniel Toyama, Cyprien de Masson d’Autume, Yujia
Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin,
Aidan Clark, Diego de Las Casas, Aurelia Guy,
Chris Jones, James Bradbury, Matthew J. Johnson,
Blake A. Hechtman, Laura Weidinger, Iason Gabriel,
William S. Isaac, Edward Lockhart, Simon Osindero,
Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem
Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hass-
abis, Koray Kavukcuoglu, and Geoffrey Irving. 2021.
Scaling language models: Methods, analysis & in-
sights from training gopher. arXiv Preprint .
Teven Le Scao, Angela Fan, Christopher Akiki, El-
lie Pavlick, Suzana Ilic, Daniel Hesslow, Roman
Castagné, Alexandra Sasha Luccioni, François Yvon,
Matthias Gallé, Jonathan Tow, Alexander M. Rush,
Stella Biderman, Albert Webson, Pawan Sasanka Am-
manamanchi, Thomas Wang, Benoît Sagot, Niklas
Muennighoff, Albert Villanova del Moral, Olatunji
Ruwase, Rachel Bawden, Stas Bekman, Angelina
McMillan-Major, Iz Beltagy, Huu Nguyen, LucileSaulnier, Samson Tan, Pedro Ortiz Suarez, Vic-
tor Sanh, Hugo Laurençon, Yacine Jernite, Julien
Launay, Margaret Mitchell, Colin Raffel, Aaron
Gokaslan, Adi Simhi, Aitor Soroa, Alham Fikri
Aji, Amit Alfassy, Anna Rogers, Ariel Kreisberg
Nitzav, Canwen Xu, Chenghao Mou, Chris Emezue,
Christopher Klamm, Colin Leong, Daniel van Strien,
David Ifeoluwa Adelani, and et al. 2022. BLOOM:
A 176b-parameter open-access multilingual language
model. arXiv Preprint .
Zhihong Shao, Yeyun Gong, Yelong Shen, Min-
lie Huang, Nan Duan, and Weizhu Chen. 2023.
Synthetic prompting: Generating chain-of-thought
demonstrations for large language models. arXiv
Preprint , abs/2302.00618.
Kashun Shum, Shizhe Diao, and Tong Zhang. 2023.
Automatic prompt augmentation and selection with
chain-of-thought from labeled data. arXiv Preprint ,
abs/2302.12822.
Shaden Smith, Mostofa Patwary, Brandon Norick,
Patrick LeGresley, Samyam Rajbhandari, Jared
Casper, Zhun Liu, Shrimai Prabhumoye, George
Zerveas, Vijay Korthikanti, Elton Zheng, Rewon
Child, Reza Yazdani Aminabadi, Julie Bernauer, Xia
Song, Mohammad Shoeybi, Yuxiong He, Michael
Houston, Saurabh Tiwary, and Bryan Catanzaro.
2022. Using deepspeed and megatron to train
megatron-turing NLG 530b, A large-scale genera-
tive language model. arXiv Preprint .
Alon Talmor, Jonathan Herzig, Nicholas Lourie, and
Jonathan Berant. 2019. Commonsenseqa: A question
answering challenge targeting commonsense knowl-
edge. In Proceedings of the 2019 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, NAACL-HLT 2019, Minneapolis, MN, USA,
June 2-7, 2019, Volume 1 (Long and Short Papers) ,
pages 4149–4158.
Romal Thoppilan, Daniel De Freitas, Jamie Hall,
Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze
Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,
YaGuang Li, Hongrae Lee, Huaixiu Steven Zheng,
Amin Ghafouri, Marcelo Menegali, Yanping Huang,
Maxim Krikun, Dmitry Lepikhin, James Qin, Dehao
Chen, Yuanzhong Xu, Zhifeng Chen, Adam Roberts,
Maarten Bosma, Yanqi Zhou, Chung-Ching Chang,
Igor Krivokon, Will Rusch, Marc Pickett, Kathleen S.
Meier-Hellstern, Meredith Ringel Morris, Tulsee
Doshi, Renelito Delos Santos, Toju Duke, Johnny So-
raker, Ben Zevenbergen, Vinodkumar Prabhakaran,
Mark Diaz, Ben Hutchinson, Kristen Olson, Ale-
jandra Molina, Erin Hoffman-John, Josh Lee, Lora
Aroyo, Ravi Rajakumar, Alena Butryna, Matthew
Lamm, Viktoriya Kuzmina, Joe Fenton, Aaron Co-
hen, Rachel Bernstein, Ray Kurzweil, Blaise Aguera-
Arcas, Claire Cui, Marian Croak, Ed H. Chi, and
Quoc Le. 2022. Lamda: Language models for dialog
applications. arXiv Preprint .
Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-
bert, Amjad Almahairi, Yasmine Babaei, Nikolay
Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti
Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-
Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,
Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,
Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-
thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan
Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura,
Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-
ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-
tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-
bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-
stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,
Ruan Silva, Eric Michael Smith, Ranjan Subrama-
nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-
lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,
Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,
Melanie Kambadur, Sharan Narang, Aurélien Ro-
driguez, Robert Stojnic, Sergey Edunov, and Thomas
Scialom. 2023. Llama 2: Open foundation and fine-
tuned chat models. CoRR , abs/2307.09288.
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V .
Le, Ed H. Chi, and Denny Zhou. 2022. Self-
consistency improves chain of thought reasoning in
language models. arXiv Preprint .
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
Bosma, Ed H. Chi, Quoc Le, and Denny Zhou. 2022.
Chain of thought prompting elicits reasoning in large
language models. arXiv Preprint .
Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak
Shafran, Karthik R. Narasimhan, and Yuan Cao. 2023.
React: Synergizing reasoning and acting in language
models. In The Eleventh International Conference
on Learning Representations, ICLR 2023, Kigali,
Rwanda, May 1-5, 2023 . OpenReview.net.
Eric Zelikman, Yuhuai Wu, and Noah D. Goodman.
2022. Star: Bootstrapping reasoning with reasoning.
arXiv Preprint .
Hang Zhang, Yeyun Gong, Xingwei He, Dayiheng Liu,
Daya Guo, Jiancheng Lv, and Jian Guo. 2023a. Noisy
pair corrector for dense retrieval. arXiv preprint
arXiv:2311.03798 .
Hang Zhang, Yeyun Gong, Yelong Shen, Weisheng Li,
Jiancheng Lv, Nan Duan, and Weizhu Chen. 2021.
Poolingformer: Long document modeling with pool-
ing attention. In International Conference on Ma-
chine Learning , pages 12437–12446. PMLR.
Hang Zhang, Xin Li, and Lidong Bing. 2023b. Video-
llama: An instruction-tuned audio-visual language
model for video understanding. arXiv preprint
arXiv:2306.02858 .
Zhuosheng Zhang, Aston Zhang, Mu Li, and Alex
Smola. 2022. Automatic chain of thought prompting
in large language models. arXiv Preprint .
Zihao Zhao, Eric Wallace, Shi Feng, Dan Klein, and
Sameer Singh. 2021. Calibrate before use: Improv-
ing few-shot performance of language models. InProceedings of the 38th International Conference on
Machine Learning, ICML 2021, 18-24 July 2021, Vir-
tual Event , volume 139 of Proceedings of Machine
Learning Research , pages 12697–12706. PMLR.
Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei,
Nathan Scales, Xuezhi Wang, Dale Schuurmans,
Olivier Bousquet, Quoc Le, and Ed H. Chi. 2022.
Least-to-most prompting enables complex reasoning
in large language models. arXiv Preprint .
A Analysis for Iter-CoT
A.1 Performance Across Different Levels of
Difficulty
We investigate the generalization ability of Iter-
CoT on questions with varying difficulty levels.
We follow the same hop-based criterion as previous
work (Fu et al., 2022) to measure query difficulty.
We sort the test set of GSM8K according to the
number of hops of the annotated reasoning chains
and conduct experiments using Iter-CoT and other
baselines, as shown in Figure 9. Our results indi-
cate that Iter-CoT is comparable to other methods
for questions with few hops, whereas its perfor-
mance is significantly better than other methods
for questions with more hops. Iter-CoT performs
the same as Simple-CoT on 2-hop questions (1%
higher), while it is on par with Complex-CoT on 8-
hop questions (2% lower) and is substantially ahead
of the other methods (about 20%). This suggests
that with Iter-CoT, we can select exemplars with
intermediate difficulty levels, which can greatly im-
prove the performance of LLM among questions
of varying difficulty. Moreover, the effect of Iter-
CoT(w/o label) is even superior to Iter-CoT(w/ la-
bel) on 7-hop and 8-hop questions, which shows
the robustness of our proposed methods.
A.2 Effective of Different Numbers of Seed
Examples
In order to investigate the sensitivity of our ap-
proaches and conventional CoT to the seed exam-
ples, we conducted an experiment on the GSM8K
dataset as shown in Figure 10. It demonstrates that
both of our approaches outperform CoT, and are
more stable as the number of examples increases.
Additionally, our experiment also shows that the
overall performance is not determined by the quan-
tity of increasing exemplars. For instance, the Iter-
CoT peak occurs at five exemplars, while the Iter-
CoT(w/o label) and Random-CoT peaks at four
exemplars.
A.3 Comparison with CoT
As Section 3 mentions, Iter-CoT can generate more
precise and comprehensive reasoning chains than
zero-shot-CoT. We conduct inference on three dis-
tinct reasoning datasets (GSM8K, Letter(4) and
Date Understanding) utilizing both Iter-CoT’s first
stage and Zero-Shot-CoT with the same questions,
which are shown in Table 5. We use the same LLMs
and temperature to generate reasoning chains andanswers. We observe that the Final CoT generated
after the Iter-CoT’s first stage is naturally more
precise and comprehensive compared to CoT gen-
erated by zero-shot-CoT, resulting in higher quality
demonstrations.
A.4 Comparison with Verify-and-Correct
Methods
Our work parallels certain existing methods that
improve LLMs reasoning abilities through error
correction strategies, such as ReAct (Yao et al.,
2023), Self-Refine (Madaan et al., 2023), and Self-
Ask (Press et al., 2023), all of which fall under
the category of LLM-Agent approaches. The key
difference of our Iter-CoT method from these lies
in its unique mechanism: it learns from errors to
create moderately challenging examples with com-
prehensive, detailed reasoning chains, facilitating
in-context learning for the model. In contrast, meth-
ods like ReAct, Self-Refine, and Self-Ask employ
LLMs more as agents for planning and decision-
making. For example, Self-ask decomposes prob-
lems into sub-problems (planning), then utilizes a
search engine to find answers for each sub-problem
(decision-making), and then compiles the results.
However, these methods typically involve iterative
calls to LLMs for each query during the inference
phase, leading to extended processing times and
increased costs. In contrast, our approach builds a
high-quality demonstration pool in advance, elim-
inating additional computational demands during
the inference stage.
A.5 Comparison with STaR-CoT
In concurrent work closely related to ours, Zelik-
man et al. (2022) applies a similar methodology
to ours in regenerating the reasoning chains for
incorrect examples (we denote STaR-CoT in this
paper). Although our work shares similar ideas to
their approach, we differ in several key respects.
First, their approach does not involve any contex-
tual information from the previous step. More-
over, their approach provides the correct answer
directly to the model, rather than using the cor-
rectness of the answer or error reasoning steps as
bootstrapping information. It is more prone to gen-
erating erroneous reasoning chains despite arriving
at the correct answer. Moreover, they continue
fine-tuning the model using the corrected reason-
ing chains, which is impossible for LLMs with
175B parameters (such as ChatGPT (Ouyang et al.,
2022)). We conduct inference on one arithmetic
reasoning dataset GSM8K utilizing both Iter-CoT’s
first stage and STaR-CoT with the same questions
shown in Table 6. We use the same LLMs and tem-
perature to generate reasoning chains and answers.
It is observed that although STaR-CoT generates
the correct answer, the rationales are wrong, lead-
ing to confusion of the entire reasoning chain and
reducing the overall performance ( 80.9% compared
to76.3%).
A.6 Average Length of Reasoning Chains
Figure 8: Average length of reasoning chains generated
by different methods on GSM8K, CSQA and Last Letter
Concatenation.
We compare the average length of reasoning
chains generated by different methods, which are
demonstrated in Figure 8. The average length of
the reasoning chains demonstrated by Iter-CoT is
significantly higher than other methods on the three
datasets (GSM8K, CSQA and Last Letter Concata-
tion). These results provide solid evidence that
the reasoning chains demonstrated by Iter-CoT are
more comprehensive than those by other alternative
methods.
B Experiment Details
B.1 Datasets and Tasks
We evaluate Iter-CoT using ten datasets from three
different categories of reasoning tasks. The spe-
cific descriptions, divisions, and references of each
dataset are shown in Table 7. The examples of each
reasoning task are shown in Table 8.
CFull Exemplars Generated by Iter-CoT
Figure 9: The performance on GSM8K across different numbers of hops.
Figure 10: Effictive of Different Numbers of Seed Examples on GSM8K.
Final CoT CoT
Q: Four classmates were comparing their ages based on their birth month. They found out that Jolyn is 2
months older than Therese while Therese is 5 months older than Aivo. Then, Leon is 2 months older than
Aivo. How much older in months is Jolyn than Leon? (GSM8K)
A: Reasoning process: We are given that Jolyn is 2
months older than Therese and Therese is 5 months
older than Aivo. Let the ages of Therese and Aivo be
T and A, respectively. We can write the ages of Jolyn,
Therese, and Aivo as J = T+2, T = A+5, and A = A.
Leon is 2 months older than Aivo, so L = A+2. We
want to find the difference between Jolyn’s age and
Leon’s age, so J - L = (T+2) - (A+2). Substituting for
T and A using the equations above gives us (A+7) -
(A+2) = 5. Therefore, Jolyn is 5 months older than
Leon. Final answer: 5. ✔A: Let’s think step by step. First let’s say the ages of
Therese and Aivo is T and A. T=A+5 J=T+2 L=A+2
J-L=T+2-(A+2) J-L=2 The correct answer is: 2. ✗
Q: Take the last letters of the words in "Steve Sweeney" and concatenate them. (Letter(4))
A: Reasoning process: First, we need to split the
sentence "Steve Sweeney" into individual words by
looking for the spaces. This gives two words: "Steve"
and "Sweeney". Next, we need to take last letter of
each word, which are "e" and "y". Finally, we need
to concatenate these letters together to get the final
answer. Final answer: ey. ✔A: Let’s think step by step. First we take the last
letters of the words in "Steve Sweeney", which are
"ete eeney". Since we need to concatenate them, we
will end up with: "ete eeney" Therefore, the correct
answer is: "ete eeney". ✗
Q: May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date one
week from today in MM/DD/YYYY? Choices: A.05/13/2044 B.06/10/2002 C.05/13/2002 D.03/13/2003
E.11/13/2001 (Date Understanding)
A: Reasoning process: 1. May 6, 1992 is ten years
ago from today, which means today is May 6, 2002.
2. The date one week from today is the date one
week from May 6, 2002. 3. The date one week from
May 6, 2002 is May 13, 2002. 4. The date one week
from today in MM/DD/YYYY is 05/13/2002. Final
answer: C.05/13/2002. ✔A: Let’s think step by step. The date one week from
today is the date one week from Monday May 13,
2002. Thus the correct answer is: B.06/10/2002. ✗
Table 5: This is an example of Iter-CoT compared to CoT on three different reasoning datasets.
Final CoT STaR CoT
Q: Tina makes $18.00 an hour. If she works more than 8 hours per shift, she is eligible for overtime,
which is paid by your hourly wage + 1/2 your hourly wage. If she works 10 hours every day for 5 days,
how much money does she make? (GSM8K)
A: Reasoning process: First, let’s figure out how
many hours Tina works per week. She works 10
hours per day and 5 days per week, so 10*5 = 50
hours. Next, let’s figure out how many of those hours
are overtime. She is eligible for overtime if she works
more than 8 hours per shift and she works 10 hours
per shift, so 10-8 = 2 hours of overtime per shift. And
since Tina works 5 shifts and 2 hours of overtime per
shift, she works a total of 5*2 = 10 hours of overtime.
Now we can figure out how much Tina makes in
regular pay. She works 50-10 = 40 hours per week
at her regular wage of $18 per hour, so she makes
40*18 = $720 in regular pay. Now we can figure out
how much Tina makes in overtime pay. She gets time
and a half for overtime, so 1.5 * $18 per hour = $27
per hour. And since she works 10 hours of overtime
and makes $27 per hour, she makes 10*27 = $270 in
overtime pay. So in total, Tina makes 720 + 270 =
$990 per week. ✔A: The correct answer is: 990. Let’s think step by
step. Tina works 10 hours per day for 5 days, so she
works 10*5 = 50 hours. She is eligible for overtime
after 8 hours per shift, so she works 50-8 = «50-
8=42»42 hours of overtime. She makes $18.00 per
hour, so she makes 18*42 = 756 dollars of overtime
pay. Overtime pay is her hourly wage + 1/2 her
hourly wage, so she makes 18+(18/2) = $27.00 per
hour of overtime. She works 42 hours of overtime,
so she makes 27*42 = 1134 dollars of overtime pay.
She makes $18.00 per hour for her regular hours, so
she makes 18*8 = «18*8=144»144 dollars of regular
pay. She makes a total of 144+1134 = 1278 dollars.
✗Therefore, the correct answer is: 990. ✔
Table 6: This is an example of Final CoT compared to STaR-CoT on GSM8K. The result shows that STaR-CoT is
prone to generate erroneous reasoning chains despite arriving at the correct answer.
Dataset Answer Format Examples Train Test Licence
GSM8K Number 8 7473 1319 MIT License
AQuA Multiple choice 4 97467 254 Apache-2.0
AddSub Number 8 GSM8K∗395 -
SingleEq Number 8 GSM8K∗508 -
SV AMP Number 8 GSM8K∗1000 MIT License
ASDiv Number 8 GSM8K∗2096 -
CSQA Multiple choice 7 9741 1221 -
StrategyQA Bineary 6 2821 1880 Apache-2.0
Date Multiple choice 8 69 300 Apache-2.0
Letter(4) String 4 500(2∗)500(4∗)Apache-2.0
Table 7: The statistics of the datasets used in this paper. Examples are the number of examples demonstrations for
each dataset. GSM8K∗denotes constructed the training set using the GSM8K, cause no available training set for
the current dataset. 2∗and 4∗in the "Letter(4)" row refers to using 2 letters in the training set while using 4 letters
in the test set (Out-of-Domain).
Reasoning Tasks Example
Arithmetic Marissa is hiking a 12-mile trail. She took 1 hour to walk the first 4 miles, then another
hour to walk the next two miles. If she wants her average speed to be 4 miles per hour,
what speed (in miles per hour) does she need to walk the remaining distance?
Commonsense Sammy wanted to go to where the people were. Where might he go?
Choices: A.race track B.populated areas C.the desert D.apartment E.roadblock
Symbolic Take the last letters of each words in "Geo Kody Isaias Giovanni" and concatenate them.
Table 8: The examples are sampled from the test sets of three typical reasoning datasets, GSM8K (Cobbe et al.,
2021), CommonSenseQA (Talmor et al., 2019) and Last Letter Concatation (Wei et al., 2022), respectively.
DATASET Iter-CoT Exemplars
GSM8K Q: Sheila, Purity, and Rose want to rent a house. Sheila has offered to pay five times Purity’s share of the rent. Rose can
only afford thrice what Purity pays. If Rose’s share is $1,800, what is the total house rent?
A:ReasoningProcess: Wearegiven thatRose’s share oftherentis$1800, andthatRose canonly afford thrice what
Puritypays. There fore, Purity’s share oftherentis1800 /3=$600. Wearealsogiven thatSheila hasoffered topayfive
times Purity’s share oftherent. There fore, Sheila’s share is5*600=$3000. Finally, wehave Rose’s share of$1800,
Purity’s share of$600 andSheila’s share of$3000. There fore, thetotalrentis1800 +600+3000 =$5400. Final answer:
5400.
Q: Padma is trading cards with Robert. Padma started with 75 cards and traded 2 or her valuable ones for 10 of Robert’s
cards. Robert started with 88 of his own cards and traded another 8 of his cards for 15 of Padma’s cards. How many
cards were traded between both Padma and Robert?
A:ReasoningProcess: Padma started with 75cards. Shetraded 2cards for10cards, soshenow has75-2+10=83 cards.
Robert started with 88cards. Hetraded 8cards for15cards, sohenow has88-8+15=95 cards.
Thetotalnumberofcards traded between both Padma andRobert is2+8+10+15=35 cards.
This includes the2cards thatPadma traded for10cards, the8cards thatRobert traded for15cards, andthe10and15
cards thatwere traded between them. Final answer: 35.
Q: Juanita goes through 1 bottle of sunscreen a month. She likes to stock up for the entire year when a certain website
offers 30% off her entire purchase. If each bottle is $30.00 how much will all of the sunscreen cost after the discount?
A:ReasoningProcess: Juanita needs 1bottleofsunscreen amonth, andthere are12months inayear, sosheneeds
12bottlesfortheyear. Thewebsiteisofferinga30% discount onherentirepurchase. Each bottleofsunscreen costs
$30.00. Tofindthetotalcostofthesunscreen afterthediscount, wefirstneed tofindthediscount amount. This isdone
bymultiplyingtheprice perbottlebythediscount rateandthenumberofbottles: $30.00 *0.3*12=$108.00. Next,
weneed tofindtheprice beforethediscount. This isdone bymultiplyingtheprice perbottlebythenumberofbottles:
$30.00 *12=$360.00. Finally, wesubtract thediscount amount from thetotalprice beforethediscount tofindthefinal
price afterthediscount: $360.00 -$108.00 =$252.00. Final answer: 252.
Q: On a three-day trip, Wendy drove 125 miles on the first day, and 223 miles on the second day. How many miles did
she drive on the third day, if the total miles that Wendy drove for the trip is 493 miles?
A:ReasoningProcess: 1.Wendy drove 125miles onthefirstdayand223miles onthesecondday,sothetotalmiles she
drove onthefirsttwodays is125+223 =348miles.
2.Thetotalmiles Wendy drove onthetripis493miles.
3.There fore, theremain ingmiles shedrove onthethird dayis493-348=145miles. Final answer: 145.
Q: Mrs. Lopez and her family are going to the movie theatre. Adult tickets are $11. Children’s tickets (ages 3-12) are $8.
Senior citizen’s tickets (ages 60+) are $9. Mrs. Lopez needs to buy movie tickets for her husband, herself, her parents
(ages 72 and 75), and her three children (ages 7, 10, 14). How much money does she need to buy everyone’s tickets?
A:ReasoningProcess: 1.Mrs. Lopez needs tobuyticketsforherhusband andherself. Thecostforthese ticketswillbe
$11+$11=$22.
2.Mrs. Lopez needs tobuyticketsforherparents, who areseniorcitizens. Thecostforthese ticketswillbe$9+$9=$18.
3.Mrs. Lopez needs tobuyticketsforherthree children, who arebetween theages of3-12.Thecostforthese tickets
willbe$8+$8+$8=$24.
Thetotalcostofalltheticketswillbe$22+$18+$24=$64. Final answer: 64.
Q: Mark has 30 candies, Peter has 25 candies, and John has 35 candies. They decided to combine their candies together
and share them equally. How many candies will each one of them have?
A:ReasoningProcess: 1.Mark has30candies, Peterhas25candies, andJohn has35candies.
2.Weneed toaddthenumberofcandiesthateach personhastofindthetotalnumberofcandiesthey have.
3.So,30+25+35=90candies.
4.Then, weneed todivide thetotalnumberofcandiesbythenumberofpeople,which is3.5.So,90/3=30candies.
Final answer: 30.
Table 9: The exemplars are selected on GSM8K train set. They are transferred to AddSub, SingleEq, SV AMP and
ASDiv.
DATASET Iter-CoT Exemplars
GSM8K Q: Ben’s potato gun can launch a potato 6 football fields. If a football field is 200 yards long and Ben’s dog can run 400
feet/minute, how many minutes will it take his dog to fetch a potato he launches?
A:ReasoningProcess: Tofindthetotaldistance thatthepotato cantravel, weneed tomultiplythenumberoffootball
fields bythenumberoffeetperfootballfield. Since there are3feetperyard, andthere are200yards perfootballfield,
wehave 200*3 =600feetperfootballfield. There fore, thetotaldistance thatthepotato cantravel is6*600 =3600 feet.
Since Ben’s dogcanrunatarateof400feetperminute, itwilltake thedog3600/400 =9minutestofetch thepotato.
Final answer: 9.
Q: Brittany has 3 gerbils: Puffy, Muffy, and Scruffy. Puffy weighs 5 ounces more than Muffy. Muffy weighs 3 ounces
less than Scruffy. If Scruffy weighs 12 ounces, how much would the scale indicate, in ounces, if Brittany put Puffy and
Muffy on the scale?
A:ReasoningProcess: Wearegiven thatScruffy weighs 12ounces andthatMuffy weighs 3ounces lessthan Scruffy.
WearealsotoldthatPuffy weighs 5ounces more than Muffy.
Usingthisinformation, wecancalculatetheweight ofMuffy bysubtracting3ounces from Scruffy’s weight of12ounces,
givingusaweight of12-3=9ounces forMuffy.
Wecanthen calculatetheweight ofPuffy byadding 5ounces toMuffy’s weight of9ounces, givingusaweight of9+5
=14ounces forPuffy.
IfBrittany puts Puffy andMuffy onthescale, thescale would indicateaweight of14+9 =23ounces. Final answer: 23.
Table 10: (Cont.) The exemplars are selected on GSM8K train set. They are transferred to AddSub, SingleEq,
SV AMP and ASDiv.
DATASET Iter-CoT Exemplars
AQuA Q: What number has a 5:1 ratio to the number 11? Options: A:22 B:50 C:55 D:52 E:12
A:ReasoningProcess: Inordertofindthenumberthathasa5:1ratioto11,wefirstneed tounderstand what aratio
means. Aratioisacomparisonoftwonumbers, anditisusuallywrittenintheform ofa:b.Inthiscase, theratiois5:1,
which means thatforevery5units ofthefirstnumber,there is1unitofthesecondnumber.There fore, ifwewant tofind
thenumberthathasa5:1ratioto11,weneed tofindanumberthatis5times larger than 11.Then, wecancheck each of
thegiven options toseeifanyofthem are5times larger than 11.Theonly optionthatfitsthisdescrip tionisC:55. Final
answer: C.
Q: The average of seven numbers is 18. The average of first three numbers is 14 and the average of last three numbers is
23. What is the middle number? Options: A:25 B:27 C:15 D:32 E:34
A:ReasoningProcess: 1.Theaverageoftheseven numbers is18,sothesum oftheseven numbers is18∗7 = 126
2.Theaverageofthefirstthree numbers is14,sothesum ofthefirstthree numbers is14∗3 = 42
3.Theaverageofthelastthree numbers is23,sothesum ofthelastthree numbers is23∗3 = 69
4.Thesum ofthefirstthree numbers andthelastthree numbers is42 + 69 = 111
5.Thesum ofthemiddlenumberandthesum ofthefirstthree numbers plus thelastthree numbers isequal tothesum
oftheseven numbers, inother words, 111 + x= 126 .
6.Themiddlenumberisx= 15 Final answer: C.
Q: Average score for Virat Kohli in a series of 10 matches is 38.9 runs. If the average for first six matches comes out to
be 42 what is his average in the last 4 matches of the series? Options: A:34.25 B:34.28 C:24.252 D:64.28 E:34.21
A:ReasoningProcess: 1)Tofindtheaveragescore forKohli inthelast4matches, weneed tofindthetotalnumberof
runs hescored inthese matches. 2)Weknow thathisaveragescore intheseriesof10matches is38.9 runs. There fore, he
scored atotalof38.9 *10=389runs inthese matches. 3)Wearegiven thathisaveragescore inthefirst6matches is42
runs. There fore, hescored atotalof42*6=252runs inthese matches. 4)Thetotalnumberofruns hescored inthelast
4matches is389-252=137runs. 5)There fore, hisaveragescore inthelast4matches is137/4=34.25 runs. Final
answer: A.
Q: A train runs at the speed of 72 kmph and crosses a 250 metre long platform in 26 seconds. What is the length of the
train ? Options: A:220 metre B:230 metre C:250 metre D:260 metre E:270 metre
A:ReasoningProcess: Weknow thatthetrain crosses a250metrelong platform in26seconds atthespeed of72
kmph. Tofind thelength ofthetrain, weneed tofirst convertthespeed from kmph tom/s, soweusetheformula:
V=Vkmph ×1
3.6.Plugging inthevalues, weget:V= 72 ×1
3.6= 20 m/s. Now thatwehave thespeed inm/s, we
canusetheformula: D=V ttofind thedistance thetrain coversin26seconds. Plugging inthevalues, weget:
D= 20 ×26 = 520 m.Since thelength oftheplatform is250metre,andthetrain covers520metrein26seconds, the
length ofthetrain must be:520−250 = 270 m. Final answer: E.
Table 11: The exemplars are selected on AQuA train set.
DATASET Iter-CoT Exemplars
CSQA Q: Where could a fungus grow and not be disturbed by sunlight? Choices: A.under rocks B.manhattan C.toenails
D.grocery store E.fallen tree
A:Reasoningprocess: 1.Fungi need mois tureandshade togrow. 2.Rocks canprovide both mois tureandshade. 3.
There fore, rocks canbeagood place forfungi togrow withoutbeingdisturbed bysunlight. Final answer: A.
Q: The man wanted to take a bus, but all the chars were full of people doing what? Choices: A.sitting down B.refusing
C.saving money D.sit down E.go outdoors
A:Reasoningprocess: 1.Elim inate answer C("sav ingmoney") because itdoesn’t have anything todowith takingabus.
2.Elim inate answer E("go outdoors") because itdoesn’t make sense forpeopletobeonabusifthey’re already outside.
3.Choose answer A("sittingdown") because it’stheonly remain inganswer thatmakes sense given thecontextclues in
thequestion. Final answer: A.
Q: A beaver can destroy a machines functionality if they build their dam in this? Choices: A.strip club B.pocket
C.millpond D.ontario E.lake or river
A:Reasoningprocess: 1.Abeaver’s dam isbuilt inabody ofwater.2.Amillpond isaman-made pond used fora
watermill. 3.There fore, ifabeaver builds itsdam inamillpond, itcanpotentially destroy thefunctionalityofthe
watermill. Final answer: C.
Q: How might a person address someone who is leaving? Choices: A.further cause B.wave goodbye C.attempt suicide
D.insulting them E.thank god
A:Reasoningprocess: 1.Weknow thatthepersonisleaving,sowecaneliminate answer choices AandCbecause they
don’t make sense incontext. 2.Wecanfurthereliminate answer choice Dbecause it’srude toinsultsome onewho is
leaving.3.That leaves uswith answer choices BandE.4.Outofthese two, themore appropriateoptionwould beB
because it’sacommon way toshow politeacknowl edge ment ofsome oneleaving. Final answer: B.
Q: What is a characteristic of thin glass? Choices: A.break easily B.shattering C.melt D.bend E.hold water
A:Reasoningprocess: A:Break easily-This fitsthecharacteristicofthinglass, asitisknown foritsfragility and
tendency tobreak underpressure. B:Shattering-This could beapossiblecharacteristicofthin glass, butitisnot
mentioned inthegiven choices, sowecannotselectitastheanswer. C:Melt -This does notfitthecharacteristicofthin
glass, asitdoes notneed tobeheated inordertobend orshape it.D:Bend -This does notfitthecharacteristicofthin
glass, asitistoofragiletobebent orshaped withoutbreak ing.E:Hold water-This does notfitthecharacteristicofthin
glass, asitisnotapropertytypically associated with glass. Final answer: A.
Q: What might be the result of a season of successful skiing? Choices: A.finish line B.broken bones C.broken legs
D.chapped lips E.healthy body
A:Reasoningprocess: 1.Aseasonofsuccessfulskiingcould resultinahealthy body ifthepersonisexercisingregularly
andtakinggood care oftheir phys icalhealth while skiing.2.None oftheother options, such asafinishline, broken
bones, orchapped lips, arerelated tothepotentialhealth benefitsofskiing,sothey cannotbethecorrectanswer. 3.
There fore, thecorrectanswer isE.healthy body. Final answer: E.
Q: Glass that hasn’t been treated to be extra strong is what? Choices: A.weak B.fragile C.forceless D.regular E.flimsy
A:Reasoningprocess: 1.Thequestionasks about glass thathasn’t been treated tobeextrastrong. This means thatthe
glass hasnotundergone anyspecialprocesses ortreatments tomake itstronger than usual. 2.Theanswer choices are:
A.weak, B.fragile,C.force less, D.regular,andE.flimsy. 3.Weneed tofindtheanswer choice thatbest describes
glass thathasn’t been treated tobeextrastrong. 4."A.weak" means notstrong. "B.fragile"means easilybroken. "C.
force less" means withoutstrength orpower. "D.regular"means normalorusual. "E.flimsy" means weak andeasily
broken. 5.Based onthese definitions, thecorrectanswer is"B.fragile". Glass thathasn’t been treated tobeextrastrong
islikely tobefragile,oreasilybroken. This isbecause ithasnotundergone anyspecialprocesses tomake itstronger, so
itwillbemore susceptibletobreak ageanddamage. Other words thatmay beused todescribe thistype ofglass include
"delicate" or"brittle". Final answer: B.
Table 12: The exemplars are selected on CSQA train set.
DATASET Iter-CoT Exemplars
StrategyQA Q: Does a Toyota Prius require an anchor in order to park?
A:Reasoningprocess: AToyotaPrius isacar,andanycarneeds tobeanchored totheground inordertopark, unlessit
isparked onaslope. Final answer: Yes.
Q: Did the husband of Elizabeth Hamilton work with a lieutenant?
A:Reasoningprocess: 1.First, weneed toknow who Elizabeth Hamil tonis.Elizabeth Hamil tonwas thewife of
Alexan derHamil ton.
2.Then, weneed todetermine ifAlexan derHamil tonworked with alieutenant. Accordingtohistoricalrecords, Alexan -
derHamil tondidwork with alieutenant named John Laurens duringtheAmer icanRevolutionaryWar.
3.There fore, theanswer tothequestion"Did thehusband ofElizabeth Hamil tonwork with alieutenant?" isYes. Final
answer: Yes.
Q: Would Constantinople survive a hypothetical invasion by Charlemagne?
A:Reasoningprocess: 1.Constantino plewasthecapitaloftheByzan tineEmpire, andCharle magne wastheruler ofthe
Carolingian Empire, which wasinEurope.
2.Constantino plewasawell-fortifiedcitywith strong walls anddefenses.
3.Charle magne wasknown forhismilitaryprowess andconquest.
4.TheByzan tineEmpirewasamajorpower initstime, andConstantino plewasakeystrate giccityfortheempire.
5.How ever, theCarolingian Empirewasalsoamajorpower andCharle magne wasaskilled andexperienced military
leader.
6.Inahypotheticalsituation, Constantino plemay putupastrong resistance against Charle magne’s forces, butitwould
notbeable towithstand asustained attack. Final answer: Yes.
Q: Would King Henry V hypothetically prevail against Charlemagne at Agincourt?
A:Reasoningprocess: 1.First, weneed tounderstand thequestionandidentifythekeyinformation: "Did John Lennon
collaboratewith thefilmmaker behind Walden?"
2.Next, weneed toresearch what Walden isandwho thefilmmaker behind itis:Walden isadocumentaryfilmbyAlan
Watts.
3.With thisinformation, wecannow search forevidence ofJohn Lennon collaboratingwith Alan Watts.
4.Afterconductingresearch, itisclear thatJohn Lennon didcollaboratewith Alan Watts onafilmproject called ’The
Touch ofZen’. Final answer: Yes.
Q: Did John Lennon collaborate with the filmmaker behind Walden?
A:Reasoningprocess: Monks aremem bers ofreligious orders thatusuallytake vows ofpoverty, chastity, andobedience.
These vows aretypically associated with alifeofspiritualcontemplationandnon-violentpursuits. How ever, there are
examplesofmonks engaginginwarfare, such astheKnights TemplarduringtheCrusades andBuddhist Shaolin monks
who have defended temples duringconquests. These examples suggest thatitisnotalways thecase thatmonks are
forbiddenfrom engaginginwarfare. Final answer: Yes.
Q: Could Saint Augustine have read Hamlet?
A:Reasoningprocess: Saint Augustinewasanearly Chris tiansaint who lived about 1,600 years ago.
Ham letisaplay byShake speare which isbelieved tohave been writteninthelate16th century.
Itispossiblethattheplay waswrittenearlierthan thatandperformed forSaint Augustine. Final answer: Yes.
Table 13: The exemplars are selected on StrategyQA train set.
DATASET Iter-CoT Exemplars
Date Understading Q: Yesterday was 12/31/1929. Today could not be 12/32/1929 because December has only 31 days. What is the
date yesterday in MM/DD/YYYY? Choices: A.12/31/1929 B.12/31/1856 C.01/10/1930 D.04/01/1930 E.12/31/1838
F.01/03/1930
A:Reasoningprocess: 1.Weknow thatyesterdaywas12/31/1929.
2.Todaycannotbe12/32/1929 because Decemberonly has31days.
3.There fore, thedate yesterdaymust be12/31/1929. Final answer: A.
Q: The deadline is Jun 1, 2021, which is 2 days away from now. What is the date one week from today in MM/DD/YYYY?
Choices: A.12/06/2021 B.05/30/2021 C.03/07/2021 D.06/05/2021 E.06/06/2021
A:Reasoningprocess: 1.Thedead lineisJun1,2021, which is2days away from now. 2.Jun1,2021 isthedate two
days from now. 3.Adding 7days from thisdate willgive usJun6,2021, which isthedate oneweek from today. 4.
Convertingthisdate intoMM/DD/YYYY format, weget06/06/2021. Final answer: E.
Q: 2015 is coming in 36 hours. What is the date today in MM/DD/YYYY? Choices: A.12/08/2014 B.12/22/2014
C.12/26/2014 D.12/29/1974 E.12/29/2014 F.12/27/2014
A:Reasoningprocess: When wearegiven that2015 iscomingin36hours, wefirstneed todetermine what thecurrent
date is.Weknow that36hours isequal to1.5days, soweneed tosubtract 1.5days from thedate when 2015 arrives,
which is12/31/2014. This means thatthecurrentdate is12/29/2014. Final answer: E.
Q: May 6, 1992 is like yesterday to Jane, but that is actually ten years ago. What is the date one week from today in
MM/DD/YYYY? Choices: A.05/13/2044 B.06/10/2002 C.05/13/2002 D.03/13/2003 E.11/13/2001
A:Reasoningprocess: 1.May 6,1992 istenyears agofrom today, which means todayisMay 6,2002. 2.Thedate one
week from todayisthedate oneweek from May 6,2002. 3.Thedate oneweek from May 6,2002 isMay 13,2002. 4.
Thedate oneweek from todayinMM/DD/YYYY is05/13/2002. Final answer: C.
Q: The current local time is 3:02 pm of 5/4/2004. What is the date tomorrow in MM/DD/YYYY? Choices: A.05/05/1915
B.05/06/2004 C.01/05/2005 D.05/04/2004 E.02/15/2004 F.05/05/2004
A:Reasoningprocess: Thecurrentdate is5/4/2004, andtomorrowisthenext day,which is5/5/2004. This isbecause the
currentmonth isMay andthecurrentdayisthe4th,sothenext dayisthe5th.Theyear remains thesame because weare
only lookingatthedate fortomorrowandnotalonger time period. Final answer: F.
Q: Today is Sep 9, 1909. What is the date today in MM/DD/YYYY? Choices: A.09/09/1939 B.12/11/1909 C.09/09/1909
D.09/30/1909 E.11/19/1909 F.09/09/1886
A:Reasoningprocess: *Thequestionisaskingforthedate todayinMM/DD/YYYY format. *Weknow thattoday’s
date isSeptem ber9,which is09.*Thenext step istofindthecorrectday. Septem berhas30days, sothedate today
is09/30/1909. *How ever, thisisnotcorrectbecause theyear is1909, not1939. *There fore, thecorrectdate todayis
09/09/1909. Final answer: C.
Q: Today is the palindrome day of 2020, because the MMDDYYYY format of the date is the same backwards as forwards.
What is the date 24 hours later in MM/DD/YYYY? Choices: A.02/03/1982 B.02/03/2100 C.02/03/2020 D.02/04/2020
E.02/03/2094 F.01/02/2020
A:Reasoningprocess: Thepalin drome date isoftheform MM/DD/YYYY , anditisthesame when read backwards. The
date oftodayis02/02/2020 andifweread itback wards itisstillthesame, soitisthepalin drome date. Thenext dayis
the02/03/2020 andthepalin drome date ofthedayaftertomorrowisthe02/04/2020. Final answer: C.
Q: The deadline is Jun 1, 2021, which is 2 days away from now. What is the date one week ago from today in
MM/DD/YYYY? Choices: A.05/23/2054 B.05/24/2021 C.04/13/2021 D.05/23/1940 E.05/23/2021 F.05/23/2020
A:Reasoningprocess: Ifthedead lineisJun1,2021, which is2days away, then todayisMay 30,2021. IftodayisMay
30,2021, then oneweek agowasMay 23,2021. Final answer: E.
Table 14: The exemplars are selected on Date Understanding train set.
DATASET Iter-CoT Exemplars
Letter (4) Q: Take the last letters of the words in "Agustin Lowe" and concatenate them.
A:Reasoningprocess: "Agustin Lowe" consists oftwowords, "Agustin" and"Lowe", andeach ofthem has5and4
letters, respectively. Thelastlettersofthese twowords are"n"and"e",respectively. When weconcatenate these two
letters, weget"ne". Final answer: ne.
Q: Take the last letters of the words in "Vern Griffin" and concatenate them.
A:Reasoningprocess: 1.First, weneed totake thelastlettersofeach word in"Vern Griffin". 2.Then weneed toconcate-
nate thelastletterstogetthefinalanswer. 3.Thelastlettersof"Vern" and"Grif fin"are"n"and"n".4.Concatenatingthe
lastletters, weget"nn". Final answer: nn.
Q: Take the last letters of the words in "Randell Graham" and concatenate them.
A:Reasoningprocess: Atthestart ofthematch, Aliceisplayinggoalkeeper, Bob isplayingleftwinger, andClaire
isplayingright midfielder. 1.Take thelastlettersofthewords in"Ran dellGraham" which would be"ll"and"m". 2.
Concatenate them toform "lm". Final answer: lm.
Q: Take the last letters of the words in "Randal Holland" and concatenate them.
A:Reasoningprocess: 1.Weneed tofindthelastlettersofthewords in"Ran dalHolland" 2."Ran dal" ends in"l"and
"Hol land" ends in"d"3.Thelastlettersofthewords in"Ran dalHolland" are"ld" Final answer: ld.
Table 15: The exemplars are selected on Last Letter Concatenation train set.
DATASET Iter-CoT(w/o label) Exemplars
GSM8K Q: In a house, there are 16 cats. Two of them are white, and 25% of them are black. The rest of the cats are grey. How
many grey cats are in this house?
A:ReasoningProcess: Given: Totalnumberofcats=16Num berofwhite cats=2Percentageofblack cats=25% Step
1:Calculatethenumberofblack cats. Num berofblack cats=(25/100) *16=4Step 2:Calculatethenumberofgrey
cats. Num berofgrey cats=Totalnumberofcats-(Num berofwhite cats+Num berofblack cats) Num berofgrey cats
=16-(2+4)=10 Final answer: 10.
Q: Ben starts each day with $50, spends $15 every day and saves the rest. After a few days, his mom doubled his total
savings and his dad gave him an additional $10. If he now has $500, How many days have elapsed?
A:ReasoningProcess: Weknow thatBenstarts each daywith $50andspends $15everyday. So,hisdaily savings can
becalculated as:Daily savings =$50-$15=$35Let´sdenote thenumberofdays thathave elapsed as"d".There fore,
thetotalsavings beforehismom doubled itandhisdadgave himanadditional $10canbecalculated as:Totalsavings
beforemom doubled itanddadgave himanadditional $10=($35 *d)+$10Accordingtothequestion, histotalsavings
afterhismom doubled itandhisdadgave himanadditional $10is$500. So,wecanwrite theequa tion: ($35 *d)*2+
$10=$500 Simplifyingtheequa tion, weget:($70 *d)+$10=$500 Subtracting$10from both sides, weget:($70
*d)=$490 Dividingboth sides by$70, weget:d=$490 /$70Calculatingthevalue ofd,weget:d=7There fore,
approximately 7days have elapsed. Final answer: 7.
Q: There were 600 people in the stadium when the football game started. Before the game was over, one-fourth of the
boys and one-eighth of the girls left early. How many people remained to see the end of the game if there were 240 girls
at the beginning of the game?
A:ReasoningProcess: Tofindouthow many peopleremained toseetheendofthegame, weneed tosubtract thenumber
ofboys who leftearly andthenumberofgirls who leftearly from thetotalnumberofpeopleatthebeginning ofthe
game. Given: Totalpeopleatthebeginning ofthegame: 600Num berofgirls atthebeginning ofthegame: 240First, let’s
calculatethenumberofboys atthebeginning ofthegame: Totalpeopleatthebeginning ofthegame -Num berofgirls at
thebeginning ofthegame =Num berofboys atthebeginning ofthegame 600-240=360Next, let’s calculatehow
many boys leftearly: (1/4) *Num berofboys atthebeginning ofthegame =(1/4) *360=90boys Then, let’s calculate
how many girls leftearly: (1/8) *Num berofgirls atthebeginning ofthegame =(1/8) *240=30girls Finally, tofind
outhow many peopleremained toseetheendofthegame, subtract thenumberofboys who leftearly andthenumberof
girls who leftearly from thetotalnumberofpeopleatthebeginning ofthegame: Totalpeopleatthebeginning ofthe
game -Num berofboys who leftearly -Num berofgirls who leftearly =Num berofpeoplewho remained attheendof
thegame 600-90-30=480 Final answer: 480.
Q: A basketball team played 40 games and won 70% of the games. It still had 10 games to play. How many games can
they lose to win 60% of their games?
A:ReasoningProcess: Tosolve theproblem, weneed todetermine themaximum numberofgames thebasketballteam
canlosetomain taina60% winrate. Step 1:Calculatethetotalnumberofgames played byadding thegames already
played (40) tothegames remain ing(10): Totalnumberofgames =40+10=50games Step 2:Calculatethenumber
ofgames theteam needs towintoachieve a60% winrate: Num berofgames towin=50x60% =30games Step 3:
Calculatethenumberofgames already won: Num berofgames already won =40x70% =28games Step 4:Calculate
themaximum numberofgames theteam canlose: Maximum numberofgames thatcanbelost=Num berofgames to
win-Num berofgames already won =30-28=2games. Final answer: 2.
Q: Jack will have ten times more handball trophies than Michael has right now in three years. If Michael has 30 trophies
right now, and the number of his trophies increases by 100 in three years, what’s the total number of trophies they’ll have
altogether after three years?
A:ReasoningProcess: Given: -Michael currently has30hand balltrophies. -Inthree years, thenumberofMichael’s
trophies willincrease by100. Tofindthetotalnumberoftrophies they’ll have altogether afterthree years, weneed to
calculatethenumberoftrophies Jack willhave inthree years andthen addittothenumberoftrophies Michael will
have inthree years. Since Jack willhave tentimes more hand balltrophies than Michael inthree years, wecancalculate
Jack’s numberoftrophies asfollows: Jack’s trophies inthree years =10*(Michael’s trophies inthree years) =10*(30
+100) =10*130=1300. Now, let’s calculatethetotalnumberoftrophies they’ll have altogether afterthree years: Total
trophies inthree years =Michael’s trophies inthree years +Jack’s trophies inthree years =130+1300 =1430. Final
answer: 1430.
Q: John decides to install a ramp in his house. He needs to get permits which cost $250. After that, he hires a contractor
which costs $150 an hour and the guy works for 3 days at 5 hours per day. He also pays an inspector 80% less to make
sure it is OK. How much was the total cost?
A:ReasoningProcess: Thecostofpermits is$250. Thecontractorworks for3days, with 5hours perday,resultingina
totalof3*5=15hours. Thecontractorcharges $150 perhour, sothetotalcostofhiringthecontractoris15*$150 =
$2250. Theinspectorispaid 80% less, which means heispaid only 20% oftheoriginalcost. So,thecostoftheinspector
is20/100 *$2250 =$450. Tocalculatethetotalcost, weneed toaddthecostofpermits, contractor,andinspector:Total
cost=Cost ofpermits +Cost ofcontractor+Cost ofinspector=$250 +$2250 +$450 =$2950. Final answer: 2950.
Table 16: The exemplars are selected on GSM8K train set. This set of exemplars is used by GSM8K, ASDiv,
SV AMP, and SingleEq.
DATASET Iter-CoT(w/o label) Exemplars
GSM8K Q: Ignatius owns 4 bicycles. A friend of his owns different types of cycles, which have three times are many tires as
Ignatius’s bikes have. He has one unicycle, a tricycle, and the rest are bikes. How many bicycles does the friend own?
A:ReasoningProcess: Ignatius owns 4bicycles, andeach bicyclehas2tires. SoIgnatius hasatotalof4bicycles*2
tires perbicycle=8tires. Thefriend’s cycleshave three times asmany tires asIgnatius’s bikes. There fore, thefriend’s
cycleshave 3*8tires =24tires. Wealsoknow thatthefriend hasoneunicycle(1tire) andonetricycle(3tires). Tofind
outhow many bicyclesthefriend owns, wesubtract thenumberoftires from theunicycleandtricyclefrom thetotal
numberoftires thefriend’s cycleshave: 24tires -1tire(unicycle)-3tires (tricycle)=20tires Since each bicyclehas2
tires, thenumberofbicyclesthefriend owns is20tires /2tires perbicycle=10bicycles. There fore, thefriend owns 10
bicycles. Final answer: 10.
Q: James spends 3 hours vacuuming and 3 times as long on the rest of his chores. How long does he spend on his chores?
A:ReasoningProcess: Tofindouthow long James spends onhischores, weneed toaddthetime hespends vacuuming
(3hours) tothetime hespends ontherestofhischores. Therestofhischores take 3times aslong asvacuuming,sowe
cancalculatethatbymultiplyingthevacuumingtime (3hours) by3.3hours (vacuuming)x3=9hours (rest ofchores)
Now, weaddthevacuumingtime andtherestofthechores time together: 3hours (vacuuming)+9hours (rest ofchores)
=12hours There fore, James spends atotalof12hours onhischores. Final answer: 12.
Table 17: (Cont.) The exemplars are selected on GSM8K train set. This set of exemplars is used by GSM8K, ASDiv,
SV AMP, and SingleEq.
DATASET Iter-CoT(w/o label) Exemplars
AQuA Q: There are a lot of houses such that the numbers of their doorplates are odd numbers and the first number of the
doorplates is 545, the last number of the doorplates is 805. How many houses are there? Options: A)125 B)111 C)101
D)121 E)131
A:Reasoningprocess: Tofindthecount ofhouses with odddoorplate numbers between 545and805, weneed tofindthe
difference between thetwonumbers anddivide itby2(since weareincrement ingby2foroddnumbers) andthen add1
toinclude thefirstnumber.Thedifference between 805and545is260. Dividing260by2gives us130. Adding 1to
include thefirstnumbergives usatotalof131houses. Final answer: E.
Q: The ratio of the radius of two circles is 2: 3, and then the ratio of their areas is? Options: A)1: 8 B)4:9 C)1: 9 D)1: 3
E)1: 2
A:Reasoningprocess: Tofindtheratiooftheareasoftwocircles, weneed tosquare theratiooftheir radii. Given that
theratiooftheradii is2:3,theratiooftheir areaswould be(2ˆ2):(3 ˆ2),which simplifiesto4:9. Final answer: B.
Q: A train passes a station platform in 36 seconds and a man standing on the platform in 20 seconds. If the speed of the
train is 54 km/hr, what is the length of the platform? Options: A)388 B)240 C)88 D)66 E)221
A:Reasoningprocess: Given: -Speed ofthetrain =54km/hr -Train passes astationplatform in36seconds -Train
passes aman stand ingontheplatform in20seconds Let’s denote: -Length ofthetrain as’L’-Length oftheplatform as
’P’When thetrain passes theplatform, itcoversadistance equal tothelength ofthetrain plus thelength oftheplatform.
Distance covered when passingtheplatform =L+PThetrain coversthisdistance in36seconds. Speed =Distance /
Time There fore, (L+P)/36=54km/hr Toconvertkm/hr tom/s, wemultiplyby(5/18): (L+P)/36=54*(5/18) m/s
Simplifying,wehave: (L+P)/36=15m/sSimilarly, when thetrain passes theman, itcoversadistance equal tothe
length ofthetrain. Distance covered when passingtheman =LThetrain coversthisdistance in20seconds. Speed =
Distance /Time There fore, L/20=54*(5/18) m/sSimplifying,wehave: L/20=15m/sNow, wehave twoequa tions:
1)(L+P)/36=152)L/20=15From equa tion2,wecanexpress Linterms ofP:L=20*15=300Substitutingthis
value ofLinequa tion1:(300 +P)/36=15Simplifying,wehave: 300+P=15*36300+P=540P=540-300P=
240There fore, thelength oftheplatform is240meters. Final answer: B.
Q: A fruit seller had some apples. He sells 40% apples and still has 420 apples. Originally, he had Options: A)588 apples
B)600 apples C)672 apples D)700 apples E)None
A:Reasoningprocess: The fruit seller sells 40% ofhisapples andstillhas420apples remain ing.Let’s denote the
originalnumberofapplesasx.Afterselling40% ofx,theremain ingnumberofapplesis0.6x. Accordingtothegiven
information, 0.6x =420. Tofindthevalue ofx,wedivide both sides oftheequa tionby0.6:x=420/0.6=700. Final
answer: D.
Table 18: The exemplars are selected on AQuA train set.
DATASET Iter-CoT(w/o label) Exemplars
CSQA Q: The Coast Guard is a police force that often does what? Choices: A.board vessels B.direct traffic C.ocean D.force law
E.arrest
A:Reasoningprocess: TheCoast Guard isabranch ofthemilitarythatisrespon sibleformaritime lawenforce ment and
search andrescueoperations. They areofteninvolved inactivitiesrelated totheseaandvessels. Among theoptions
provided, themost suitable answer isA.board vessels. The Coast Guard frequently boards vesselsforinspections,
investigations, andenforce ment ofmaritime laws andregulations. Final answer: A.
Q: Where do I store folding chairs for religious experiences? Choices: A.closet B.church C.room D.basement E.garage
A:Reasoningprocess: Todetermine thebest optionforstoringfoldingchairs forreligious experiences, weneed to
consider thespecific require ments andcontextofreligious activities. OptionA:Closet -This could beaviable choice
ifthere isadedicated closet within thereligious establishment specif ically forstoringfoldingchairs. Itwould ensure
thatthechairs areeasilyaccessibleandorganized. OptionB:Church -While achurch may have designated areasfor
storingchairs, such asastorageroom orbasement, itmay notbethemost suitable choice ifthereligious experiences
areheld inother locations outside ofthechurch. OptionC:Room -This optionisquite generic andlacks speci ficity.
Itcould potentially beasuitable choice ifthere isadedicated room within thereligious establishment specif ically for
storingfoldingchairs. OptionD:Base ment -SimilartooptionB,abasement could beasuitable choice ifthereligious
establishment hasadedicated basement area forstoringchairs. How ever, ifthereligious experiences areheld inother
locations, thismay notbethemost practicaloption. OptionE:Garage -Storingfoldingchairs inagarage may notbe
ideal forreligious experiences asitistypically used forparkingvehiclesandmay notprovide asuitable andorganized
space forthechairs. onsideringthevariousoptions, themost suitable choice forstoringfoldingchairs forreligious
experiences would beA.closet. This optionensures thatthechairs areeasilyaccessibleandorganized within thereligious
establishment. Final answer: A.
Q: What might people do to protect their legs from getting dirty on the farm? Choices: A.wear jeans B.milk cow
C.believe in god D.avoid mud E.plant flowers
A:Reasoningprocess: Toprotecttheir legs from gettingdirty onthefarm, peoplecantake severalmeasures. Let’s
analyze theoptions provided: A.wear jeans -This optionseems likeapracticalchoice asjeans areknown fortheir
durabilityandabilitytoprovide protectionagainst dirtandmud. B.milk cow -While milkingacow isacommon farm
activity,itdoes notdirectly address thequestionofprotectinglegsfrom gettingdirty. C.believe ingod-This option
does notappear toberelevant toprotectinglegsfrom gettingdirty onthefarm. D.avoid mud -Avoid ingmud canbea
preventivemeasure, butitmay notalways bepossibleorpracticalonafarm. E.plant flowers-Plant ingflowersdoes not
address thequestionofprotectinglegsfrom gettingdirty. Final answer: A.
Q: What may jogging make you feel like? Choices: A.increased heart rate B.improved health C.frightened D.shin splints
E.being tired
A:Reasoningprocess: When yougojogging, your heart ratetypically increases asyour body works harder tomeet the
demands oftheexercise. So,optionA(increased heart rate) seems likeaplausiblechoice. Jogging isalsoknown tohave
numeroushealth benefits,such asimprovingcardiovascularfitness, strength eningmuscles, andaidinginweight loss.
There fore, optionB(improved health) isalsoalikely option. How ever, jogging isnottypically associated with feelings
ofbeingfright ened orexperiencingshin splints. Shin splints areacommon overuse injurythatcanoccurduringrunning
orhigh-impact activities, butthey arenotdirectly related tojogging itself. Lastly, jogging canoftenlead tofeelings of
tiredness, especially ifyoupush yourselfandexertalotofenergy duringtheactivity.So,optionE(beingtired) isa
reasonable choice aswell. Final answer: E.
Q: The best way to cure boredom at a high elevation with no buildings around is to do what? Choices: A.do crossword
puzzle B.go skiing C.play games D.hang out at bar E.sleep
A:Reasoningprocess: Inahigh elevation with nobuild ings around, thebest way tocure boredom would betogo
skiing.Skiingisapopularrecre ational activitythatcanbeenjoyed inmoun tainousareas,especially athigh elevations. It
provides anexhilaratingexperience andallows youtomake themost ofthenaturalsurround ings. Final answer: B.
Q: Where is an inexpensive place to have a reception? Choices: A.outside B.wedding party C.restaurant D.church
basement E.country club
A:Reasoningprocess: Based onthegiven choices, themost inexpensiveoptionforhavingareceptionwould likely bea
church basement. Church basements areoftenavail able foralower costoreven forfreeformem bers ofthechurch or
community. This makes them abudget-friendly optionforhostingevents such aswedding receptions. Final answer: D.
Q: Where does the red cross respond to a storm? Choices: A.summer B.tropics C.blue shield D.weather report E.america
A:Reasoningprocess: The correctanswer isE.Amer ica.The Red Cross responds tostorms invariouslocations,
includingtheUnited States, where they provide assistance andsupport duringnaturaldisasterssuch asstorms and
hurricanes. Final answer: E.
Table 19: The exemplars are selected on CommonSenseQA train set.
DATASET Iter-CoT(w/o label) Exemplars
STQA Q: Is the Antarctic Peninsula south of the Equator?
A:Reasoningprocess: TheAntarc ticPenin sulaislocated atthesouth ernmost partoftheEarth, which means itisinthe
south ernhemi sphere. TheEqua torisanimag inary linethatdivides theEarth intothenorth ernandsouth ernhemi spheres.
There fore, since theAntarc ticPenin sulaislocated inthesouth ernhemi sphere, itissouth oftheEqua tor. Final answer:
Yes.
Q: Is lunch on the beach a good activity to spot the full circle of a rainbow?
A:Reasoningprocess: First, toseearainbow, youneed tobeoutsideintherainornear asource ofwater.Ifyouareon
thebeach, youarelikely tobenear asource ofwater,sothatcriterion issatisfied. Second, youneed tohave thesun
shining.Ifyouarehavinglunch onthebeach, youarelikely tobethere duringthedaytime, when thesunisshining,so
thatcriterionisalsosatisfied. Third, youneed tohave theright anglebetween thesun, your eyes, andthewaterdroplets
intheair.This isabitharder topredict, butiftheconditions areright, youshould beable toseearainbow. How ever, as
mentioned inthepreviousanswer, thefullcircleofarainbow cannotusuallybeseen from ground level, andlunch onthe
beach occurs atmiddaywhen thesunislikely high inthesky.There fore, itisunlikely thatyouwould beable toseethe
fullcircleofarainbow from thebeach duringlunch. Final answer: No.
Q: Were any of the characters in Macbeth played by an Oscar-winning actor?
A:Reasoningprocess: Toanswer thequestion, weneed toresearch theactorswho have played thecharactersinMacbeth
andfindoutifanyofthem have won anOscar.Some ofthecharactersinMacbeth have been played byOscar-winning
actors. Forinstance, thecharacterofMacbeth hasbeen played byactorssuch asLaurence Olivier, OrsonWelles, and
Michael Fassbender,allofwhom have won Oscarsfortheir performances inother roles. Final answer: Yes.
Q: Are monks forbidden from engaging in warfare?
A:Reasoningprocess: Monks aremem bers ofreligious orders thatusuallytake vows ofpoverty, chastity, andobedience.
These vows aretypically associated with alifeofspiritualcontemplationandnon-violentpursuits. How ever, there are
examplesofmonks engaginginwarfare, such astheKnights TemplarduringtheCrusades andBuddhist Shaolin monks
who have defended temples duringconquests. These examples suggest thatitisnotalways thecase thatmonks are
forbiddenfrom engaginginwarfare. Final answer: No.
Q: Does Post Malone have a fear of needles?
A:Reasoningprocess:We know thatPost Maloneisapersonbecause thequestionstates thatheisaperson. Peoplecan
have fears because itisacommon human trait tohave fears ofvariousthings. Thefearofneedles isacommon fear
among peoplebecause needles cancause pain, discomfort, andanxietyformany people.How ever, thefactthatPost
Malonehasmany tattoos onhisbody suggests thatheiscomfortable with needlesandthere foredoes nothave afearof
needles. Additionally, thefactthatthemost common method oftattooinginvolves electrictattoomachines andmultiple
needlessuggests thatPost Malonehasbeen exposed toneedlesmany times andhasnotshown anyfearordiscomfort.
There fore, itisunlikely thatPost Malonehasafearofneedles. Final answer: No.
Q: Can you get negative effects from a placebo?
A:Reasoningprocess: Place bosaresubstances ortreatments thathave notherapeuticeffect, andareoftenused inmedical
trialsasacontrolgroup tocompare theeffects ofarealtreatment. Since place bosthem selves have noactiveingredients,
itisunlikely forthem tocause negativeeffects ontheir own. How ever, itispossibleforapersontoexperience negative
effects from aplacebo duetothenocebo effect. This occurs when apersonbelieves atreatment tobeharm ful,even
though ithasnoactiveingredients, andthey experience negativesideeffects asaresultoftheir expectations andbeliefs
about thetreatment. Itispossibleforapersontoexperience negativeeffects from aplacebo duetothenocebo effect.
Final answer: Yes.
Table 20: The exemplars are selected on StrategyQA train set.
DATASET Iter-CoT(w/o label) Exemplars
Date Understading Q: This is the last day of 1899. What is the date one week ago from today in MM/DD/YYYY? Choices: A.12/24/1802
B.12/24/1899 C.12/17/1899 D.01/02/1900 E.03/12/1900 F.05/24/1900
A:Reasoningprocess: Tofindthedate oneweek agofrom today, weneed tosubtract 7days from thelastdayof1899,
which isDecember31,1899. Subtracting7days from December31,1899, wegetDecember24,1899. Final answer: B.
Q: Today is the last day of the first quarter of 2008. What is the date a month ago in MM/DD/YYYY? Choices:
A.02/01/2008 B.12/26/2007 C.02/28/2008 D.02/29/2008 E.02/08/2008 F.08/29/2008
A:Reasoningprocess: Tofindthedate onemonth agofrom thelastdayofthefirstquarterof2008, weneed tosubtract
onemonth from March 31,2008. Since Febru aryonly has29days inaleap year, wecancalculatetheanswer is
02/29/2008 Final answer: D.
Q: Jane and John married on Jan 2, 1958. Today is their golden wedding anniversary. What is the date yesterday in
MM/DD/YYYY? Choices: A.02/03/2008 B.12/27/2007 C.01/02/2008 D.12/31/2007 E.01/01/2008
A:Reasoningprocess: Jane andJohn marriedonJan2,1958. Todayistheir golden wedding anniver sary, which means
they have been marriedfor50years. Tofindthedate yesterday,weneed tosubtract onedayfrom thecurrentdate. Given
thattodayisJan2,2008, thecorrectanswer is:01/01/2008. Final answer: E.
Q: Today is 3/5, and it is Jane’s second time in the year 1973 to see a meteor shower. What is the date 24 hours later in
MM/DD/YYYY? Choices: A.03/02/1973 B.03/06/1973 C.04/05/1973 D.01/02/1973 E.03/05/1972 F.03/08/1983
A:Reasoningprocess: Todayis3/5,andwewant tofindthedate 24hours later. Adding 24hours to3/5would give us
3/6. Final answer: B.
Q: Jane thinks today is 6/18/2019, but John thinks today is 6/19/2019. Jane is correct. What is the date one year ago from
today in MM/DD/YYYY? Choices: A.06/17/2018 B.06/19/2018 C.06/13/2018 D.05/23/2018 E.07/09/2018 F.06/18/2018
A:Reasoningprocess: Tofindthedate oneyear agofrom today, wesubtract 1year from thecurrentdate. Given that
todayis6/18/2019, oneyear agowould be6/18/2018. Final answer: F.
Q: Jane scheduled 3 apointments with 5 poeple for tomorrow (Tue, 7/9/1972). What is the date one year ago from today
in MM/DD/YYYY? Choices: A.07/09/1971 B.07/15/1971 C.07/08/1910 D.07/01/1971 E.07/07/1971 F.07/08/1971
A:Reasoningprocess: Tofindthedate oneyear agofrom today,weneed tosubtract 1year from thegiven date, which is
July 9th,1972. Final answer: A.
Q: In the US, Thanksgiving is on the fourth Thursday of November. Today is the US Thanksgiving of 2001. What is
the date one week from today in MM/DD/YYYY? Choices: A.11/30/2002 B.11/29/2078 C.12/27/2002 D.12/11/2002
E.11/29/2002 F.11/15/2002
A:Reasoningprocess: TheUSThanks givingin2001 wasonNovem ber22nd. Adding oneweek tothatdate, weget
Novem ber29th. Final answer: E.
Q: The current local time is 3:02 pm of 5/4/2004. What is the date tomorrow in MM/DD/YYYY? Choices: A.05/05/1915
B.05/06/2004 C.01/05/2005 D.05/04/2004 E.02/15/2004 F.05/05/2004
A:Reasoningprocess: Thecurrentlocaltime is3:02 pmof5/4/2004. Tofindthedate tomorrow, weneed toaddoneday
tothecurrentdate. Since itisalready 3:02 pm,tomorrow’s date willbethesame asthecurrentdate until3:02 pm.After
3:02 pm,itwillbethenext day. Final answer: F.
Table 21: The exemplars are selected on Date Understanding train set.
DATASET Iter-CoT(w/o label) Exemplars
Letter(4) Q: Take the last letters of the words in "Keith Ruiz" and concatenate them.
A:Reasoningprocess: 1)Thelastlettersof"Keith Ruiz" are"h"and"z".2)Concatenatingthese lettersgives us"hz".
There fore, thecorrectanswer is:hz. Final answer: hz.
Q: Take the last letters of the words in "Saul Moss" and concatenate them.
A:Reasoningprocess: Let’s take thelastlettersofeach word in"Saul Moss": -Thelastletterof"Saul" is"l".-Thelast
letterof"Moss" is"s".Now, let’s concatenate them: -"l"+"s"="ls" Final answer: ls.
Q: Take the last letters of the words in "Morton Stanton" and concatenate them.
A:Reasoningprocess: Takingthelastlettersofeach word in"Mor tonStanton" andconcatenatingthem, wehave: n
(from Morton)n(from Stanton) Final answer: nn.
Q: Take the last letters of the words in "Drew Barnett" and concatenate them.
A:Reasoningprocess: Takingthelastlettersofthewords "Drew" and"Barnett", wehave "w"and"t"respectively.
Concatenatingthem gives us"wt". Final answer: wt.
Table 22: The exemplars are selected on Last Letter Concatation(4) train set.
