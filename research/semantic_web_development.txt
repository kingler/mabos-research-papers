 
Semantic Web Development
Technical Proposal
February 4, 2000
BAA 00-07
Program title:
DAML
Proposal title:
Semantic Web Development
Prime offeror:
Massachusetts Institute of Technology Laboratory for Computer Science andWorld Wide Web Consortium
Principal Investigator:
Tim Berners-Lee, MIT W3C< timbl@w3.org
>
Co-Principal Investigators:
David R. Karger < Karger@mit.edu >, Lynn Andrea Stein < las@lcs.mit.edu >, Ralph
R. Swick < swick@w3.org >, Daniel J. Weitzner < djweitzner@w3.org >
Sub contractors:
Two to three individuals acting as MIT staff.
Technical Contact:
Ralph R. Swick, < swick@w3.org >
Administrative Contact:
Paul Powell, < ppowell@mit.edu >
Type of business:
Educational
Duration of effort:
4.25 yearsPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
1 of 52 11/5/09 10:07 AM
A. Executive Summary
When the World Wide Web was proposed a decade ago it was envisioned not only as
a medium for human communication but also one of machine communication. Thesecond half of that hope is as yet unrealized, with the frustrating result that vastamounts of data available to the human enquirer cannot practically be analysed andcombined by machine. At the outset of the Web, the ﬁeld of hypertext was one which
had shown much initial promise but little wide scale deployment. Its conversion to aglobal scalable system was to change that. In the meantime, much work in knowledgerepresentation (KR) -- in ontology, interchange languages, and agent infrastructure --has demonstrated the viability of KR as a basis for agent interaction whilesimultaneously highlighting the importance of support for heterogeneity anddecentralization. At present, the ﬁeld of knowledge representation has shown much
initial promise but little truly widespread deployment.
The Semantic Web concept is to do for data what HTML did for textual information
systems: to provide suf ﬁcient ﬂexibility to be able to represent all databases, and logic
rules to link them together to great added value. The ﬁrst steps in this direction were
taken by the World-Wide Web Consortium ( W3C
) in de ﬁning Resource Description
Framework (RDF)  [Lassila et al. 1999], a simple language for expressing relationships in
triples where any of the triple can be a ﬁrst class web object. This basis has the
decentralized property necessary for growth. The proposed project is to utilize anddemonstrate the great power of adding, on top of the RDF model (modi ﬁed as
necessary) the power of KR systems. We refer to this augmented language as theSemantic Web Logic Language, or SWeLL.
We propose to build on the DARPA Agent Markup Language (DAML) infrastructure
to provide precisely such an interchange between two or more rather different kinds ofapplications. The ﬁrst of these involves structured information manipulations required
to maintain the ongoing activities of an organization such as the W3C, including accesscontrol, collaborative development, and meeting management. In the second, we willaddress the informal and often heuristic processes involved in document managementin a personalized information environment. Integrated into both environments will betools to enable authors to control terms under which personal or sensitive informationis used by others, a critical feature to encourage sharing of semantic content.
Optionally, we will also explore applications to spoken language interfaced discoursePROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
2 of 52 11/5/09 10:07 AM
systems, automation and automated application construction, and intentional naming
of networked resources (by function rather than by a ﬁxed naming scheme). By using
the uniform structure of the Semantic Web in each of these applications, we willdemonstrate the ability of this technology to build bridges between heterogeneouscomponents and to provide next-generation information interchange.
The Internet being a medium whose level of inherent security is very low, it is
expected that digital signature technology will be essential in verifying the stepsinvolved in most discussions. Indeed, the fundamental rules controlling input to asystem will not simply be logic, but will combine semantics with the security of digitalsignature. The project's access control system will employ digital signature. We expectto incorporate digital signature in a way consistent with industry work on digitalsignature for Extensible Markup Language (XML) [Eastlake].
The project will involve the creation of interoperating systems to prototype the
Semantic Web ideas. These will necessarily include simple tools for authoring,browsing, and manipulating the language underlying these applications, as well as thesystems themselves.
The work will be deployed along three axes: by adoption by W3C staff internally and
by partners such as LCS Oxygen and other DAML participants; by disseminationthrough and codevelopment with the Open Source community, and when appropriate,by facilitation of consensus around interoperable standards for the Semantic Web usingthe W3C processs.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
3 of 52 11/5/09 10:07 AM
B. Innovative Claims and Program Vision
This project is a key move in the transition to a Semantic Web  software and
information environment, in which complex applications can interoperate byexchanging information with a basis in high level logic and well-de ﬁned meaning. The
project is constructed from software modules which, while performing quite dissimilarfunctions, exchange information using the languages of the Semantic Web, includingthe DARPA Agent Markup Language (DAML). The project will form a practical testbedof these ideas. If successful, it will also provide a model to lead both military andcommercial development in the future, generating a critical mass of existing systems onthe Semantic Web to trigger wide growth of the technology.
We are particularly concerned with information management and information ﬂow
on the Semantic Web. Two contrasting subsystems are proposed as the essential basis ofour development, with a number of optional projects. One system is an organizationalmanagement system which implements the social and managerial processes -- the"social machines" of an organization, the World Wide Wide Consortium (W3C). Thissystem uses well-de ﬁned logical algorithms to implement such things as resource
management (meeting planning, calendars, etc.), secure web-site access control, andtools to enable individuals to control use of personal information contributed to theSemantic Web. The W3C's "Live Early Adoption and Demonstration" policy of using itsown technology makes it a particularly appropriate testbed.
The other central system is a personal and group information system based on our
previous Haystack
 work. Haystack [Adar et al.] is a personal information environment:
It stores a particular individual's documents and other on-line information, togetherwith automatically generated annotations concerning the context in which theinformation is encountered, providing content- and context-based retrieval. Haystackalso uses heuristic algorithms to analyze personal activity to ﬁnd patterns and relevant
resources within a user's information environment, making it an interesting contrast tothe more deliberative W3C systems. While the two systems differ on a scale from secureenforcement of rigid policy to enhanced guesswork about relevant material, they sharean internal model for the storage of information which maps well onto the XML-basedResource Description Framework (RDF) developed by W3C. This makes these twosystems excellent candidates for integration using Semantic Web techniques. Using RDFto interchange raw data and higher level logic languages to be developed within theDAML community for the exchange of inference rules, the crucial step is to gain addedPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
4 of 52 11/5/09 10:07 AM
value from interoperability at the semantic level.
In the past, such interworking would have only operated at the level of raw data.
While the systems would have been able to share, for example, the fact that a personwas a member of a group, they would not have been able exchange the reason why. Toask why is to ask for a justi ﬁcation -- a series of steps by which the fact was derived.
The Semantic Web Logic Language (SWeLL) -- part of the DAML family -- will allowthis justi ﬁcation to be passed between systems.
The World Wide Web currently links a heterogeneous distributed decentralized set of
systems. Some of these systems use relatively simple and straightforward manipulationof well-characterized data, such as an access control system. Others, such as searchengines, use wildly heuristic manipulations to reach less clearly justi ﬁed but often
extremely useful conclusions. In order to achieve its potential, the Semantic Web mustprovide a common interchange language bridging these diverse systems. Like HTML,the Semantic Web language should be basic enough that it does not impose an undueburden on the simplest web software systems, but powerful enough to allow moresophisticated components to use it to advantage as well.
The Semantic Web, then, will serve as an interchange "bus" for on-line data. In effect,
it will allow any web software to read and manipulate data published by any other webPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
5 of 52 11/5/09 10:07 AM
software. SWeLL will enable this interchange. The pairing of simple, predictable,
reliable systems with complex, unpredictable, heuristic systems is one of the novelpossibilities opened by the Semantic Web. This combination of systems is new groundwhich this project will speci ﬁcally explore.
In importing structured information into a heuristic system such as Haystack, we are
able to enhance the operation of the heuristic system. The Haystack system currentlylooks at the contents of documents, and a user's interactions with them, in order todetermine things such as subjective "quality" and relevance". Imagine now that allinformation available to the user from the W3C administrative system is imported intoHaystack. The Haystack inference engines will be able to ﬂow semantic links through
the social structure and be able to include concepts of W3C documents status. Theinformation space is much richer. When before two documents might have seemedsyntactically related, the versioning system might reveal that one was in fact an earlierversion of the other. The structured information imported from W3C is also enhancedby being integrated into the semantic network of a haystack, making it addressablethrough the heuristic retrieval machinery built into Haystack.
In the other direction there are at least two interesting ways in which heuristic
systems can export information -- through the semantic web -- to hard logical systems.In one case, a heuristic is used to ﬁnd a solid argument, which can then be directly
accepted by the logic system (e.g., using the proof veri ﬁer). In the other, a heuristic
system (such as a search engine) cannot logically justify its results, but has achievedsuch a level of success that those results are authorized for input into an otherwisestrictly logical system as hard data. In this case, the accepting system is simply takingthe heuristic system's word for it, rather than analyzing the justi ﬁcation further. Digital
signature here plays a crucial role in ensuring the validity of such assertions. Personalinformation management schemas will create a trusted environment in which authorsof semantic content will be willing to open their metadata to other's haystacks.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
6 of 52 11/5/09 10:07 AM
C. Software Components Proposed
The research goals set out in Section B require the design of software components to
enable users and their machines to interact with metadata on the Semantic Web. Thesenew Semantic Web tools will be designed with an eye toward general application, buttargeted initially toward the two testbed environments of this project: SemanticWeb-based W3C organizational tools and Haystack interfaces with the Semantic Web.
W3C Organizational Tools
The W3C operation is distributed globally with over 380 Member organizations.
With over 50 active working groups including participants from hundreds of memberrepresentatives, numerous documents in being edited by many collaborators, activeonline publishing of these documents are various stages of maturity, the W3C makes anideal testbed for development of decentralized Semantic Web tools. As the Webcommunity at-large depends heavily on the technical information presented at the W3Csite, these tools will also be tested by the pressures of the public Web.
We propose to build a suite of Semantic Web-powered tools to assist in the
management of and participation in the W3C's work. The basic functions of the toolswill include:
Semantic content authoring tools
SWeLL-based proof generators
SWeLL-based proof validators
Access control: controlling access to documents on various parts of the W3C site
Personal INformation Schema (PINS) controls: using DAML and SWeLL, users
will be able to attach conditions to use and re-use of information they contributeto the Semantic Web
Our plans to build organizational management tools with Semantic Web components
is illustrated by our proposed approach to access control. Employees of W3C Memberorganizations are granted access to portions of the W3C Web site that may differ fromthe access granted to non-Members. Today, W3C webmasters maintain severaldatabases to manage access permissions for all members. Using Semantic Web tools, wewish to delegate to the Member company primary contact and to the chairs of theworking groups the authority to authorize individuals to join restricted maildistribution lists, to publish Web pages at speci ﬁc locations on the W3C Web site, to
register for meetings and workshops, and to access materials on other parts of the WebPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
7 of 52 11/5/09 10:07 AM
site. This delegation must be done by following a chain of assertions regarding the
resources being access controlled and the individuals whose access is being authorizedor veri ﬁed. To enable this the software components required include:
A web browser or a http proxy modi ﬁed to send proofs of access (these will likely
be based on the Open Source W3C Amaya or Mozilla and W3C Jigsaw platforms);
An application for generating access proofs in simple cases for that browser;
A web server modi ﬁed to accept SWeLL access justi ﬁcations;
A generic SWeLL proof checker employed as access veri ﬁer by that server;
A version of that checker modi ﬁed to include XML Digital Signature veri ﬁcation.
A PINS tool for managing working group membership information while
preserving social constraints.
In addition to the access control system, we will use the Semantic Web tools as
building blocks to help bring functions such as document version management, issuetracking, personal information management, and event scheduling.
Haystack
The Haystack system supports the storage, organization, retrieval, and (eventually)
sharing of an individual's documents and other knowledge. Haystack was designedwith a rich data representation that is quite similar to the RDF data model. Haystackalready contains numerous tools that gather information about the user into this datamodel, as well as tools for modifying, searching and navigating this data model. Muchof the data within Haystack is generated by automated services that "reason" aboutextant data in order to generate new data.
We will augment Haystack to import data from and export data to the Semantic Web.
As numerous applications begin to make their information available in the SemanticWeb format, it becomes easy for Haystack to import this information to augment itsuser's information space. And because of the similarity of Haystack's model to RDF, it isalso easy for Haystack to export its own information for access by other Semantic Webenabled systems. This requires two basic tools:
A Semantic Web parser for Haystack
A tool that exports Haystack data to the Semantic Web, providing URIs for
internal Haystack objects
Haystack is designed as a personal  information repository; we therefore expect and
hope that over time each Haystack will develop a specialized vocabulary of metadataPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
8 of 52 11/5/09 10:07 AM
tuned to its own user. This makes the exchange of information challenging, both
between multiple Haystacks and between Haystack and other tools that do not haveknowledge of this specialized metadata. The Semantic Web will provide the mechanismfor this information exchange. We propose the following components.
A component that exports the "meaning" of a user's specialized metadata for use
by other systems
A component that imports Semantic Web assertions and uses them to convertexternal data to conform to the Haystack user's specialized metadata.
A component that exports proofs explaining why a given piece of information is
present in a Haystack, so that other visiting Haystacks can decide whether theytoo would like to believe that piece of information.
While the Semantic Web will support the exchange of information from different
vocabularies, human assistance will be required to de ﬁne those vocabularies and the
connections between them. Users will need tools to de ﬁne their own metadata
structures for others. And they will need to examine others' metadata structures inorder to relate them to their own. We propose the following components.
An authoring tool that will let users describe their metadata and the rules their
Haystack uses to generate it.
A browsing tool that lets users examine the Semantic Web information at anothersite and guide their Haystack in relating that information to their own metadata.
General Shared Components
Haystack will also exploit the general purpose components being designed for the
Semantic Web. We will specialize the following components for use in Haystack.
The proof constructor will be used to explain how certain Haystack information
was generated. This will require augmenting the proof system with fuzzy notionsof relevance.
The proof veri ﬁer will be used (essentially unchanged) to decide whether to make
use of proofs generated by other systems
The access control system described previously will be used to limit the sharing ofHaystack's information to authorized individuals.
Personal Information Management Preferences
In order to encourage users to share semantic content, we will provide a PersonalPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
9 of 52 11/5/09 10:07 AM
Information management Schema (PINS) tool to enable users to attach usage
restrictions to information, especially personalized information, made part of theSemantic Web. The tools that enable users to interact with Semantic Web content will beaware of these preferences and help users' applications to follow the permissionsattached to metadata by its original creator.
Full Oxygen Integration Option
As an option, we propose to explore strategies for integrating the Semantic Web tools
developed in the early phase of this project with the LCS Oxygen Project. WhileHaystack, an Oxygen component, is already a leading part of this DAML initiative, wepropose to create links between this and other Oxygen components including tools totake advantage of advanced work on speech, automation, and networking.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
10 of 52 11/5/09 10:07 AM
D. Technical description
The power and explosive growth of the World Wide Web is based on two very simple
concepts; a way of creating names for anything that is accessible on the Internet and theone-way navigational  link from a document to such a nameable thing. These
navigational links direct the readers' attention to other Internet resources, but they donot capture the author's reason for having created the link. To capture such arelationship, today's web authors use natural language, making such information allbut inaccessible to automated processing.
Over time, a community builds up a shared vocabulary for the concepts with which
it works. Separate communities that have similar experiences will have commonconcepts but different vocabularies. In the Semantic Web, we will use the naming powerof the World Wide Web to attach names to the concepts as used by each community andwe will have a new kind of link -- a link with meaning -- that describes the relationshipsbetween the names used by one community and the names used by another. Thus, theSemantic Web will contain bridges between these islands of local (community)vocabulary and will enable extended information access across community boundaries.
An important feature provided by the Semantic Web is the ability to respond to the
query "What is the basis for that statement?"; to help a user to answer the question "Do Ibelieve that?", or alternatively, "How much risk is there to my achieving my objectives ifI act on the basis of that statement?". The language of the Semantic Web must thus beable to represent information destined for automated processing. Resource DescriptionFramework (RDF) is a existing industry language which will form the basis for thislanguage, which we refer to as SWeLL, the Semantic Web Logic Language. RDF is aﬂexible and general language for the expression of assertions and allows the exchange
of raw facts between heterogeneous systems (see diagram).
Example: Simple Search Made Sensible
We provide an example illustrating how the Semantic Web permits bridges between
the vocabularies developed by independent communities.
Today, we might ask "What is bmw7's power?" and get no answer back because
BMW's web page gives the answer in German terminology. With the Semantic Web, wemight retrieve an answer based on heuristically driven classical logic:
What is bmw7's power?PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
11 of 52 11/5/09 10:07 AM
search( bmw7, power, x ) yields a nil result1.
search( bmw7, subclass, x ) yields x=beamer, car, thing2.
search( beamer, power, x ) yields a nil result3.
search( power, equivalent, x ) yields x=Macht4.
search( bmw7, Macht, x ) yields x=160kw5.
deduce( bmw7, power, 160kw )6.
The bmw7's power is 160kw.
And, of course, the Semantic Web allows us to investigate further:
Why?
Because power is the same as Macht and the catalog from BMW says the Macht
of the bmw7 is 160kw.
In general, individual queries to the Semantic Web will be very specialized
circumscribed requests made by special-purpose applications. Want-to-buy requests,invoices, web searches, and even check-writing are each examples of such transactions.These Semantic Web applications do not rely on the full power of SWeLL to make theirrequests. And, when processing these requests, the ful ﬁlling applications will likely use
heuristics or restricted inference rules in order to answer the requests. Inference enginestypically have a query language specially designed to constrain the question so that theanswer can be produced in a tractable fashion. This is how most systems, including thecomponents of this project, work. However, interchange between components can beembedded in a suf ﬁciently general language to ensure that virtually any components
have the potential to interoperate over the Semantic Web.
Logic of Authority
In practice -- in a distributed decentralized world -- some sources will be more
reliable (on some topics) than others and different sources may even assert mutuallycontradictory information. RDF is based on XML for which digital signature standardsare expected to emerge early in the life of this project. XML Digital Signature will beused to provide an authentication component in this project. SWeLL processors willgenerally be aware of the source and authority for each piece of information.Information will be processed differently as a function of trust in its source.
It is not enough for facts to be shared between different data systems, or even for
signed data to be shared. Several logic-based languages have been used with somesuccess as knowledge interchange languages (e.g. SHOE, KIF, etc.). In these systemsPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
12 of 52 11/5/09 10:07 AM
RDF-like facts are augmented with rules that combine logical information with
directives for effecting inference. Such directives are not always exchangeable betweendifferent types of KR systems, but the logical relationships must be expressible inSWeLL. For this, SWeLL extends RDF by including negation and explicit quanti ﬁcation.
But to achieve its full potential, the Semantic Web must do more. The Semantic Web
is composed of heterogeneous systems. No real system can answer every possiblequestion about its data (i.e. none can compute the deductive closure of its information).Different systems make different compromises, affording different sets of inferences.For this reason, one application will often be able to reach a particular conclusion whenanother does not.
In the general case, one piece of software will need to be able to explain or justify to
another why its assertions ought to be accepted. This allows an untrusted system toeffectively communicate information, by compellingly justifying that information. Thesteps of such a justi ﬁcation amount to a logical proof of the assertion, and the ﬁnal key
element of the Semantic Web is a proof veri ﬁcation system that allows justi ﬁcations and
inferences to be exchanged along with raw data. Thus, a heuristic of one system mayposit a relationship (such as that a person may access a web page) and succeed inﬁnding a logical justi ﬁcation for it. This can be conveyed to a very rigid security system
that could never have derived this relationship or its justi ﬁcation on its own, but which
can verify that the justi ﬁcation is sound.
The Semantic Web works by allowing each individual system to maintain its own
language and characteristics. The access control system works with ﬁnite sets of people,
groups, and documents, and allows constrained expressions for access control.Haystack uses a certain set of user-programmed rules rather than a general inferenceengine. Prolog, SHOE, Algernon and KIF systems in turn make different decisionsregarding their inference languages, and so have correspondingly differentcharacteristics.
Organizational Modeling: A Structured Application
The W3C uses a mixture of database and web-based tools to provide administrative
support for day-to-day operations. Speci ﬁc challenges include balancing rapid response
and autonomy of subgroups with general accountability. This challenge is heightenedby having personnel distributed geographically around the world. Concepts modeledby the systems include people, W3C Member organizations, individuals, workingPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
13 of 52 11/5/09 10:07 AM
groups and other groups of various kinds, mailing lists, and documents. All documents
involved in W3C publicly visible or internal work are on the Web. The web serversallow access to an individual web resource to be ﬁnely controlled without changing the
URI of that resource.
Currently, W3C is at a similar level of development to many organizations in that
applications are built as custom web access to databases. However, data exists in avariety of formats and storage media from ﬂat ﬁles to relational databases.
There is a great deal of overlap among the W3C data systems, but this shared
conceptual space more often translates into redundancy than in useful sharing ofsubsystems. For example, the concept of group membership exists independently inweb access control, W3C membership management, mailing lists administration, andmeeting registration. In an ideal world group membership would be delegated using aﬂexible trust system which would map the practical nature of real-life trust
relationships.
Our proposed system uses Semantic Web techniques to expose this organizational
data consistently. For example,
The W3C membership table is exposed at the W3C web site in RDF;1.
The list of those authorized access though a member company may be delegatedto a remote web site;2.
The membership of a working group may be delegated to the chair;3.
The access control of ﬁles is stored as metadata close to the ﬁle, and determined
by the ﬁle owner;4.
One or more annotation servers allow a third party to store information about
items for which they have no write access;5.
and so on6.
In this context, we expect to demonstrate the operation of systems which cross
domains such as one or more of the following.
Generic query engines will perform queries crossing domains;1.
Validation may be performed of organizational invariants across domains;2.
New application building may be done using generic tools;3.
An access proof construction client will be able to use heuristics to ﬁnd a
justiﬁcation for access, and the access control system will be able to validate its
correctness;4.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
14 of 52 11/5/09 10:07 AM
The heuristic models of haystack will be able to interoperate with the
organizational management systems.5.
The expectation is that during the life of the project, code will be available for the
validation of XML digital signatures. This will allow these systems to check informationstrictly with regard to its source, and particularly a validated signature.
Example Scenario:401: Oh Yeah? Prove you have access!
The Semantic Web will allow us to model social processes, making facts and rules
available for sharing between heterogeneous implementations of those social processes.For example, consider access to the W3C web site
.
A portion of the W3C web site is con ﬁdential to the W3C Membership. Traditional
web server facilities allow us to create a w3c-member group, issue accounts that belongto that group, and limit access to certain paths within the web site to that group.
But this is a poor model of the actual social process, and the W3C spends a lot of
administrative resources bridging the gap: the right to access the member con ﬁdential
portions of the W3C web site is actually granted to any W3C Member representative,and each W3C Member organization has a distinguished Advisory CommitteeRepresentative (AC Rep) who has the right to appoint other representatives fromhis/her organization. We have extended the traditional web server facilities to modelgroups within groups, but we have not automated the various policies that AC Repsuse to appoint representatives; for example, the ACME AC Rep may say "do not grantanyone the right to represent ACME to W3C without my explicit approval" while theZebco AC Rep says "everyone who can receive mail in the Zebco.com domain may actas a Zebco representative to W3C." The W3C system administration team has toremember and manually implement these policies. Even this is a simpli ﬁcation of the
overall con ﬁdentiality policy; W3C has other classes of individuals such as invited
experts, liaisons, and other exceptions.
In the Semantic Web we can represent the whole range of policies as logical
assertions using classical logic with quoting and some axioms about digital signatures.We replace the ﬁxed structure of groups and accounts in the web server with a
component that veri ﬁes assertions of the form
Kwebmaster assures "hasAccess(Krequestor, pageID)"
wherePROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
15 of 52 11/5/09 10:07 AM
K assures "S"
means that the statement S was signed with K or can be deduced from statements
signed by K; i.e. we have the following axioms:
(S=>T) => ((K assures "S") => (K assures "T"))
(K assures "S") /\ (K assures "T") => (K assures "S /\ T")
Next, the W3C Director delegates appointment of member representatives to AC
Reps by publishing a signed assertion:
Kdirector assures
"\forall org, Kacrep, Krep (ACRep(Kacrep, org)/\ (Kacrep assures "memberRep(Krep, org)")=> memberRep(Krep, org)"
And in the course of ACME joining W3C, the W3C Director certi ﬁes the key of Wiley,
their AC Rep:
Kdirector assures "ACRep(Kwiley, ACME)"
Wiley appoints John Doe to represent ACME to W3C by publishing a signed
assertion:
Kwiley assures "memberRep(KjohnDoe, ACME)"
The W3C Webmaster records his/her trust in the W3C Director on matters of
member representation ala:
Kwebmaster assures "\forall org, rep ((Kdirector assures "memberRep(rep, org)") =>
memberRep(rep, org))"
Finally, the secretariat of a member con ﬁdential meeting arranges that Kwebmaster
sign a statement that the meeting record is member con ﬁdential:
\forall K, org (memberRep(K, org) => hasAccess(K, meetingRecord))
When John Doe requests the meeting record, he will get an HTTP authentication
challenge. To meet this challenge, he must prove to the web server that
Kwebmaster assures hasAccess(KjohnDoe, meetingRecord)
This follows from the above: the webmaster grants access to that page to any
member representative, and trusts the W3C Director on matters of membershiprepresentation; the W3C Director, in turn, delegates that decision to AC Reps; Wiley hasappointed John Doe a representative of ACME, and so he is granted access.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
16 of 52 11/5/09 10:07 AM
The proof-checking machinery required in the web server to make use of the
statements above is similar to previous work done in TAOS [Wobber et al. 1993] withBAN logic [Burrows et al. 1990]. In the Semantic Web project we propose to show thatproof checking on access can be scalable to the entire Web.
Note, too, that in principle the above statements can be recorded anywhere; they
needn't be stored inside the trusted computing base of the W3C web server, and theW3C administrative staff needn't be aware that Wiley has appointed John Doe arepresentative of ACME. This obliges John Doe to assemble all these facts and arrangethem into a proof when submitting his request for access to the page.
In practice the web server will have a limited ability to construct proofs for common
cases of authorization, in addition to its general ability to check these proofs. Butmember organizations can implement arbitrarily complex policies without burdeningthe W3C administrative team by publishing their own signed assertions andimplementing their own agent for generating authorization proofs. Computation ofthese assertions may be by heuristic, rather than by rigorous logical calculation,provided that the exported proof still meets the standards of SWeLL and the accesscontrol system's proof veri ﬁer.
Information Management: An Unstructured Application
Where the day to day management of the W3C is a well-structured and largely
deterministic process, many web applications are more heuristic and less sharplydeﬁned. Inter-document relationships and relevance, as manipulated for example by
web search engines and recommender systems, are exemplary of this less formallystructured kind of relationship.
Haystack is a system that we have built for information management. In its current
incarnation, we have focused on the management of individual corpora, i.e., theinformation with which a single user interacts. Modern information management tools-- such as information retrieval and data mining algorithms -- have been effective atfacilitating interaction with global corpora such as the World Wide Web. This one-size-ﬁts-all approach to information management has been roughly analogous to a public
library: the corpus is large, broad, and impersonal, and the retrieval tools are relativelyinsensitive to individual and contextual differences among their users. Haystack's focuson individual corpora and personalized information management is more like one'sown bookshelf. Your own haystack collects the information with which you interact,PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
17 of 52 11/5/09 10:07 AM
captures the contexts  within which you use it, and learns  how you organize that
information. So, for example, you can ask your haystack for "the paper I just read thatwas on the same topic as the email I forwarded to Pat last Thursday." This query mixescontent ("topic") and context ("email I forwarded..."); it relies on interconnections ("sametopic") and interactions ("paper I just read") that are meaningful only to its particularuser.
Haystack already allows browsing and annotation of the Haystack internal data
model. Haystack's internal data model is a lot like RDF and we will be providingtranslators between these two models for import/export of Haystack data. We willadapt the Haystack UI to browse and annotate Semantic Web information. This includessome rudimentary graph browsing as well as an attempt at semi-sensible "structure"browsing.
At the same time, the power of individual haystacks would be signi ﬁcantly enhanced
by connecting them; this is a direction we will undertake using the Semantic Web.Haystacks represent the information environments of their users. It would be of greatbeneﬁt if individual haystacks could be used as proxies for collaboration. After all, if
you can't ﬁnd what you're looking for on your own bookshelf, you are more likely to
turn to your neighbor -- either for access to his bookshelf or to ask for advice -- than tohead to the library. Under the current proposal, we intend to address exactly this issue.One's own haystack contains a substantial collection of one's own intelligence. Itrepresents the areas of one's expertise. And, having learned one's perspective on thatinformation, it embodies one's own biases and insights. By allowing one haystack toquery another, we facilitate information sharing, expert identi ﬁcation, and community
building. This will be accomplished by adding DAML facilities to Haystack, allowingone haystack to communicate with another using the power of the Semantic Web.
Information management is the heart of the W3C operation. During the course of
developing a speci ﬁcation a large corpus of contextual information is created. This
corpus includes discussion threads and rationale for each portion of the speci ﬁcation
and detailed issues with their resolution. The W3C process requires consensus butprovides for recording of dissenting opinions as a means to allow consensus to bereached. When a draft speci ﬁcation is later presented for advancement to a higher
status, the issues list and minority statements should become part of the review process.The information management system should facilitate discovery of common threads ofdiscourse. This is especially challenging when those threads are separated in time andPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
18 of 52 11/5/09 10:07 AM
when the terminology used by the discussants changes and evolves. In the Semantic
Web we intend to investigate the use of Haystack's heuristics for ﬁnding related
information and develop an augmented set of authoring tools for annotating discussionthreads and the evolution of terminology.
This of course introduces signi ﬁcant privacy and information control issues, not
unlike those of the W3C's access control. We intend to adapt the W3C ACL system (tobe developed under this project) for use in inter-haystack collaboration and informationexport. There may be substantial differences between the speci ﬁc rules of access control
for the W3C's activities and those of information sharing among haystacks; but this isprecisely the kind of ﬂexibility that the Semantic Web is designed to support. Haystack
may accept different justi ﬁcations from W3C ACL, but the underlying proof language
and much of the veri ﬁcation infrastructure will be shared between these systems.
Accordingly, we expect to adapt the Haystack UI to support manual proof veri ﬁcation,
i.e., to browse the proof and accept/reject statements with human assistance.
As Haystack deals typically with subjective and vaguely-de ﬁned terms such as
relevance and information quality, the algorithms it uses are generally heuristicscontrolled and adjusted by the user. This sets it apart from the mechanical, logicaloperations of the W3C operational machinery. The systems are in that way quitedistinct. The real power of the Semantic Web will be evidenced not by inter-haystacksharing, but by the ways in which this same DAML integration allows informationsharing between a haystack and a radically different information producer or consumer.
Consider, for example, the export of Haystack data to the access control system.
Suppose (for some reason) a person wants to make access to their research papersavailable to interested academics in the ﬁeld, but not to the general public. A haystack
can be used to heuristically generate a collection of names of authors of papers whosecontents match the speci ﬁed ﬁeld, together with their email addresses. This information
can be exported in one of two ways. First, the haystack can export a list of the emailaddresses of all qualifying individuals as an RDF ﬁle on the Semantic Web. She or he
then introduces into the formula for access to the documents a term which allows accessby people whose email addresses are in the list. The secure system has been allowed totrust -- for a speci ﬁc purpose only -- the output of a rough and ready heuristic. More
extremely, the Haystack can produce, on demand, a SWeLL justi ﬁcation as to why a
particular email address should be included. This justi ﬁcation includes reference to
relationships, such as document relevance, that are meaningful only within Haystack.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
19 of 52 11/5/09 10:07 AM
But it also includes reference to other relationships, such as the Dublin Core's creator
metadata, that may be directly manipulable by the consuming system.
Vision
There is, of course, no reason to limit communication over the Semantic Web to these
two applications. Indeed, in options to this proposal, we intend to develop a variety ofother DAML applications that will similarly bene ﬁt from exploitation of the
universality of communication over the Semantic Web. We would then expect to create,for example, a spoken language interface to the information contained in one'sHaystack; an intentional naming scheme that allows one to locate W3C working groupswith relevant interests; or construct a complete vacation planner on the ﬂy.
This project is a test on a ﬁnite scale of a system designed to scale in an unbounded
fashion. Aspects of the Semantic Web's features supporting smooth evolution oftechnology will only be tested thoroughly when similar but independent systems areindependently designed and later merged by the creation of linking rules. For example,if another organization were to model its processes independently and later connect theshared concepts (such as "meeting") to W3C's so as to directly enable shared calendars,then we would have a success.
Options
The Oxygen project, currently underway at MIT, brings numerous LCS and AI lab
researchers together to build a ubiquitous computational infrastructure involving bothhandheld and embedded computational units. The projects ﬁtting into Oxygen include
speech technology (as a user interface), Haystack (for knowledge representation) andthe Intentional Naming System (for naming and resource discovery). All of thesesystems could bene ﬁt by sharing a common representational infrastructure using the
Semantic Web. Haystack has already been discussed; here we discuss the otherpotential integrations.
For more than a decade, the Spoken Language Systems Group has been conducting
research in human language technologies and their utilization in conversationalinterfaces -- interfaces that can understand the verbal query in order to help userscreate, access, and manage information. Their technologies, which have been ported toeight languages and more than a dozen applications, are based on a semanticrepresentation of the input query, in the form of a hierarchical frame consisting ofkey-value pairs. The semantic frame is the central point for database access, discoursePROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
20 of 52 11/5/09 10:07 AM
and dialogue modelling, as well as natural language generation. Their involvement in
the Semantic Web effort will provide a much needed perspective based on humanlanguage. Furthermore, many of the tools developed by the speech group work byextracting information from other systems: for example, the Jupiter system responds toweather queries by ﬁnding appropriate information on the web---currently in textual
form. Representing this information semantically would improve Jupiter's ability toanswer queries.
The intentional naming system (INS) [Adjie-Winoto et al. 1999] currently under
development at LCS is intended for naming and resource discovery in future mobilenetworks of devices and services. The idea in intentional naming is to name entitiesbased on descriptive attributes, rather than simply on network location (which is whatthe DNS does). This allows applications to discover resources based on what  they are
looking for, rather than where  they are located in the network. This is natural for most
applications, since they often can describe the former but do not know about the latter.
INS bene ﬁts greatly from the Semantic Web and its associated markup language,
since it needs an expressive naming syntax to describe entities (e.g., the closest and leastloaded printer near where you're standing right now). It also needs to be able tostandardize similar services that might be advertised by their providers with differentnames, as in one person calling the device a "printer" and the other calling it a "paperoutput device." The Semantic Web makes this possible.
Because INS incorporates techniques in its resolution architecture to handle service
and user mobility as well as group communication, we believe that using the SemanticWeb in this system will allow us to explore and demonstrate the bene ﬁts of the semantic
web in mobile networks of devices and services.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
21 of 52 11/5/09 10:07 AM
E. Evaluation
The primary means of evaluation to be used in this project are those centered around
feasibility demonstration by actual deployment of the technology. Although the earlierexperimental phases of this project will require more limited deployment than the later,more ﬁnished stages, we anticipate employing our own work to the extent possible as a
primary means of evaluation.
In this project, we will integrate the results of our work at the earliest possible stage
into the daily work of the World Wide Web Consortium. The philosophy of "Live EarlyAdoption and Demonstration" (LEAD) has been a operational tool at the Consortiumfor the last few years. It is an approach that we have found particularly effective inthose areas (such as web-based collaboration) where the weakest link has been betweenthe development of technology and its actual deployment. For example, theConsortium's practical use of its Amaya (web authoring and browsing) client andJigsaw server has shed considerable light on interactive editing in HTTP 1.1.
Because many of the prototypical tools that we are building will be organizational
process management tools, we anticipate using these tools in the running of the WorldWide Web Consortium. This will put pressure on these tools to be useful and functionalas well as robust; by living with them, we will also quickly learn where they must beimproved. As these tools become more sophisticated, we will increasingly deploy themin critical-path Consortium operations.
The Semantic Web is primarily a tool for interoperability. This is why we are
proposing to build a suite of applications, rather than a single monolithic application.The goal of interoperability between heterogeneous components that we build is onethat will test the extent to which the Semantic Web is achieving its promise. The morediverse the systems interoperating, the greater the merit of the Semantic Web. Initially,we expect the process management tools and information management tools to besomewhat separate. As the Semantic Web's interoperability increases, we expect to seefurther synergies arise between these diverse systems. This will be a re ﬂection of the
extent to which the Semantic Web is achieving its goals. The broader set of optioncomponents will increase the rigor of this test.
Ultimately, the test of the Semantic Web--and the applications that we build for
it--will be the extent to which applications built by others interoperate with ours. Thenext test is transmission of information between our applications and those built byPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
22 of 52 11/5/09 10:07 AM
other DAML contractors. If the Semantic Web lives up to its potential, even this phase
will ultimately be surpassed by one in which non-participant organizations constructapplications to exploit this infrastructure. Similarly, we will judge our tools by theextent to which they are ultimately useful to other groups.
An interesting result of the project will be to ﬁnd how much logical information
(from inference rules and other metadata) can in practice be exchanged betweensystems. It may be that in certain applications much more signi ﬁcant information is in
the logic than in any raw data, in which case the Semantic Web will enable a dramaticenhancement of interoperability. This project is designed to get as much advancedexperience early on, before very large scale deployment. The diversity of systemssuccessfully interfaced to the Semantic Web will be an important indicator of success.The deployment of the system into the running working processes of the W3C willsometimes mean that practical concerns may dictate what systems can be changed andin which ways at the time of deployment. Therefore the research aspect of the projectwill have to be adaptable to these practical concerns. However, it will have theadvantage of running tests on live data rather than imagined or simulated scenarios,including new real life application needs which arise unforeseen during development.It will also increase the applicability of experience and even running code to secondgeneration adopters of the technology.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
23 of 52 11/5/09 10:07 AM
H. Proprietary Claims
There are no proprietary claims by an external party on the ideas or products of this
project. MIT and the researchers in this proposal have full control over all intellectualand material rights.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
24 of 52 11/5/09 10:07 AM
I. Statement of Work
This project will contribute to the development of a vibrant, ubiquitous Semantic
Web by building critical Semantic Web infrastructure and demonstrating how thatinfrastructure can be used by working, user-oriented applications.
SWeLL Infrastructure
Basic SWeLL infrastructure components, the building blocks of all Semantic Web
applications to be produced by this project, will be built ﬁrst, and then re ﬁned
throughout the life of the activity. The basic components are:
SWeLL parser
Proof generator
Proof checker
Authoring tool
Schema editor
Query language
Once the parser, proof generator, and proof checker are built, they will be used
together to establish the basic functionality of logical expression in the SWeLLenvironment. As other components are built, they will be deployed in variouscombinations to develop SWeLL functionality for both the W3C web site and Haystack.
Haystack export as RDF
A Haystack HTTP server makes Haystack data available as RDF.
Foundation veri ﬁcation
This involves the re ﬁnement (if necessary) of SWeLL, the de ﬁnition of a proof
transfer language, the construction of a parser and of a proof validator for thatlanguage, and the publication of test data.
Import of W3C corpus into Haystack
The collection and state of W3C documents is made available to Haystack users.
Access validating HTTP server
With the de ﬁnition of an access control schema and an extension to HTTP , we modify
an existing HTTP server to use the proof engine and accept SWeLL requests forauthentication. This will be tested with an HTTP client modi ﬁed to send (hand-written,PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
25 of 52 11/5/09 10:07 AM
not automatically generated) access justi ﬁcations.
Exposure of W3C administrative systems
At least two W3C administrative systems should be available on the Semantic Web at
this stage. This will involve creation of schemas for the systems involved and thegeneration of custom user agents or (in most cases) the modi ﬁcation of legacy systems
to generate SWeLL.
Import/Export of Haystack in SWeLL
The export of Haystack data to the Semantic Web requires the generation of schemas
and the conversion of internal formats to RDF. At around the same time we hope todemonstrate the import on demand of arbitrary data from the Semantic Web into auser's haystack. This adds Haystack's user interface to the Semantic Web toolset.
Cross-domain query demonstration
Choosing an appropriate query language, we make a query across previously
disjoint domains as a test rather than live system.
Socially meaningful cross-domain operation
A cross-domain query that provides a socially useful function, modelling the real
social needs of the organization, for example PINS and ACLs.
Community evangelism and deployment (years 3 and 4)
The pace of uptake of technology in the commercial community at large is dif ﬁcult to
predict in the current enthusiastic environment. As suf ﬁcient interest occurs that this is
possible, we will coordinate its transition to the W3C standards process.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
26 of 52 11/5/09 10:07 AM
J. Management Plan
The personnel in this proposal are all university researchers.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
27 of 52 11/5/09 10:07 AM
L. Technology Sharing
Technology developed under this proposal will be propagated through the very
same mechanisms that have enabled the rapid spread of today's core World Wide Webstandards. Sharing DAML-based technology will occur along three dimensions, withdifferent user communities becoming involved as the technology increasingly matures.
The ﬁrst axis of technology sharing is with explicit supporting partners such as
World Wide Web Consortium staff and members, the LCS Oxygen environment, andDAML collaborators. The second axis involves sharing with public metadatacommunities, W3C Metadata standards activities, and related open source andacademic communities. Finally, the third axis of technology sharing is to move matureDAML infrastructure to the W3C standards track and, as appropriate, other standardsbodies such as the Internet Engineering Task Force.
Axis one of technology sharing will occur within the con ﬁnes the two chosen DAML
testbeds, Haystack and the W3C community. With 60 staff in three sites around theworld and over 380 member organizations internationally, the W3C community willprovide a substantial testbed for initial application of DAML-based software andservices developed by this project. For example, as soon as the DAML-based accesscontrol tools are stable, they will be deployed on the W3C web site for use in mediatingW3C member access to W3C documents and services. Later, as authoring tools becomeavailable, they will be made available to members for use in creating W3C documentsand associated metadata. Other tools such as proof checkers and heuristic documentmanagement systems will also be deployed to address W3C work ﬂow and
collaboration issues. Drawing an analogy between this phase of Semantic Webtechnology sharing and the original development of the World Wide Web, one may seebasic DAML tools serving the same role as the original CERN phonebook did. This ﬁrst
phase of technology sharing will provide the DAML team with vital input on thesoundness of our design and begin the process of building broader support for theDAML approach.
Through the life of the Semantic Web activity, the links with LCS's Oxygen project
will also provide key technology sharing and evangelism opportunities. In particular,the corporate partners in Oxygen will be a valuable sounding board for assessing thecommercial viability of DAML and an important venue for technology transfer from thelaboratory to the market. Oxygen research will shed light on semantic web interfacePROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
28 of 52 11/5/09 10:07 AM
with novel operating system internals and distributed applications.
The second axis of DAML deployment will bring tools and techniques developed
with DAML to the attention of well-known public metadata communities such as theDublin Core bibliographic schema and the OpenGIS framework for representinggeographic information. An important avenue of technology diffusion will be theW3C's RDF Interest Group, a global community of metadata developers who work inthis group to coordinate their efforts and provide W3C feedback on its metadatastandardization efforts. While we do not expect these communities to necessarily acceptthe entire DAML framework they will provide vital corpora of metadata on which totest DAML. At this stage we also expect increased interaction with the communitiesdeveloping the XML Signature Speci ﬁcation for attaching digital signatures to XML, as
well as developers working on the Platform for Privacy Preferences ( P3P
), which will
have signi ﬁcant overlap with IMP . Finally, in this phase we would expect to use
Haystack tools to interact with these public metadata stores.
In the ﬁnal axis of technology sharing, we will concentrate on bringing critical DAML
infrastructure components into the W3C standards development process. This is ofcourse not a unilateral action by W3C staff, and happens only when communityconsensus is that work on standards would be worthwhile. Deployment along the othertwo axes will hopefully bring this about. The W3C Process document
 describes the
creation of new standardization activities. As the recognized source of Web standards,W3C is in a unique position to move concepts developed in this project into the publicWeb. As has been noted, W3C has already completed a ﬁrst round of Web metadata
standards through our RDF work. We expect that DAML will provide valuableguidance to the Web development community as a whole on evolving the SemanticWeb. W3C's close liaisons with other standards bodies, especially the IETF and the WAPForum, will also provide valuable opportunities for technology sharing.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
29 of 52 11/5/09 10:07 AM
M. Facilities
All work carried out by MIT under this proposal will be conducted at the MIT
Laboratory for Computer Science, the major site for computer science research at MIT.The Laboratory provides a basic computing environment for research, includingcommon services such as Internet access and printing. LCS provides administrativesupport for contract research, which will be utilized by the proposed project. LCSco-ordinates the physical plant provided to the research groups. Equipment andfacilities required to support speci ﬁc research programs, such as computational
workstations, specialized network facilities, and dedicated servers and prototypingmachines, is acquired on a per-program basis. This proposal includes an equipmentbudget to acquire such facilities for this project. The required facilities fall into (howmany) categories: explanation of computers and servers here. MIT is unable to supplythese facilities from institutional resources.
The MIT Laboratory for Computer Science is the United States host for the World
Wide Web Consortium The W3C team and research groups are equipped with recentcomputing systems, and suf ﬁcient bandwidth for ef ﬁcient work with other national and
international collaborators, including video conferencing. The Consortium has acollaborative web server allowing delegated authority to work in creative sharedspaces, hypertext email archives, an Event Tracking Agent for issue tracking, andautomated facilities for meeting organiztion. We have three conventional telephoneconference bridges and Internet video conferencing facilities. The Lab generally canoffer wireless LAN (802.11+DHCP) access for meeting guests.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
30 of 52 11/5/09 10:07 AM
N. Government Furnished Property
No Government furnished property is required for this research.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
31 of 52 11/5/09 10:07 AM
O. Experience
This projects involves a new collaboration between two organizations: The World
Wide Web Consortium and the MIT Lab for Computer Science.
The World Wide Web Consortium W3C was established in 1994 in response to a
growing demand for a coordination body for the rapid development of Web standards.It was founded by the inventor of the Web, Tim Berners-Lee (PI on this project), and ishosted by MIT LCS in the USA, INRIA in France, and Keio University in Japan, withofﬁces in several other countries. The W3C has over the last 6 years overseen processes
of issue raising, design, consensus building and testing resulting in about 20Recommendations including HTML, XML, XHTML, XML Transformations (XSL),Cascading Style Sheets, and Portable Network Graphics.
The need for common standards for interchange of metadata (information about Web
resources) drove the Consortium to create, in the Resource Description Framework(RDF), a general knowledge representation language of limited power and greatextensibility. Ralph Swick (co-PI on this proposal) was and is the W3C metadata leadand co-author of the RDF Model and Syntax Recommendation.
The W3C Technology and Society Domain, lead by Daniel Weitzner (co-PI on this
proposal) has lead the Web community in developing technology to assist in solvingsocial problems such as privacy and authentication. The PINS information managementtools proposed as part of this project will draw heavily on the W3C's work on thePlatform for Privacy Preferences (P3P) and work on digital signatures for XML.
The MIT Laboratory for Computer Science (LCS) is an interdepartmental laboratory,
bringing together faculty, researchers, and students in a broad program of study,research and experimentation. The Laboratory's principal goal is to pursue innovationsin information technology that will yield long-term improvements in the ways thatpeople live and work. The hallmark of its research is a balanced consideration oftechnological capability and human utility.
Currently, LCS is focusing its research on the architectures of tomorrow's information
infrastructures. In the interest of making computers more ef ﬁcient and easier to use,
LCS researchers are putting great effort into human-machine communication via speechunderstanding; designing new computers, operating systems, and communicationsarchitectures for a networked world; automating information gathering andPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
32 of 52 11/5/09 10:07 AM
organization; and the theoretical underpinnings of CS.
One central technology in the current LCS agenda is the Haystack project led by
co-PIs David Karger and Lynn Andrea Stein. Haystack combines the function of atraditional text-document retrieval system with the gathering, representation,presentation and management of arbitrary metadata, forming a personal informationmanagement tool and a part of the semantic information space for LCS'snext-generation computer systems.   Haystack builds on Karger's previous work ininformation retrieval (including Scatter/Gather) and Stein's research in knowledgerepresentation (especially nonmonotonic logics), software agents (including the Sodabotagent environment in the MIT AI Lab's DARPA-funded Intelligent Room), and webmanipulation (e.g., the Squeal/ParaSite structured web interface).
Other LCS members whose work will inform this project include Steve Garland of
the LCS Software Devices and Systems group, principal developer of LP , a proofassistant for multisorted ﬁrst-order logic, and co-designer of the Larch and IO
Automata speci ﬁcation languages and analysis tools; Daniel Jackson, co-leader of the
LCS Software Design group and author of numerous langauges and tools for describingthe structural properties of software (including Alloy/Alcoa, with properties similar toSWeLL); Nancy Lynch, leader of the LCS Theory of Distributed Systems group, authorof Atomic Transactions  and Distributed Algorithms  and co-designer of IO Automata; and
Ron Rivest, co-leader of the LCS Cryptography and Information Security Group,co-inventor of the RSA public key cryptosystem, the MD5 digital ﬁngerprinting
algorithm, and the SDSI public key infrastructure.
Optional Semantic Web applications and features draw on additional expertise
within LCS. The Spoken Language Systems Group (including Stephanie Seneff) hasbeen conducting research in human language technologies and their utilization inconversational interfaces. Their technologies, which have been ported to eightlanguages and more than a dozen applications, are based on a semantic representationof the input query. Their involvement in the Semantic Web effort will provide a muchneeded perspective based on human language.
The LCS Computer-Aided Automation Group, directed by Srini Devadas, is
dedicated to exploring and implementing computer-based solutions to problems in thedesign and control of electronic devices in the home, of ﬁce, and factory. The group is
engaged in research to further automated control of these electronic devices, and toleverage advances in networking technology to allow intelligent products to interactPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
33 of 52 11/5/09 10:07 AM
with one another, further enhancing their usefulness.
Hari Balakrishnan, of the Software Devices and Systems group, works on wireless
device networks and intentional naming schemes. His PhD work includes the Snoop
Protocol , designed to signi ﬁcantly improve TCP performance over error-prone wireless
links, and studies of the effects of bandwidth and latency asymmetry and the effects ofsmall window sizes on TCP performance.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
34 of 52 11/5/09 10:07 AM
Q. Quali ﬁcations
Tim Berners-Lee
A graduate of Oxford University (BA Physics ﬁrst class, 1976), Tim now holds the
3Com Founders chair at the Laboratory for Computer Science ( LCS) at the
Massachusetts Institute of Technology ( MIT ). He directs the World Wide Web
Consortium , an open forum of companies and organizations with the mission to lead
the Web to its full potential.
With a background of system design in real-time communications and text
processing software development, in 1989 he invented the World Wide Web , an
internet-based hypermedia initiative for global information sharing, while working atCERN
, the European Particle Physics Laboratory. He wrote the ﬁrst web client
(browser-editor)  and server, and the original HTML, HTTP and URI speci ﬁcations, in
1990. Awards include ACM Software Systems Award (1995), ACM Kobayashi award(1996), the IEEE Computer Society Wallace McDowell Award (1996), Computers andCommunication (C&C) award (1996); OBE (1997), Charles Babbage award (1998), aMacArthur Fellowship
 and The Eduard Rhein technology award (1998). Honorary
degrees from Parsons School of Design , New York (D.F.A., 1996), Southampton
University  (D.Sc., 1996), and Essex University  (D.U., 1998), Southern Cross University
(1998). Distinguished Fellow of the British Computer Society , Honorary Fellow of the
Institution of Electrical Engineers . Publications include:
T. Berners-Lee " Universal Resource Identi ﬁers in WWW ", RFC1630 , 1994/6
Berners-Lee, T.J., et al, "World-Wide Web: Information Universe", Electronic
Publishing: Research, Applications and Policy , 1992/4.
Berners-Lee, T.J., et al, "The World Wide Web," Communications of the ACM , 1994/8.
T. Berners-Lee, L. Masinter, M. McCahill, " Universal Resource Locators (URL) ",
RFC1738 , 1994/12
T. Berners-Lee, D. Connolly " Hypertext markup Language - 2.0 ", RFC1866 , 1996/5
R. Fielding, J. Gettys, J. Mogul, H. Frystyk, L. Masinter, P . Leach, T. Berners-Lee
"Hypertext Transfer Protocol HTTP 1.1 ", RFC 2616 , 1999/6
Tim Berners-Lee, Dan Connolly, Ralph R. Swick " Web Architecture: Describing andPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
35 of 52 11/5/09 10:07 AM
Exchanging Data ", W3C Note, 1999/6/7
Berners-Lee, T., Weaving the Web , Harper SanFrancisco, 1999PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
36 of 52 11/5/09 10:07 AM
Dan Connolly
Dan Connolly (B.S. in Computer Science, University of Texas at Austin , 1990) is the
leader of the XML Activity  in the World Wide Web Consortium. He began contributing
to the World Wide Web project, and in particular, the HTML speci ﬁcation, while
developing hypertext production and delivery software in 1992.
Mr. Connolly presented a draft of HTML 2.0  at the ﬁrst Web Conference  in 1994 in
Geneva, and served as editor until it became a Proposed Standard RFC in November1995.
Mr. Connolly was the chair of the W3C Working Group that produced HTML 3.2 and
HTML 4.0, and collaborated with others to form the W3C XML
 Working Group and
produce the W3C XML 1.0 Recommendation.
Prior to joining the World Wide Web Consortium, Mr. Connolly was a software
engineer at HaL Software Systems were he participated in the design andimplementation of document database tools including building proxy servers toconnect those tools to the World Wide Web.
Mr. Connolly's research interest is investigating the value of formal descriptions of
chaotic systems like the Web, especially in the consensus-building process.
Connolly, ed, XML: Principles, Tools and Techniques, World Wide Web Journal
(O'Reilly and Associates, 1997)
"An Evaluation of the World Wide Web as a Platform for Electronic Commerce", in
Kalakota, Whinston, Readings in Electronic Commerce (Addison-Wesley, 1996)
Berners-Lee, Connolly, eds., Hypertext Markup Language 2.0, Internet Engineering
Task Force RFC1866 (1995), http://www.ietf.org/rfc/rfc1866.txtPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
37 of 52 11/5/09 10:07 AM
David R. Karger
David R. Karger (A.B. summa cum laude  in Computer Science, 1989, Harvard College;
Certiﬁcate of Advanced Study in Mathematics 1990, Churchill College, Cambridge
University; Ph.D., 1994, in Computer Science, Stanford University) is an AssociateProfessor of Computer Science and a member of the Laboratory for Computer Science.He was the recipient of a David and Lucille Packard Foundation Fellowship(1997--2002), an Alfred P . Sloane Foundation Fellowship (1996--1998), the 1997Mathematical Programming Society Tucker Prize, the 1995 ACM Doctoral Dissertationaward, and a 1995 NSF CAREER grant.
Professor Karger's research interests include algorithms and information retrieval.
His work in algorithms has focused on applications of randomization to graphoptimization problems and led to signi ﬁcant progress on several core problems. He is
the author of more than 20 publications and has served on the program committees ofsome of the most important theoretical computer science conferences. He is a memberof the executive committee of SIGACT, ACM's theoretical computer science group, andon the editorial board of Information Retrieval
.
Karger's work on information retrieval includes the co-development of the
Scatter/Gather information retrieval system at Xerox PARC, which suggested severalnovel approaches for ef ﬁciently retrieving information from massive corpora and
presenting it effectively to users. He has received two patents related to his work on thisproject. He is presently co-PI on the Haystack personalized information managementproject.
Professor Karger's World Wide Web home page can be found at
http://theory.lcs.mit.edu/~karger/
Publications relevant to proposed work:
D. Cutting, D. R. Karger, J. Pedersen, and J. W. Tukey. ``Scatter/Gather: A
Cluster-based Approach to Browsing Large Document Collections.'' In Proceedings
of the 15th  Annual International ACM SIGIR Conference on Research and
Development in Information Retrieval}, pages 318--329, 1992.
D. Cutting, D. R. Karger, and J. Pedersen. ``Constant Interaction-TimeScatter/Gather Browsing of Very Large Document Collections.'' In Proceedings of
the 16th  Annual International ACM SIGIR Conference on Research and
Development in Information Retrieval}, July 1993. Pittsburgh, PA.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
38 of 52 11/5/09 10:07 AM
Adar, E., D. R. Karger, and L. A. Stein, "Haystack: Per-User Information
Environments," Conference on Information and Knowledge Management  , Kansas City,
Missouri, November 1999, pp. 413-422.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
39 of 52 11/5/09 10:07 AM
Lynn Andrea Stein
Lynn Andrea Stein (A.B. cum laude in Computer Science, 1986, Harvard and
Radcliffe Colleges; Sc.M., 1987, and Ph.D., 1990, in Computer Science, BrownUniversity) is an Associate Professor of Computer Science and a member of theArtiﬁcial Intelligence Lab and the Lab for Computer Science at the Massachusetts
Institute of Technology, where she heads the AP Group. She was a recipient of (amongothers) the Ruth and Joel Spira Teaching Award, the General Electric Faculty for theFuture Award, and the National Science Foundation Young Investigator Award.
Professor Stein is an internationally known researcher whose work spans the ﬁelds of
knowledge representation and reasoning, software agents, human-computer interactionand collaboration, information management, object-oriented programming, andcognitive robotics. She is author or co-author of more than 50 publications and hasserved on the program and advisory committees of numerous national andinternational conferences in these ﬁelds. She has recently given invited lectures at the
national conference on arti ﬁcial intelligence (AAAI) and the European Meeting on
Cybernetics and Systems Research and will deliver plenary addresses at this spring'sInternational Conference on Complex Systems. From 1991 to 1996 she served asAssociate Chair and then Chair of the AAAI's Symposium Committee and from 1995 to1998 as an Executive Councilor of the AAAI. Recent major publications include:
Stein, Lynn Andrea. Introduction to Interactive Programming  (San Francisco: Morgan
Kaufmann, 2001).
Stein, L. A., "Resolving Ambiguity in Nonmonotonic Inheritance Hierarchies,"
Artiﬁcial Intelligence  55 (2-3): 259-310, June 1992.
Boddy, M., R. P . Goldman, K. Kanazawa, and L. A. Stein, "A Critical Examination of
Model-Preference Defaults," Fundamenta Informaticae , 21 (1-2), July-August 1994.
Stein, L. A. and L. Morgenstern,, "Motivated Action Theory: A Formal Theory of
Causal Reasoning," Artiﬁcial Intelligence  71 (1):1-42, November 1994.
Stein, L. A. and S. B. Zdonik, "Clovers: The Dynamic Behavior of Types and
Instances," International Journal of Computer Science and Information Management  1 (3):
1-11, 1998.
Spertus, E., and L. A. Stein, "A Relational Database Interface to the World-Wide Web,"PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
40 of 52 11/5/09 10:07 AM
ACM Conference on Digital Libraries , Berkeley, California, August 1999, 248-249.
Adar, E., D. R. Karger, and L. A. Stein, "Haystack: Per-User Information
Environments," Conference on Information and Knowledge Management  , Kansas City,
Missouri, November 1999, pp. 413-422.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
41 of 52 11/5/09 10:07 AM
Ralph R. Swick
Ralph R. Swick (B.S. Physics and Mathematics, Carnegie-Mellon University, 1977) is a
Research Associate in the Lab for Computer Science at the Massachusetts Institute ofTechnology where he is the Technical Director for the Technology and Society Domainof the World Wide Web Consortium and leads work on metadata within the W3C.
Mr. Swick was the co-editor of the W3C Resource Description Framework Model and
Syntax Speci ﬁcation and was one of the principals in the RDF design. Before joining
W3C Mr. Swick was Technical Director of the X Consortium where he led the designand development of major portions of the X Window System. Mr. Swick was one of thenamed co-recipients of the 1999 Usenix Association Lifetime Achievement Awardspresented to the X Window System Community. While a member of the corporateresearch staff of Digital Equipment Corporation, Mr. Swick was active in Project Athenaat MIT where he worked on the X Window System and contributed to the Kerberosauthentication system. Subsequent to Project Athena Mr. Swick was in the Of ﬁce
Systems Advanced Development Group at Digital where he prototyped severaladvanced information management and group collaboration tools.
Asente, Converse, Swick. The X Window System Toolkit (Digital Press/Butterworth-
Heinemann, 1998).
Berners-Lee, Connolly, Swick, Web Architecture: Describing and Exchanging Data
(World Wide Web Consortium Note, 1999) http://www.w3.org/1999/04/WebData
Lassila, Swick [eds], Resource Description Framework (RDF) Model and Syntax
Speci ﬁcation (World Wide Web Consortium Recommendation, 1999)
http://www.w3.org/TR/1999/REC-rdf-syntax-19990222PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
42 of 52 11/5/09 10:07 AM
Daniel Weitzner
Daniel Weitzner is Director of the World Wide Web Consortium's Technology and
Society  activities. He was one of the ﬁrst to propose user empowerment tools for the
Web, such as content ﬁltering and privacy protection technology, as means to address
global policy challenges on the Internet. As Technology and Society Domain Leader, heis responsible for development of technology standards that enable the web to addresssocial, legal, and public policy concerns such as privacy, free speech, protection ofminors, authentication, intellectual property and identi ﬁcation. He is also the W3C's
chief liaison to public policy communities around the world and a member of theICANN Protocol Supporting Organization Protocol Council
.
Weitzner holds a research appointment at MIT's Laboratory for Computer Science
and teaches Internet public policy at MIT.
Before joining the W3C, Mr. Weitzner was co-founder and Deputy Director of the
Center for Democracy and Technology , an Internet civil liberties organization in
Washington, DC. At CDT he played a leading role in the Supreme Court litigationestablishing comprehensive First Amendment rights on the Internet. He was alsoDeputy Policy Director of the Electronic Frontier Foundation
. Mr. Weitzner has a degree
in law from Buffalo Law School, and a B.A. in Philosophy from Swarthmore College.
Selected Publications:Weitzner, D, Berman, J., "Abundance and Control: Renewing the Democratic Heart of
the First Amendment in the Age of Interactive Media," Yale Law Journal , Vol. 104, No.7,
May 1995
Weitzner, D, "Directing Policy-Making: Beyond the Net's Metaphor," Communications
of the ACM , Vol. 40, No. 2, February 1997.
Weitzner, D., Berman, J., "Technology and Democracy, " Social Research  (Volume 64
No. 3 (Fall 1997))
Weitzner, D., (ed.), Browning, G., Electronic Democracy: Using the Internet to In ﬂuence
American Politics . Pemberton Press, 1996.
Weitzner, D. "The Clipper Chip Controversy," Computerworld  July 25, 1994.
Weitzner, D., Kapor, M., "The EFF Open Platform Proposal," 1992.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
43 of 52 11/5/09 10:07 AM
http://www.eff.org/pub/Infrastructure/Old/overview_eff.op
He is also a commentator for NPR's Marketplace Radio.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
44 of 52 11/5/09 10:07 AM
R. Bibliography
Adar, Eytan. Hybrid-Search and Storage of Semi-structured Information . Master's Thesis,
MIT, May 1998.
Adar, E., D. R. Karger, and L. A. Stein, "Haystack: Per-User Information
Environments," Conference on Information and Knowledge Management  , Kansas City,
Missouri, November 1999, pp. 413-422.
http://www.acm.org/pubs/citations/proceedings/cikm/319950/p413-adar/
Adjie-Winoto, W., Schwartz, E.,Balakrishnan, H., Lilley, J., "The design and
implementation of an intentional naming system," Proc. 17th ACM SOSP , KiawahIsland, SC, Dec. 1999.
Asoorian, Mark. Data Manipulation Services in the Haystack IR System . Master's Thesis,
MIT, May 1998.
Baader, F. and Hollunder, B. (1991). KRIS: Knowledge representation and inference
system. ACM SIGART Bulletin  2(3) 8-14.
Baldonado, M., C.-C. K. Chang, L. Gravano and A. Paepcke (1997). "The Stanford
Digital Library Metadata Architecture." International Journal of Digital Libraries  1:2,
September 1997, pp. 108-121.
Berners-Lee, T., 1999, Weaving the Web , HarperCollins Publishers, 10 East 53rd Street,
New York, NY
Berners-Lee, T., and D. Connolly, 1998. Web Architecture: Extensible Languages
, W3C
Note
http://www.w3.org/TR/1998/NOTE-webarch-extlang-19980210
Boddy, M., R. P . Goldman, K. Kanazawa, and L. A. Stein, "A Critical Examination of
Model-Preference Defaults," Fundamenta Informaticae , 21 (1-2), July-August 1994.
ftp://ftp.ai.mit.edu/pub/users/las/critical-examination-of-MPD.ps.Z
Borgida, A., Brachman, R.J., McGuiness, D.L. and Resnick, L.A. (1989). CLASSIC: a
structural data model for objects. Proceedings of 1989 SIGMOD Conference on the
Management of Data . pp.58-67. New York, ACM Press.
Brachman, R.J., Gilbert, V .P . and Levesque, H.J. (1985). An essential hybrid reasoningPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
45 of 52 11/5/09 10:07 AM
system: knowledge and symbol level accounts of KRYPTON. Proceedings of IJCAI85 .
pp.547-551. San Mateo, California, Morgan Kauffman.
Brachman, R.J. and Schmolze, J. (1985). An overview of the KL-ONE knowledge
representation system. Cognitive Science  9(2) 171-216.
Bray, T., J. Paoli and C.M. Sperberg-McQueen. 1998. Extensible Markup Language
(XML) . W3C (World-Wide Web Consortium) Recommendation.
http://www.w3.org/TR/1998/REC-xml-19980210
Burrows, M., Abadi, M., Needham, R. (1990) A Logic of Authentication ,
Technical Report, DEC System Reearch Center, Number 39
http://gatekeeper.dec.com/pub/DEC/SRC/research-reports/abstracts/src-rr-039.html
Bush, Vannevar. As We may Think. Atlantic Monthly , 176(1)641-649, January 1945.
Chawathe, S., H. Garcia-Molina, J. Hammer, K. Ireland, Y. Papakonstantinou, J.
Ullman and J. Widom (1994). The TSIMMIS Project: Integration of HeterogenousInformation Sources. IPSJ Conference , Tokyo, Japan.
Craven, M., D. DiPasquo, D. Freitag, A. McCallum, T. Mitchell, K. Nigram and S.
Slattery. 1998. Learning to Extract Symbolic Knowledge from the World Wide Web. InProceedings of the AAAI-98 Conference on Arti ﬁcial Intelligence . AAAI/MIT Press.
Crawford, J. (1990), Access-Limited Logic: A Language for Knowledge Representation
,
Doctoral dissertation, Department of Computer Sciences, University of Texas at Austin,Austin, Texas. UT Arti ﬁcial Intelligence TR AI90-141, October 1990. ( Algernon and
Access-Limited Logic )
ftp://ftp.cs.utexas.edu/pub/qsim/papers/Crawford-PhD-91.ps.Z
http://www.cs.utexas.edu/users/qr/algernon.html
Cutting, Douglass, David R. Karger, Jan Pedersen, and John W. Tukey.
"Scatter/gather: A cluster-based approach to browsing large document collections." InProceedings of the 15th Annual International ACM SIGIR Conference on Research andDevelopment in Information Retrieval , pages 318-329, Copenhagen, Denmark, 1992.
Eastlake, D., Reagle, J, Solo, D. (Eds.), (2000), XML-Signature Core Syntax and
Processing , W3C Working Draft
http://www.w3.org/TR/2000/WD-xmldsig-core-20000104/
Engelbart, Douglas C. Augmenting Human Intellect: A Conceptual Framework . StanfordPROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
46 of 52 11/5/09 10:07 AM
Research Institute Technical Report, Menlo Park, CA, October 1962.
Evett, M.P ., W.A. Andersen, and J.A. Hendler. 1993. Providing Computational
Effective Knowledge Representation via Massive Parallelism. In Parallel Processing for
Artiﬁcial Intelligence . L. Kanal, V . Kumar, H. Kitano, and C. Suttner, Eds. Amsterdam:
Elsevier Science Publishers.
http://www.cs.umd.edu/projects/plus/Parka/parka-kanal.ps
Farquhar, A., Fikes, R., Pratt, W., & Rice, J. (1995). Collaborative ontology construction
for information integration . Technical Report KSL-95-63, Stanford University Knowledge
Systems Laboratory.
Freeman, Eric and Scott Fertig. "Lifestreams: Organizing your Electronic Life" AAAI
Fall Symposium: AI Applications in Knowledge Navigation and Retrieval, November1995, Cambridge, MA.
Finin, T., D. McKay, R. Fritzson, and R. McEntire. 1994. KQML: An Information and
Knowledge Exchange Protocol. In Knowledge Building and Knowledge Sharing . K. Fuchi
and T. Yokoi, Eds. Ohmsha and IOS Press.
http://www.cs.umbc.edu/kqml/papers/kbks.ps
Finin, T., McKay, D., Fritzson, R. (Eds.). (1992) The KQML Advisory Group. An
overview of KQML: A Knowledge Query and Manipulation Language
http://www-ksl.stanford.edu/knowledge-sharing/papers/index.html#kqml-overview
Finin, T., Weber, J., Wiederhold, G., Genesereth, M., Fritzson, R., McKay, D., McGuire,
J., Shapiro, S. and Beck, C. (1992). Speci ﬁcation of the KQML Agent-Communication
Language. The DARPA Knowledge Sharing Initiative External Interfaces WorkingGroup.
Genesereth, M., and Fikes, R., Eds. (1992). Knowledge Interchange Format
, version 3.0
reference manual. Technical Report Logic-92-1, Computer Science Department, StanfordUniversity.
http://www-ksl.stanford.edu/knowledge-sharing/papers/index.html#kif
Gruber, T. R. (1992). Ontolingua: A mechanism to support portable ontologies . Stanford
University, Knowledge Systems Laboratory, Technical Report KSL-91-66
http://www-ksl.stanford.edu/knowledge-sharing/papers/index.html#ontolingua-long
Gruber, T. (1993a). A translation approach to portable ontology speci ﬁcations.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
47 of 52 11/5/09 10:07 AM
Knowledge Acquisition , 5(2):199-220.
Guha, R. V . (1992). Contexts: A formalization and some applications. Ph.D. Thesis,
Dept. of Computer Science, Stanford.
Heﬂin, J., Hendler, J., and Luke, S. SHOE: A Knowledge Representation Language for
Internet Applications. Technical Report CS-TR-4078 (UMIACS TR-99-71), Dept. ofComputer Science, University of Maryland at College Park. 1999.
http://www.cs.umd.edu/projects/plus/SHOE/aij-shoe.ps
Heﬂin, J., Hendler, J., and Luke, S. Applying Ontology to the Web: A Case Study. In: J.
Mira, J. Sanchez-Andres (Eds.), International Work-Conference on Arti ﬁcial and Natural
Neural Networks, IWANN'99. Proceedings, Volume II. Springer, Berlin, 1999. pp.715-724.
http://www.cs.umd.edu/projects/plus/SHOE/iwann99.pdf
Hendler, J., He ﬂin, J., Luke, S., Spector, L., Rager, D. Simple HTML Ontology
Extensions , University of Maryland
http://www.cs.umd.edu/projects/plus/SHOE/
ISO/IEC 13211-1:1995 Information technology -- Programming languages -- Prolog --
Part 1: General core
Knoblock, C. A. and J. L. Ambite (1997). Agents for Information Gathering. Software
Agents . J. Bradshaw. Menlo Park, CA, AAAI/MIT Press: 1-27.
Karger, D. R., Klein, P . N., and Tarjan, R. E., "A Randomized Linear-Time Algorithm
to Find Minimum Spanning Trees." Journal of the ACM , 42(2):321--328, 1995.
Karger, D. R., and Stein, C., "A New Approach to the Minimum Cut Problem." Journal
of the ACM , 43(4):601--640, July 1996. Preliminary portions appeared in SODA 1992 and
STOC 1993.
Karger, D. R., Motwani, R., and Sudan, M., "Approximate Graph Coloring by
Semide ﬁnite Programming." Journal of the ACM , to appear. Preliminary version in
Proceedings of the 35th Annual Symposium on the Foundations of Computer Science , pages
2--13. IEEE, IEEE Computer Society Press, November 1994.
Karger, D. R., "Minimum Cuts in Near-Linear Time." In Proceedings of the 28th ACM
Symposium on Theory of Computing , pages 56--63. ACM, ACM Press, May 1996.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
48 of 52 11/5/09 10:07 AM
Karger, D. R., Lehman, E., Leighton, T., Levine, M., Lewin, D., and Panigrahy, R.,
"Relieving Hot Spots on the World Wide Web." In Proceedings of the 29th ACM
Symposium on Theory of Computing , ACM Press, May 1997.
Koller, D., A. Levy and A. Pfeffer (1997). P-Classic: A tractable probabilistic
description logic. Fourteenth National Conference on Arti ﬁcial Intelligence (AAAI-97),
Providence, RI.
Kumar, D., Ed. (1990). Current Trends in SNePS--Semantic Network Processing System .
Berlin, Springer.
Lassila, O., and Swick, R. [Eds.], (1999), Resource Description Framework (RDF) Model
and Syntax Speci ﬁcation
http://www.w3.org/TR/1999/REC-rdf-syntax-19990222
Levesque, H.J. and Brachman, R.J. (1987). Expressiveness and tractability in
knowledge representation and reasoning. Computational Intelligence  3 78-93.
Lieberman, H., L. A. Stein, and D. Ungar, "Of Types and Prototypes: The Treaty of
Orlando," SIGPLAN Notices  23 (5):43-44 , May 1988.
Low, Aidan. A Folder-Based Graphical Interface for an Information Retrieval System.
Master's Thesis, MIT, May 1999.
Luke, S. and J. He ﬂin. 1997. SHOE 1.0, Proposed Speci ﬁcation.
http://www.cs.umd.edu/projects/plus/SHOE/spec.html
Luke, S., L. Spector, and D. Rager. 1996. Ontology-Based Knowledge Discovery on
the World-Wide Web. In Working Notes of the Workshop on Internet-Based InformationSystems at the 13th National Conference on Arti ﬁcial Intelligence (AAAI96). A. Franz
and H. Kitano, eds. AAAI. 96-102.
http://www.cs.umd.edu/projects/plus/SHOE/aaai-paper.html
MacGregor, R. M. (1991). The Evolving Technology of Classi ﬁciation-based
Knowledge Representation Systems. Principles of Semantic Networks . J. F. Sowa. San
Mateo, California, Morgan Kauffman: 385-400.
MacGregor, R. & Bates, R. (1987). The LOOM knowledge representation language.
Tech Report ISI-RS-87-188, ISI, CA.
McHugh, Jason, Serge Abiteboul, Roy Goldman, Dallan Quass, and Jennifer Widom.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
49 of 52 11/5/09 10:07 AM
Lore: A Database Management System for Semistructured Data." SIGMOD Record,
26(3):54-66, September 1997.
Marchiori, M., Ed. (1999). Platform for Privacy Preferences 1.0 (P3P1.0). World-Wide
Web Consortium. http://www.w3.org/TR/P3P
Neches, R., Fikes, R., Finin, T., Gruber, T., Patil, R., Senator, T., & Swartout, W. (1991).
Enabling technology for knowledge sharing. AI Magazine , pages 36-56.
Raggett, D., Le Hors, A., and Jacobs I., Eds. 1999, HTML 4.01 Speci ﬁcation , W3C
Recommendation
http://www.w3.org/TR/1999/REC-html401-19991224
Roscheisen, M., M. Baldonado, K. Chang, L. Gravano, S. Ketchpel, and A. Paepcke
(1998). "The Stanford InfoBus and Its Service Layers: Augmenting the Internet withHigher-Level Information Management Protocols." Digital Libraries in ComputerScience: the MeDoc Approach, eds. Barht, A., M. Breu, A. Endres and A. de Kemp.Berlin, Germany: Springer-Verlag, pp. 213-230.
Reiter, R. (1980). A logic for default reasoning. Artiﬁcial Intelligence  13 81-132.
Salton, Gerard, James Allan, and Chris Buckley. Automatic Structuring and Retrieval
of Large Text Files. Communications of the ACM, 37(2):97-108, February 1994.
Schmolze, J.G. and Woods, W.A. (1992). The KL-ONE family. Lehmann, F., Ed.
Semantic Networks in Arti ﬁcial Intelligence . pp.133-177. Oxford, Pergamon Press.
Sowa, J.F., Ed. (1991). Principles of Semantic Networks: Explorations in the Representation
of Knowledge . San Mateo, California, Morgan-Kaufman.
Spertus, E., and L. A. Stein, "Just-In-Time Databases and the World-Wide Web,"
Conference on Information and Knowledge Management  , Washington, DC, November 1998,
pp. 30-37.
http://www.mills.edu/ACAD_INFO/MCS/SPERTUS/cikm98.pdf
Spertus, E., and L. A. Stein, "A Relational Database Interface to the World-Wide Web,"
ACM Conference on Digital Libraries , Berkeley, California, August 1999, pp. 248--249.
http://www.acm.org/pubs/citations/proceedings/dl/313238/p248-spertus/
Stein, L. A., "Delegation is Inheritance," Proceedings of the Conference on Object Oriented
Programming Systems, Languages, and Applications , Orlando, Florida, October 1987, pp.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
50 of 52 11/5/09 10:07 AM
138-146. Also appears as Brown University Technical Report CS-87-15 , July 1987.
Stein, L. A., "Compound Type Expressions: Flexible Types in Object Oriented
Programming," Panel Position Paper, Proceedings of the Conference on Object Oriented
Programming Systems, Languages, and Applications , San Diego, California, September
1988, pp. 360-361.
Stein, L. A., Resolving Ambiguity in Nonmonotonic Reasoning . Ph.D. Thesis, Brown
University Department of Computer Science, 1990.
Stein, L. A., "Resolving Ambiguity in Nonmonotonic Inheritance Hierarchies,"
Artiﬁcial Intelligence  55 (2-3): 259-310, June 1992. Earlier version appears as MIT AI Lab
Memo 1316 , August 1991.
Stein, L. A., "Science and Engineering in Knowledge Representation and Reasoning,"
AI Magazine 17 (4):77-83, Winter 1996.
ftp://ftp.ai.mit.edu/pub/users/las/science-and-engineering-in-KR.ps.gz
Stein, L. A., H. Lieberman, and D. Ungar, "A Shared View of Sharing: The Treaty of
Orlando," in Object-Oriented Concepts, Databases, and Applications , W. Kim and F.
Lochovsky, eds., A.C.M. Press, 1989, pp. 31-48.
Stein, L. A. and L. Morgenstern,, "Motivated Action Theory: A Formal Theory of
Causal Reasoning," Artiﬁcial Intelligence  71 (1) :1-42, November 1994. Earlier versions
appear as MIT AI Lab Memo 1338 , December 1991 (postscript, 3.6M); and as Brown
University Technical Report CS-89-12 , March 1989.
ftp://ftp.ai.mit.edu/pub/users/las/motivated-action-theory.ps.Z
Stein, L. A. and S. B. Zdonik, "Clovers: The Dynamic Behavior of Types and
Instances," International Journal of Computer Science and Information Management  1 (3):
1-11, 1998.
http://www.ai.mit.edu/people/las/papers/Clovers/Clovers_Final.pdf
Stoffel, K., M. Taylor and J. Hendler. 1997. Ef ﬁcient Management of Very Large
Ontologies. In Proceedings of American Association for Arti ﬁcial Intelligence
Conference (AAAI-97). AAAI/MIT Press.
Swartout, Bill, Ramesh Patil, Kevin Knight and Tom Russ. "Toward Distributed Use
of Large-Scale Ontologies". In Proceedings of the Tenth Knowledge Acquisition for
Knowledge-Based Systems Workshop , November 9-14, 1996. Banff, Alberta, Canada.PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
51 of 52 11/5/09 10:07 AM
http://ksi.cpsc.ucalgary.ca/KAW/KAW96/swartout/Banff_96_ ﬁnal_2.html
Vilain, M. (1991). Deduction as parsing: tractable classi ﬁcation in the KL-ONE
framework.
Wobber, E., Abadi, M., Burrows, M., Lampson, B. (1993) Authentication in the Taos
Operating System , Technical Report, DEC Systems Research Center, Number 117,
http://gatekeeper.dec.com/pub/DEC/SRC/research-reports/abstracts/src-rr-117.html
Woods, W.A. (1975). What's in a link: Foundations for semantic networks. Bobrow,
D.G. and Collins, A.M., Ed. Representation and Understanding: Studies in Cognitive Science .
pp.35-82. New York, Academic Press.
Yen, John, Robert Neches, and Robert MacGregor. "CLASP: Integrating Term
Subsumption Systems and Production Systems." In IEEE Transactions on Knowledge and
Data Engineering , Vol. 3, No. 1, pp. 25-32, 1991.
PROPOSAL: Semantic Web Development http://www.w3.org/2000/01/sw/DevelopmentProposal
52 of 52 11/5/09 10:07 AM
