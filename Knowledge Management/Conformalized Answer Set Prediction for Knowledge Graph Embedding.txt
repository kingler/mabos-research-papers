Conformalized Answer Set Prediction for Knowledge Graph Embedding
Yuqicheng Zhu†‡, Nico Potyka§, Jiarong Pan‡∗, Bo Xiong†
Yunjie He†‡, Evgeny Kharlamov‡♭, Steffen Staab†♮
†University of Stuttgart,‡Bosch Center for AI,§Cardiff University,
♭University of Oslo,♮University of Southampton,∗Eindhoven University
yuqicheng.zhu@de.bosch.com
Abstract
Knowledge graph embeddings (KGE) ap-
ply machine learning methods on knowledge
graphs (KGs) to provide non-classical reason-
ing capabilities based on similarities and analo-
gies. The learned KG embeddings are typically
used to answer queries by ranking all potential
answers, but rankings often lack a meaning-
ful probabilistic interpretation - lower-ranked
answers do not necessarily have a lower prob-
ability of being true. This limitation makes it
difficult to distinguish plausible from implausi-
ble answers, posing challenges for the applica-
tion of KGE methods in high-stakes domains
like medicine. We address this issue by ap-
plying the theory of conformal prediction that
allows generating answer sets, which contain
the correct answer with probabilistic guaran-
tees. We explain how conformal prediction can
be used to generate such answer sets for link
prediction tasks. Our empirical evaluation on
four benchmark datasets using six representa-
tive KGE methods validates that the generated
answer sets satisfy the probabilistic guarantees
given by the theory of conformal prediction.
We also demonstrate that the generated answer
sets often have a sensible size and that the size
adapts well with respect to the difficulty of the
query.
1 Introduction
Knowledge Graph Embeddings (KGE) map en-
tities and predicates into numerical vectors, pro-
viding non-classical reasoning capabilities by ex-
ploiting similarities and analogies between en-
tities and relations (Wang et al., 2017; Biswas
et al., 2023). KGE models are typically evalu-
ated through link prediction (Bordes et al., 2013;
Sun et al., 2019; Nickel et al., 2011). To answer
queries in the form of ⟨head entity ,predicate ,?⟩or
⟨?,predicate ,tail entity ⟩, all possible entities are
ranked according to their plausibility scores re-
turned by the KGE models. Higher-ranked po-sitions of the correct answers indicate better model
performance.
However, ranking all possible entities has lim-
ited practical value, since the rankings do not dis-
tinguish plausible answers from implausible ones
with high quality. It is crucial to provide tight
answer sets that provably cover the true answer ,
particularly in high-stakes domains like medicine,
where reliable predictions and risk assessment are
critical.
Identifying a set of plausible answer entities
from the entire entity set is challenging. KGE mod-
els are trained to assign higher plausibility scores
to true triples than to false ones. However, due to
the lack of ground truth negative triples in KGs,
negative examples used for training are typically
generated by corrupting existing triples (Bordes
et al., 2013; Sun et al., 2019). Some of the gen-
erated negative samples may actually be valid but
unobserved triples, which can mislead the KGE
model and result in incorrect plausibility scores.
Furthermore, the training process uses gradient
descent-based optimization techniques (Rumelhart
et al., 1986), which do not guarantee convergence
to the global optimum. As a result, the plausibility
scores returned by KGE models not only fail to
ensure correct triple ranking, but they also lack a
clear probabilistic interpretation, meaning they do
not correspond to the actual likelihood of a triple
being true (i.e., they are uncalibrated). Therefore,
constructing answer sets based on the uncalibrated
plausibility scores can lead to somewhat arbitrary
result sets.
Prior works suggest to apply off-the-shelf cali-
bration techniques, such as Platt scaling (Platt et al.,
1999) and Isotonic regression (Kruskal, 1964), to
map uncalibrated plausibility scores to the expected
correctness of predictions (Tabacof and Costabello,
2020; Safavi et al., 2020). However, perfect calibra-
tion is impossible in practice (Gupta et al., 2020),
both Platt scaling and Isotonic regression are em-arXiv:2408.08248v1  [cs.AI]  15 Aug 2024
pirical calibration techniques that lack formal prob-
abilistic guarantees and are highly sensitive to the
calibration set.
In contrast, our work diverges from these ap-
proaches by applying the theory of conformal pre-
diction (V ovk et al., 2005) to construct answer sets
with formal statistical guarantees. Intuitively, con-
formal prediction tests whether each possible an-
swer to a query conforms to the existing query-
answer pairs (triples) in the training set. The an-
swer set is then constructed by including all an-
swers that do not reject the true hypothesis. To
the best of our knowledge, this is the first method
that does not merely convert plausibility scores into
probabilities but instead ensures statistical validity
in the uncertainty quantification of the predictions
within the context of KGE.
Conformal prediction is a general framework
rather than a specific algorithm. In our paper, we
carefully design conformal predictors tailored to
the link prediction task such that the answer sets
are (1) probabilistically guaranteed to include the
true answer entity at a specified confidence level,
(2) tight, and (3) adaptive, providing smaller sets
for easier queries than harder ones. We perform ex-
tensive experiments on commonly used benchmark
datasets and a variety of KGE methods. Our em-
pirical results show that: (1) conformal predictors
satisfy the statistical guarantees in Proposition 1
and produce tighter answer sets compared to other
baselines (Experiments 1); (2) conformal predic-
tors generate answer sets that adapt to query diffi-
culty, yielding smaller sets for easier queries than
for harder ones (Experiment 2); (3) high-quality an-
swer sets can be obtained with a relatively small cal-
ibration set (Experiment 3); and (4) conformal pre-
dictors are effective across different user-specified
error rates (Experiment 4).
2 Related Work
Uncertainty quantification in KGE methods re-
mains a relatively unexplored area. Existing ap-
proaches incorporate uncertainty into KGE by mod-
eling entities and relations using probability distri-
butions (He et al., 2015; Xiao et al., 2016). How-
ever, these methods primarily focus on enhancing
the performance of KGE models through more ex-
pressive representations, without systematically an-
alyzing or rigorously evaluating the quality of un-
certainty in embeddings or predictions.
Furthermore, research by Tabacof and Costa-bello (2020) and Safavi et al. (2020) applies off-the-
shelf calibration techniques, such as Platt scaling
and Isotonic regression, to KGE methods. These
techniques aim to convert uncalibrated plausibility
scores into probabilities by minimizing the nega-
tive log-likelihood on a validation set. However,
these approaches are quite sensitive to the valida-
tion set and do not provide formal guarantees about
the generated probabilities.
This paper applies conformal prediction, which
has its roots in online learning literature, is a
method that produces predictive sets ensuring cov-
erage guarantees (V ovk et al., 2005). This ap-
proach has been successfully applied across var-
ious domains, including image classification (An-
gelopoulos et al., 2021), natural language pro-
cessing (Maltoudoglou et al., 2020) and node
classification/regression on graphs (Huang et al.,
2024; Zargarbashi et al., 2023; Zargarbashi and
Bojchevski, 2023). However, to the best of our
knowledge, it has not yet been applied to KGE.
3 Preliminaries
3.1 Knowledge Graph Embedding
We consider a knowledge graph (KG) G ⊆ E×
R×Edefined over a set Eof entities and a set
Rof relation names. The elements in Gare called
triples and denoted as < h, r, t > . A KGE model
Mθ:E×R×E→Rassociates each triple
with a score that measures the plausibility that the
triple holds. The parameters θare learned to let
Mθassign higher plausibility scores to positive
triples (real facts) while assigning lower plausibil-
ity scores to negative triples (false facts).
Note that the interpretation of plausibility scores
varies across different types of KGE methods. In
distance-based models like TransE (Bordes et al.,
2013) and RotatE (Sun et al., 2019), the plausibility
score is determined by the negative distance in the
embedding space. In semantic matching models
such as RESCAL (Nickel et al., 2011) and DistMult
(Yang et al., 2015), plausibility scores are derived
from similarity measures (often computed through
the dot product of entity embeddings).
3.2 Conformal Prediction
Conformal prediction (a.k.a conformal inference) is
a general framework for producing answer sets that
cover the ground truth with probabilistic guarantees
(V ovk et al., 2005). In this section, we recall some
basics from (V ovk et al., 2005; Shafer and V ovk,
2008).
Let(xi, yi)denote a data point with an object
xiand its label yi. The objects are elements of
anobject space X, and the labels are elements of
alabel space Y. For a more compact notation,
we write zifor(xi, yi), and call Z:=X × Y
theexample space . Furthermore, we let Z1:n=
{z1, . . . z n} ⊆ Z be the set of nexamples and
denote Z∗as the set of all possible example sets.
A conformal predictor Γ :Z∗× X → 2Yaims
to predict a subset of Ylarge enough to cover the
ground truth with high probability. Given a training
setZ1:nand any new object xn+1∈ X, the confor-
mal predictor Γshould, for every probability of er-
rorϵ∈(0,1), produce a answer set Γϵ(Z1:n, xn+1)
for the input object xn+1that contains the ground
truth label yn+1with probability at least 1−ϵ.
Moreover, the answer sets are required to shrink as
ϵincreases: Γϵ1⊆Γϵ2whenever ϵ1≥ϵ2.
To specify such a conformal predictor, we first
need to define a nonconformity measure S:Z∗×
Z →R.S(Z1:n, zn+1)measures how unusual the
example zn+1is as an element of Z1:n. Given any
such a nonconformity measure S, if we construct
the answer set Γϵ(Z1:n, xn+1)by including all y∈
Ysuch that
|{i= 1, . . . , n + 1 : αi≥αn+1}|
n+ 1> ϵ, (1)
where
αi:=S(Z1:n∪ {(xn+1, y)},(xi, yi)), i= 1, . . . , n
αn+1:=S(Z1:n∪ {(xn+1, y)},(xn+1, y)),
then we have following probabilistic guarantees:
Theorem 1 (V ovk et al. (2005); Lei et al. (2018)) .
Suppose nis large, and a set of examples Z1:n+1
are independent and identically distributed (i.i.d.).
Given ϵ∈(0,1), the answer set of the ob-
jectxn+1constructed by a conformal predictor
Γϵ(Z1:n, xn+1)cover the ground truth yn+1at
least with probability 1−ϵ
P(yn+1∈Γϵ(Z1:n, xn+1))≥1−ϵ (2)
furthermore, if there are no ties between αi, then it
is also holds that
P(yn+1∈Γϵ(Z1:n, xn+1))≤1−ϵ+1
n+ 1(3)
The proof of Equation 2 is provided in (V ovk
et al., 2005, section 2.1.3). Intuitively, the construc-
tion of Γϵ(Z1:n, xn+1)can be understood as an ap-
plication of the widely accepted Neyman-Pearsontheory (Lehmann et al., 1986) for hypothesis testing
and confidence intervals (Shafer and V ovk, 2008).
Here, we test for all y∈ Y that the hypothesis
H(the example (xn+1, y)conforms to Z1:n) by
evaluating the nonconformity score of (xn+1, y).
We construct the answer set by including all y, for
which (xn+1, y)is not rejected by the test.
Additionally, the proof of Equation 3 is detailed
in (Lei et al., 2018, Appendix A.1). Notably, the
theorem remains valid under the weaker assump-
tion of exchangeability (V ovk et al., 2005, section
2.1.1).
4 KGE-based Answer Set Prediction
In this section, we formally define the KGE-based
answer set prediction task and outline three key
desiderata guiding the development of effective set
predictors. We then introduce and discuss several
basic set predictors.
4.1 Problem Definition and Desiderata
We reformulate the link prediction task as an an-
swer set prediction task. Instead of object-label
pairs(xi, yi)in section 3, each data point is a triple
tr(qi, ei). Here, qidenotes a query in form of ei-
ther⟨h, r,?⟩or⟨?, r, t⟩, and tr(q, e)corresponds
to the respective triple ⟨h, r, e⟩or⟨e, r, t⟩.
Given a set of (training) triples T1:n=
{tr(q1, e1), . . . , tr (qn, en)}, a test query qn+1and
a user-specific error rate ϵ, we aim to predict a
set of entities ˆC(qn+1)⊆Ethat covers the true
answer en+1with probability at least 1−ϵ.
P(en+1∈ˆC(qn+1))≥1−ϵ (4)
We refer to Equation 4 as the coverage desidera-
tum. However, this criterion alone is insufficient,
as it can be trivially met by a predictor that al-
ways outputs sets containing all possible answers.
To develop sensible set predictors, we also con-
sider the size desideratum and the adaptiveness
desideratum . The size desideratum emphasizes the
need for smaller sets, as smaller sets are generally
more informative. The adaptiveness desideratum
requires that the set sizes reflect query difficulty:
smaller sets should correspond to easier queries,
while larger sets should be used for harder queries.
4.2 Basic Set Predictors
Naive Predictor . Given a query, assume the KGE
model provides the probability of each possible
answer entity being true. A straightforward ap-
proach towards our goal is to construct the set by
including entities from highest to lowest probabil-
ity until their sum exceeds the threshold 1−ϵ. We
refer to this approach as the naive predictor and
provide its pseudocode in Algorithm 2 (Appendix
A). However, the plausibility scores provided by
KGE models are not calibrated. We convert these
plausibility scores into a "probability distribution"
using a softmax function.
Platt Predictor . Following the recommenda-
tions of (Tabacof and Costabello, 2020; Safavi
et al., 2020), we improve the naive predictor by
using a multiclass Platt scaling (Guo et al., 2017)
to calibrate the plausibility scores and then con-
struct sets based on these calibrated probabilities.
We refer to this method as the Platt predictor and
provide more details of this predictor in Appendix
A.2.
TopK Predictor . Another straightforward ap-
proach is to construct the set with the Top-K entities
from the ranking, referred to as the topk predictor.
We select Kto ensure the Top-K entities cover the
correct answers for 1−ϵof the validation queries.
5 Conformal Prediction for KGE-based
Answer Set Prediction
To improve the basic set predictors, we apply con-
formal prediction, a general framework that re-
quires adaptation to be effective in the context of
KGE. The two essential components in this design
are the nonconformity measure and the method
for constructing answer sets. In this section, we
propose several KGE-specific nonconformity mea-
sures and outline an efficient approach to construct-
ing answer sets.
5.1 Nonconformity Measures
The probabilistic guarantees in Theorem 1 hold
under i.i.d assumption, regardless of the data dis-
tribution or the definition of the nonconformity
measure. However, the size of the resulting answer
sets depends on how effectively the nonconformity
measure captures the underlying structure of the
data. Next, we introduce several nonconformity
measures for KGE models and explain the ratio-
nale behind each one.
Formally, given a set of training triples T1:nand
a test triple tn+1:=tr(qn+1, en+1), the nonconfor-
mity measure S(T1:n, tn+1)estimates how unusual
the triple tn+1is as a part of T1:n.NegScore . The underlying idea of KGE meth-
ods is to assign higher plausibility scores to positive
triples and lower scores to negative triples. There-
fore, a natural choice for the nonconformity score
is the negative value of the plausibility score. The
intuition here is that a lower plausibility score indi-
cates a higher nonconformity, suggesting that the
triple is less consistent with the existing triples rep-
resented in the training set. Formally, let MT1:n
denote a KGE model trained on T1:n, then the cor-
responding nonconformity measure is defined as
S(T1:n, tn+1) =−MT1:n(tn+1) (5)
Minmax . While the NegScore predictor di-
rectly uses the raw plausibility scores, the scale of
these scores can vary significantly across different
queries, potentially affecting the consistency and re-
liability of the nonconformity measure. To address
this, we normalize the scores for each query using
min-max scaling. This ensures that the nonconfor-
mity score reflects not only the raw plausibility but
also the relative position of the triple within the
score distribution for all possible triples in a given
query. We then define the nonconformity measure
as
S(T1:n, tn+1) =−MT1:n(tn+1), (6)
where
M(tr(q, e)) = (7)
M(tr(q, e))−mine′∈EM(tr(q, e′))
max e′∈EM(tr(q, e′))−mine′∈EM(tr(q, e′)).
(8)
Softmax . Another approach to normalizing plau-
sibility scores is by using the softmax function,
which converts the plausibility scores into a (uncal-
ibrated) "probability distribution" over all possible
answers for a given query. Unlike min-max scaling,
Softmax scaling is more sensitive to the relative
differences between scores, naturally highlighting
the most likely triples while acknowledging others.
This can result in more nuanced nonconformity
measures, especially when the score distribution
has varying degrees of separation between true and
false triples. The nonconformity score is then de-
fined as the of softmax outputs and the "ground
truth" probability, which is assumed to be 1for the
true answer.
S(T1:n, tn+1) = 1−ˆMT1:n(tn+1), (9)
where
ˆM(tr(q, e)) =exp(M(tr(q, e)))P
e′∈Eexp (M(q, e′)).(10)
5.2 Answer Set Construction
If we construct answer sets as describe in Sec-
tion 3, we need to retrain the KGE model with
T1:n∪ {tr(qn+1, e)}and recalculate the noncon-
formity scores of training triples for testing each
triple tr(qn+1, e)(for all e∈E). It is computa-
tionally not feasible for KGE methods, given the
huge number of possible entities e∈Eand the
time-consuming training and hyper-parameter tun-
ing process.
We adopt so called split/inductive conformal pre-
diction (V ovk et al., 2005; Lei et al., 2015) to ad-
dress this issue (see Algorithm 1 for details). The
training set of size nis first divided into a proper
training set T1:mof size m < n and a calibra-
tion set Tm+1:nof size n−m. Rather than using
the entire training set to train the KGE model and
evaluate nonconformity scores, we train the KGE
model once on the proper training set T1:mand use
it to calculate the nonconformity scores on the cal-
ibration set Tm+1:n. Intuitively, if the calibration
set is chosen randomly and is sufficiently large, its
empirical coverage should closely match the true
coverage probability for a new query. This strategy
significantly increases the efficiency of the confor-
mal predictors while preserving the probabilistic
guarantees in Theorem 1 (Lei et al., 2018).
Formally, in split conformal prediction, if we
construct answer sets by including all entity e∈E
such that
|{i=m+ 1, . . . , n + 1 : αi≥αn+1}|+ 1
n−m+ 1> ϵ,
(11)
where
αi:=S(T1:m, tr(qi, ei)), i=m+ 1, . . . , n
αn+1:=S(T1:m, tr(qn+1, e)).
We have the following proposition:
Proposition 1 (Lei et al. (2015), Theorem 2.2) .
Given a set of triples T1:n+1that are i.i.d, an error
rateϵ∈(0,1)and any nonconformity measure S.
Ifnis large, the answer set of a test query ˆC(qn+1)
constructed following Equation 11 satisfies
P(en+1∈ˆC(qn+1))≥1−ϵ (12)furthermore, if there are no ties between noncon-
formity scores in the calibration set Tm+1:n, we
have
P(en+1∈ˆC(qn+1))≤1−ϵ+1
n−m+ 1(13)
The proof of Proposition 1 can be found in (Lei
et al., 2018, Appendix A.1)1. Note that the addi-
tional assumption for Equation 13 is a quite weak
assumption, by using a random tie-breaking rule,
this assumption could be avoided entirely.
Algorithm 1 Pseudocode for Split Conformal Pre-
diction.
Require: A training set T1:m, a calibration set
Tm+1:n, a testing query qn+1, an error rate ϵ
and a nonconformity measure S.
1:
2:▷Calibration Step
3:L′←an empty set
4:for each triple tr(q′, e′)inTm+1:ndo
5: L′←L′∪ {S(T1:m, tr(q′, e′))}
6:end for
7:t← ⌈(|Tm+1:n|+ 1)(1 −ϵ)/|Tm+1:n|⌉
8:τ←tth quantile of elements in L′
9:
10:▷Prediction Step
11:L←an empty set
12:for each entity einEdo
13: L←L∪ {(e, S(T1:m, tr(qn+1, e))}
14:end for
15:ˆC(qn+1)←an empty set
16:for(e, s)inLdo
17: ifs < τ then
18: ˆC(qn+1)←ˆC(qn+1)∪ {e}
19: end if
20:end for
21:return ˆC(qn+1)
6 Experiments
In this section, we present five experiments that
evaluate the quality of the answer sets from (base-
line) predictors in Section 4 ( naive ,Platt ,topk) and
conformal predictors ( NegScore ,Softmax ,Minmax )
in Section 5 based on coverage, size and adaptive-
ness desiderata.
In our experiments, we use four commonly
used benchmark link prediction datasets: WN18
1Unlike (Lei et al., 2018), we split the training set unevenly,
resulting in slight differences in Equation 13.
WN18 FB15k
model MR methods coverage size model MR methods coverage size
naive 0.44 (0.004) 12.28 (1.262) naive 0.73 (0.001) 258.14 (0.834)
Platt 0.85 (0.002) 4043.41 (89.765) Platt 0.84 (0.002) 1197.64 (45.923)
topk 0.90 (0.000) 48.01 (0.739) topk 0.90 (0.000) 336.68 (1.332)
NegScore 0.90 (0.001) 20.99 (0.587) NegScore 0.90 (0.001) 45.18 (0.280)
Softmax 0.90 (0.001) 112.80 (4.650) Softmax 0.90 (0.000) 414.88 (2.390)TransE 245.82 (6.368)
Minmax 0.90 (0.001) 113.57 (5.098)TransE 43.05 (0.176)
Minmax 0.90 (0.000) 275.27 (3.217)
naive 0.91 (0.003) 17690.17 (117.856) naive 0.71 (0.003) 748.09 (5.216)
Platt 0.90 (0.002) 16950.17 (116.477) Platt 0.88 (0.002) 1156.33 (7.552)
topk 0.90 (0.001) 50.85 (2.440) topk 0.90 (0.000) 408.43 (3.752)
NegScore 0.90 (0.002) 1.27 (0.010) NegScore 0.90 (0.001) 52.31 (0.605)
Softmax 0.90 (0.001) 1.91 (0.249) Softmax 0.90 (0.000) 140.36 (3.196)RotatE 478.13 (44.173)
Minmax 0.90 (0.003) 3.88 (0.698)RotatE 61.77 (0.976)
Minmax 0.90 (0.001) 42.35 (1.064)
naive 0.58 (0.011) 300.09 (24.737) naive 0.58 (0.016) 121.14 (13.125)
Platt 0.80 (0.005) 2021.25 (223.393) Platt 0.87 (0.003) 615.92 (24.759)
topk 0.90 (0.001) 54.46 (1.640) topk 0.90 (0.000) 394.18 (2.357)
NegScore 0.91 (0.001) 45.50 (3.630) NegScore 0.90 (0.001) 168.64 (4.506)
Softmax 0.90 (0.001) 2.14 (0.062) Softmax 0.90 (0.000) 72.61 (0.491)RESCAL 321.73 (21.501)
Minmax 0.90 (0.002) 2.02 (0.075)RESCAL 65.52 (1.815)
Minmax 0.90 (0.001) 79.62 (5.573)
naive 0.47 (0.002) 36.54 (7.024) naive 0.35 (0.013) 19.47 (0.897)
Platt 0.84 (0.001) 1265.82 (205.375) Platt 0.90 (0.001) 485.01 (2.341)
topk 0.90 (0.001) 57.48 (2.439) topk 0.90 (0.000) 362.91 (1.414)
NegScore 0.90 (0.001) 2244.87 (405.033) NegScore 0.90 (0.000) 156.02 (2.872)
Softmax 0.90 (0.001) 2.02 (0.047) Softmax 0.90 (0.000) 28.40 (0.421)DistMult 370.21 (20.313)
Minmax 0.90 (0.002) 1.51 (0.049)DistMult 45.13 (0.556)
Minmax 0.90 (0.000) 40.35 (0.894)
naive 0.94 (0.007) 19968.55 (142.153) naive 0.28 (0.011) 50.24 (1.309)
Platt 0.86 (0.002) 16788.25 (125.356) Platt 0.90 (0.001) 922.43 (9.375)
topk 0.91 (0.002) 40.58 (1.811) topk 0.90 (0.000) 414.06 (4.429)
NegScore 0.90 (0.003) 1.47 (0.008) NegScore 0.90 (0.001) 99.11 (9.237)
Softmax 0.90 (0.001) 1.10 (0.007) Softmax 0.90 (0.001) 37.20 (0.927)ComplEx 454.21 (27.914)
Minmax 0.90 (0.002) 2.83 (0.171)ComplEx 66.87 (1.603)
Minmax 0.90 (0.001) 118.43 (20.418)
naive 0.50 (0.015) 3.42 (1.423) naive 0.45 (0.026) 819.05 (111.870)
Platt 0.84 (0.007) 79.09 (1.785) Platt 0.88 (0.014) 4824.48 (699.253)
topk 0.90 (0.001) 53.21 (1.475) topk 0.90 (0.000) 386.02 (3.107)
NegScore 0.90 (0.002) 1.50 (0.067) NegScore 0.90 (0.000) 44.39 (2.225)
Softmax 0.90 (0.001) 1.57 (0.090) Softmax 0.90 (0.000) 79.30 (6.029)ConvE 311.27 (12.598)
Minmax 0.90 (0.001) 1.34 (0.028)ConvE 67.56 (1.644)
Minmax 0.90 (0.000) 48.31 (8.576)
Table 1: Quality of the filtered answer sets on WN18 and FB15k datasets. This table presents the mean rank (MR) of
KGE models (lower is better), along with the coverage and size of answer sets generated using various set predictors.
Conformal predictors are underlined. Means and standard deviations (in the brackets) over 15 trials are reported at
the10% level ( ϵ= 0.1). Predictors that fail to meet the coverage threshold of 1−ϵ(0.9) are highlighted in red. The
best predictors, which meet the coverage desideratum and minimize answer set size, are highlighted in bold.
(Bordes et al., 2013), WN18RR (Dettmers et al.,
2018), FB15k (Bordes et al., 2013) and FB15k237
(Toutanova and Chen, 2015) and six representative
KGE methods: TransE (Bordes et al., 2013), Ro-
tatE (Sun et al., 2019), RESCAL (Nickel et al.,
2011), DistMult (Yang et al., 2015), ComplEx
(Trouillon et al., 2016) and ConvE (Dettmers et al.,
2018). We provide more information about the
experimental settings in Appendix B.
6.1 Experiment 1: Coverage and Set Size on
WN18 and FB15k
A good set predictor should cover the true answer
with a probability of at least 1−ϵ(coverage desider-
atum) and predict smaller sets (size desideratum).
In this experiment, we evaluate desiderata by mea-
suring the coverage (i.e., P(en+1∈ˆC(qn+1))) and
the average size of answer sets for each method.Each procedure is repeated 15 times, and we re-
port the mean and standard deviation (in brackets)
across trials in Table 1. As usual in the evaluation
of link prediction, for each query, we consider only
answer candidates that did not already occur in the
training and validation data.
As demonstrated in Proposition 1, conformal
predictors consistently meet the coverage desider-
atum, with coverage tightly concentrated around
1−ϵ. Compared to baseline predictors that also
satisfy the coverage desideratum, conformal predic-
tors outperform them in terms of producing smaller
answer sets, thus better satisfying the size desidera-
tum.
The naive predictor, on the other hand, fre-
quently fails to meet the coverage desideratum,
often providing lower coverage than necessary, in-
dicating that the plausibility scores are generally
overconfident. While applying a calibration tech-
nique to the naive predictor (Platt predictor) im-
proves coverage, it still does not meet the coverage
guarantee, and the resulting significant increase in
set size makes it impractical for use.
The topk predictor meets the coverage desidera-
tum but generally produces larger and fixed-sized
answer sets compared to the conformal predictors.
In Appendix A.3, we also discuss simpler fixed-
sized predictors and compare them to the topk pre-
dictor. It is worth noting that the topk predictor can
be viewed as a specific case of the conformal pre-
dictor, where the nonconformity score is defined
by the rank position.
Additionally, we observed that there is no uni-
versally optimal nonconformity score for confor-
mal predictors; the choice is model- and dataset-
dependent. For instance, NegScore seems to better
capture the nonconformity of triples in distance-
based models (TransE, RotatE), while Softmax
and Minmax scores are more suitable for semantic
matching models (RESCAL, DistMult, and Com-
plEx).
The calibration technique in (Tabacof and Costa-
bello, 2020; Safavi et al., 2020) should theoretically
enhance the design of the nonconformity measure
and thereby improve the conformal predictor. How-
ever, in our setting, it fails to do so. The results are
presented in Table 7, with a discussion of potential
reasons provided in the Appendix C.
Due to space constraints, additional results, in-
cluding those without filtering existing answers
and results from more datasets, are provided in Ap-
pendix D. The conclusions are consistent across all
scenarios.
6.2 Experiment 2: Adaptiveness of Answer
Sets
This experiment aims to determine whether the size
of answer sets adapts well to the difficulty of the
query. Unfortunately, there is no well justified way
to evaluate query difficulty at the moment. We
therefore follow the experimental protocol used in
(Angelopoulos et al., 2021) for computer vision
tasks. The authors evaluate difficulty by looking at
the rank of the true label in the ranking obtained
from the classifier by ordering labels according to
their softmax-probabilities. The higher the rank,
the more difficult the query. Analogously, we use
the rank of the true answer given by the KGE model
to evaluate query difficulty.
We categorize queries by difficulty levels basedon the rank of the true answer (e.g., 1-100, 101-
200, etc.). For each difficulty level, we calculate
the average size of answer sets. Figure 1 illustrates
the size of answer sets stratified by query difficulty.
The x-axis represents rank intervals from 1 to 3000,
segmented into 100-rank bins (reflecting different
difficulty levels), while the y-axis shows the aver-
age size of answer sets within each interval.
We observe that the size of answer sets gener-
ated by conformal predictors closely aligns with
the difficulty levels of the queries, thereby fulfilling
the adaptiveness desideratum. This is a valuable
property because, in practice, the true answer to a
query is unknown. By examining the size of the an-
swer set, we can estimate the predictive uncertainty
for the query.
6.3 Experiment 3: Impact of Calibration Set
Size on Answer Set Quality
In this experiment, we investigate the impact of
size of the calibration set, Tm+1:n, on the quality of
answer sets in terms of coverage and size desider-
ata. We randomly sampled calibration sets of 10,
100, 200, and 500 triples from the validation set
for use in conformal prediction. We then evaluated
the coverage and average size of the resulting an-
swer sets. This process was repeated 20 times to
compute the mean and standard deviation of the
results. For comparison, we also evaluated the an-
swer sets generated using the entire validation set
as the calibration set.
As shown in Proposition 1, the coverage of con-
formal predictors with an i.i.d calibration set should
fall between 1−ϵand1−ϵ+1
n−m, where n−m
is the size of the calibration set. This is confirmed
by the results in Table 2. The size of answer sets
generated by split conformal predictors depends on
the alignment between the distribution of noncon-
formity scores in the calibration set and those in
the original training set (which includes both the
proper training set and the calibration set). A larger
calibration set typically better represents the origi-
nal training set, leading to tighter answer sets, as
confirmed by the results in Table 2. Notably, even
with a relatively small calibration set, the quality of
the answer sets closely approximates that obtained
using the entire validation set.
6.4 Experiment 4: Impact of Error Rate on
Answer Set Quality
In this experiment, we examine the effect of the
user-specified error rate ( ϵ) on the quality of answer
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer010002000300040005000Size of Prediction SetsRESCAL+NegScore on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRESCAL+Softmax on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRESCAL+Minmax on FB15k237Figure 1: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on RESCAL models) on the FB15k237 dataset, more results
can be found in Figure 3 - 14 in Appendix.
Predictor Size of Calibration Set Coverage Size
NegScore10 0.98 (0.018) 7626.93 (6145.132)
100 0.91 (0.019) 54.67 (18.268)
200 0.91 (0.014) 50.88 (12.725)
500 0.90 (0.010) 47.58 (6.891)
Entire validation set 0.90 (-) 46.26 (-)
Softmax10 0.97 (0.002) 8604.95 (7395.591)
100 0.91 (0.018) 2.70 (1.158)
200 0.91 (0.012) 2.31 (0.591)
500 0.90 (0.008) 2.07 (0.255)
Entire validation set 0.90 (-) 2.07 (-)
Minmax10 0.96 (0.03) 2796.73 (546.911)
100 0.91 (0.020) 2.24 (0.671)
200 0.91 (0.016) 2.18 (0.390)
500 0.90 (0.009) 1.99 (0.145)
Entire validation set 0.90 (-) 1.94 (-)
Table 2: This table shows the coverage and size (with
means and standard deviations over 20 trials) of answer
sets generated by different predictors using varying sizes
of calibration sets on the WN18 dataset.
sets. Figure 2 illustrates how ϵinfluences the size
of answer sets (upper diagram) and the coverage of
answer sets (lower diagram) across various predic-
tors. The red line in lower diagram correspond to
the desired coverage 1−ϵ.
As expected, the size of answer sets decreases
asϵincreases, aligning with the requirements dis-
cussed in Section 3. The topk and conformal pre-
dictors consistently generate smaller answer sets
compared to the naive and Platt predictors. No-
tably, conformal predictors produce the most com-
pact answer sets when the error rate is set to a very
low value. In terms of coverage, conformal predic-
tors consistently meet the probabilistic guarantee
in Proposition 1 across the range of ϵvalues.
7 Discussion
Our method predicts answer sets for queries with
a guaranteed coverage of the true answer at a pre-
specified probability, such as 90%, while maintain-
ing a small average size. Unlike ranking-based
0.20 0.15 0.10 0.05
01000200030004000Size of Prediction Setsnaive
Platt
topk
NegScore
Softmax
Minmax
0.20 0.15 0.10 0.05
0.00.20.40.60.81.0Coveragenaive
Platttopk
NegScoreSoftmax
Minmax
target coverageFigure 2: This figure shows how the coverage and size
of answer sets change with respect to ϵacross different
predictors on the WN18 dataset.
outputs, our approach is particularly well-suited for
decision-making in high-stakes domains, includ-
ing medical diagnosis, drug discovery, and fraud
detection. For instance, a doctor could use our
method to automatically eliminate a large number
of irrelevant diseases, thereby referring the patient
to the most appropriate specialists. Additionally,
our method is easy to implement and is compati-
ble not only with any KGE models but also with
embedding methods capable of answering more
complex queries, such as Query2Box (Ren et al.,
2020) and CQD (Arakelyan et al.).
The adaptability of our answer sets to the un-
certainty of queries also enables our method to
quantify the predictive uncertainty of KGE models.
This feature broadens the applicability of our ap-
proach by systematically identifying hard or uncer-
tain queries during testing. Detecting such queries
can help identify potential failure cases or outliers,
alerting users when the model’s predictions may be
unreliable.
8 Limitations
A limitation of our method is the requirement to di-
vide the training set into two parts: one for training
the model and another for calculating the noncon-
formity scores, due to the adoption of split confor-
mal prediction. This division reduces the number
of triples available for model training. However,
this issue is mitigated by the fact that the validation
set, typically reserved for hyperparameter tuning,
can also serve as the calibration set. Moreover, as
demonstrated in Experiment 4, even a small subset
of the validation set is sufficient to produce nearly
optimal answer sets.
Another limitation is that the probabilistic guar-
antee provided by Theorem 1 and Proposition 1
relies on the i.i.d. assumption, which may not
hold under distribution shifts. We are currently
extending our conformal predictors to covariant
shift case, where only the input distribution P(X)
changes while the conditional distribution P(Y|X)
remains the same. We begin with the simpler sce-
nario where the likelihood ratio between the train-
ing and test distributions is known. Following (Tib-
shirani et al., 2019), we weight each nonconformity
score proportionally to the likelihood ratio to en-
sure the probabilistic guarantee in Proposition 1
holds beyond the i.i.d. assumption.
References
Anastasios Nikolas Angelopoulos, Stephen Bates,
Michael I. Jordan, and Jitendra Malik. 2021. Un-
certainty sets for image classifiers using conformal
prediction. In ICLR . OpenReview.net.
Erik Arakelyan, Daniel Daza, Pasquale Minervini, and
Michael Cochez. Complex query answering with
neural link predictors. In International Conference
on Learning Representations .
James Bergstra and Yoshua Bengio. 2012. Random
search for hyper-parameter optimization. Journal of
machine learning research , 13(2).
Russa Biswas, Lucie-Aimée Kaffee, Michael Cochez,
Stefania Dumbrava, Theis E Jendal, Matteo Lissan-
drini, Vanessa Lopez, Eneldo Loza Mencía, Heiko
Paulheim, Harald Sack, et al. 2023. Knowledge
graph embeddings: open challenges and opportu-
nities. Transactions on Graph Data and Knowledge ,
1(1):4–1.Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. Advances in neural information pro-
cessing systems , 26.
Samuel Broscheit, Daniel Ruffinelli, Adrian Kochsiek,
Patrick Betz, and Rainer Gemulla. 2020. LibKGE - A
knowledge graph embedding library for reproducible
research. In Proceedings of the 2020 Conference on
Empirical Methods in Natural Language Processing:
System Demonstrations , pages 165–174.
Tim Dettmers, Pasquale Minervini, Pontus Stenetorp,
and Sebastian Riedel. 2018. Convolutional 2d knowl-
edge graph embeddings. In Proceedings of the AAAI
conference on artificial intelligence , volume 32.
Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Wein-
berger. 2017. On calibration of modern neural net-
works. In International conference on machine learn-
ing, pages 1321–1330. PMLR.
Chirag Gupta, Aleksandr Podkopaev, and Aaditya Ram-
das. 2020. Distribution-free binary classification:
prediction sets, confidence intervals and calibration.
Advances in Neural Information Processing Systems ,
33:3711–3723.
Shizhu He, Kang Liu, Guoliang Ji, and Jun Zhao. 2015.
Learning to represent knowledge graphs with gaus-
sian embedding. In Proceedings of the 24th ACM in-
ternational on conference on information and knowl-
edge management , pages 623–632.
Kexin Huang, Ying Jin, Emmanuel Candes, and Jure
Leskovec. 2024. Uncertainty quantification over
graph with conformalized graph neural networks. Ad-
vances in Neural Information Processing Systems ,
36.
Joseph B Kruskal. 1964. Nonmetric multidimen-
sional scaling: a numerical method. Psychometrika ,
29(2):115–129.
Erich Leo Lehmann, Joseph P Romano, and George
Casella. 1986. Testing statistical hypotheses , vol-
ume 3. Springer.
Jing Lei, Max G’Sell, Alessandro Rinaldo, Ryan J Tib-
shirani, and Larry Wasserman. 2018. Distribution-
free predictive inference for regression. Journal of
the American Statistical Association , 113(523):1094–
1111.
Jing Lei, Alessandro Rinaldo, and Larry Wasserman.
2015. A conformal prediction approach to explore
functional data. Annals of Mathematics and Artificial
Intelligence , 74:29–43.
Lysimachos Maltoudoglou, Andreas Paisios, and Harris
Papadopoulos. 2020. Bert-based conformal predictor
for sentiment analysis. In Conformal and Proba-
bilistic Prediction and Applications , pages 269–284.
PMLR.
Maximilian Nickel, V olker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In ICML , pages
809–816. Omnipress.
OpenAI. 2024. Chatgpt(3.5)[large language model].
https://chat.openai.com .
John Platt et al. 1999. Probabilistic outputs for support
vector machines and comparisons to regularized like-
lihood methods. Advances in large margin classifiers ,
10(3):61–74.
H Ren, W Hu, and J Leskovec. 2020. Query2box: Rea-
soning over knowledge graphs in vector space using
box embeddings. In International Conference on
Learning Representations (ICLR) .
Daniel Ruffinelli, Samuel Broscheit, and Rainer
Gemulla. 2019. You can teach an old dog new tricks!
on training knowledge graph embeddings. In Inter-
national Conference on Learning Representations .
David E Rumelhart, Geoffrey E Hinton, and Ronald J
Williams. 1986. Learning representations by back-
propagating errors. nature , 323(6088):533–536.
Tara Safavi, Danai Koutra, and Edgar Meij. 2020. Evalu-
ating the calibration of knowledge graph embeddings
for trustworthy link prediction. In EMNLP (1) , pages
8308–8321. Association for Computational Linguis-
tics.
Glenn Shafer and Vladimir V ovk. 2008. A tutorial on
conformal prediction. Journal of Machine Learning
Research , 9(3).
Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian
Tang. 2019. Rotate: Knowledge graph embedding
by relational rotation in complex space. In ICLR
(Poster) . OpenReview.net.
Pedro Tabacof and Luca Costabello. 2020. Probability
calibration for knowledge graph embedding models.
InICLR . OpenReview.net.
Ryan J Tibshirani, Rina Foygel Barber, Emmanuel Can-
des, and Aaditya Ramdas. 2019. Conformal pre-
diction under covariate shift. Advances in neural
information processing systems , 32.
Kristina Toutanova and Danqi Chen. 2015. Observed
versus latent features for knowledge base and text
inference. In Proceedings of the 3rd workshop on
continuous vector space models and their composi-
tionality , pages 57–66.
Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric
Gaussier, and Guillaume Bouchard. 2016. Complex
embeddings for simple link prediction. In Interna-
tional conference on machine learning , pages 2071–
2080. PMLR.
Vladimir V ovk, Alexander Gammerman, and Glenn
Shafer. 2005. Algorithmic learning in a random
world , volume 29. Springer.Quan Wang, Zhendong Mao, Bin Wang, and Li Guo.
2017. Knowledge graph embedding: A survey of
approaches and applications. IEEE transactions on
knowledge and data engineering , 29(12):2724–2743.
Han Xiao, Minlie Huang, and Xiaoyan Zhu. 2016.
TransG : A generative model for knowledge graph
embedding. In Proceedings of the 54th Annual Meet-
ing of the Association for Computational Linguistics
(Volume 1: Long Papers) , pages 2316–2325, Berlin,
Germany. Association for Computational Linguistics.
Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao,
and Li Deng. 2015. Embedding entities and relations
for learning and inference in knowledge bases. In
ICLR (Poster) .
Soroush H Zargarbashi, Simone Antonelli, and Aleksan-
dar Bojchevski. 2023. Conformal prediction sets for
graph neural networks. In International Conference
on Machine Learning , pages 12292–12318. PMLR.
Soroush H Zargarbashi and Aleksandar Bojchevski.
2023. Conformal inductive graph neural networks.
InThe Twelfth International Conference on Learning
Representations .
A Baseline Predictors
A.1 Naive Predictor
We provide detailed pseudocode for naive predictor
in this section. See Algorithm 2 for details.
Algorithm 2 Pseudocode for naive predictor.
Require: A KGE model Mθtrained on T1:n, a
testing query qn+1and an error rate ϵ.
1:L←an empty set
2:for each entity einEdo
3: L←L∪ {(e, M θ(tr(qn+1, e)))}
4:end for
5:normalize the scores in Lwith softmax func-
tion.
6:L←sort elements in Lbased on normalized
scores (from largest to smallest).
7:p←0
8:ˆC(qn+1)←an empty set
9:for(e, s)inLdo
10: p←p+s
11: ifp <1−ϵthen
12: ˆC(qn+1)←ˆC(qn+1)∪ {e}
13: end if
14:end for
15:return ˆC(qn+1)
A.2 Platt Predictor
The Platt predictor enhances the naive predictor us-
ing a calibration technique. The only difference in
its procedure, as outlined in line 5 of Algorithm 2,
is the modification of softmax outputs through tem-
perature scaling(Guo et al., 2017) — a multiclass
extension of Platt scaling (Platt et al., 1999).
Temperature scaling employs a single scalar pa-
rameter T >0across all possible answer entities
for a given query. Let Mθ(tr(qn+1), ei)represent
the plausibility score of entity ei∈Efor query
qn+1. The calibrated score ˆsiis then calculated as
ˆsi=σ(Mθ(tr(qn+1), ei)/T), (14)
where σ(·)is the softmax function.
The parameter T, known as the temperature,
"softens" the softmax output by increasing its en-
tropy when T > 1. As T→ ∞ , the probability
ˆsiapproaches 1/|E|, indicating maximum uncer-
tainty. When T= 1, the original softmax output is
recovered. Conversely, as T→0, the probability
collapses to a point mass ( ˆsi= 1). The optimalWN18 FB15k
method coverage size method coverage size
top1 0.45 0.48 top1 0.12 0.17
top3 0.65 1.76 top3 0.24 0.71
top10 0.80 7.32 top10 0.46 3.91
top100 0.92 90.91 top100 0.79 71.46
topk 0.90 52.96 topk 0.90 395.11
Table 3: Comparison of the fixed-size set predictors
and the top-K predictor with Klearned based on the
validation set. The table reports the mean values of
coverage and the average size of filtered answer sets
over 15 trials. Results are based on the RESCAL model
applied to the WN18 and FB15k datasets.
value of Tis determined by minimizing the nega-
tive log-likelihood on the validation set.
NLL =−1
NNX
i=1log(ˆsiPN
j=1ˆsj), (15)
where Nis the size of calibration (validation) set.
A.3 Fixed-sized Predictor
The ranking-based metric Hits@Kevaluate how
often KGE models place the correct answers within
the top-K entities, implicitly suggesting that the top-
K entities should be chosen as answer sets. Based
onHits@K, we evaluate the quality of fixed-sized
set predictor, which produce top-K entities (with a
manually chosen K) as the answer set.
We select Kvalues commonly used in Hits@K
metrics (1, 3, 10, 100). The results in Table 3 and 4
demonstrate that coverage is highly sensitive to the
choice of K. Concretely, the fixed-sized set predic-
tor either fails to meet the coverage desideratum or
generate unnecessarily large answer sets.
Consequently, in the main body of the paper,
we adopt the topk predictor, where we use Kthat
cover the true answer in 1−ϵof queries in the
validation set. The topk predictor effectively bal-
ances the trade-off between coverage and average
size. However, unlike conformal predictors, the
topk predictor cannot adapt answer set sizes to the
difficulty of individual queries, as it uses the same
size for all queries.
B Detailed Experimental Setting
B.1 Information About KGE Models and
Benchmark Datasets
We provide the statistics of the benchmark datasets
in Table 5 and the scoring functions of KGE meth-
ods in Table 6.
WN18 FB15k
method coverage size method coverage size
top1 0.45 1.00 top1 0.12 1.00
top3 0.65 3.00 top3 0.24 3.00
top10 0.80 10.00 top10 0.46 10.00
top100 0.92 100.00 top100 0.79 100.00
topk 0.90 60.00 topk 0.90 465.00
Table 4: Comparison of the fixed-size set predictors
and the top-K predictor with Klearned based on the
validation set. The table reports the mean values of
coverage and the average size of answer sets over 15
trials. Results are based on the RESCAL model applied
to the WN18 and FB15k datasets.
#Entity #Relation #Training #Validation #Test
WN18 40,943 18 141,442 5,000 5,000
WN18RR 40,943 11 86,835 3,034 3,134
FB15k 14,951 1,345 483,142 50,000 59,071
FB15k-237 14,541 237 272,115 17,535 20,466
Table 5: Statistics of benchmark datasets for link pre-
diction task.
Scoring Function s(< h, r, t > )
TransE (Bordes et al., 2013) −||h+r−t||1/2
RotatE (Sun et al., 2019) −||h◦r−t||p
RESCAL (Nickel et al., 2011) hTMrt
DistMult (Yang et al., 2015) hTdiag(r)t
ComplEx (Trouillon et al., 2016) Re(hTdiag(r)t)
ConvE (Dettmers et al., 2018) f(vec(f([h;r]∗ω))W)t
Table 6: The scoring function s(<h, r, t >)of KGE
models used in this paper, where h, r, t denote the em-
beddings of h, r, t ,◦denotes Hadamard product. ·refers
to conjugate for complex vectors in ComplEx, and 2D
reshaping for real vectors in ConvE. ∗is operator for
2D convolution. ωis the filters and Wis the parameters
for 2D convolutional layer.
B.2 Personal Identification Issue in FB15k
and FB15k237
While FB15k and FB15k237 contain information
about individuals, it typically focuses on well-
known public figures such as celebrities, politicians,
and historical figures. Since this information is al-
ready widely available online and in various public
sources, its inclusion in Freebase doesn’t signifi-
cantly compromise individual privacy compared to
datasets containing sensitive personal information.
B.3 Details of Pre-training KGE Models
For training KGE models, we use the implementa-
tion of LibKGE (Broscheit et al., 2020) and basi-
cally follow the hyperparameter search strategy in
(Ruffinelli et al., 2019). All experiments were con-
ducted on a Linux machine with a 40GB NVIDIAA100 SXM4 GPU.
We first conduct quasi-random hyperparameter
search via a Sobol sequence, which aims to dis-
tribute hyperparameter settings evenly to avoid
"clumping" effects (Bergstra and Bengio, 2012).
More specifically, for each dataset and model, we
generated 30 different configurations per valid com-
bination of training type and loss function. we
added a short Bayesian optimization phase (best
configuration so far + 30 new trials) to tune the
hyperparameters further. All above steps are con-
ducted using Ax framework ( https://ax.dev/ )
We use a large hyperparameter space including
loss functions (pairwise margin ranking with hinge
loss, binary cross entropy, cross entropy), regular-
ization techniques (none/L1/L2/L3, dropout), opti-
mizers (Adam, Adagrad), and initialization meth-
ods used in the KGE community as hyperparam-
eters. We consider 128, 256, 512 as possible em-
bedding sizes. More details see in (Ruffinelli et al.,
2019, Table 5).
The hyperparameters of the baseline models are
located within the software folder we submitted.
Concretely, all configuration files (*.yaml) that we
use for training baseline models/competing mod-
els/models for aggregation can be found in folder
"configs".
C Calibrated Conformal Predictor
Conformal prediction is a theoretical framework
that quantifies predictive uncertainty by ensuring
answer sets meet probabilistic guarantees, followed
by identifying a nonconformity measure that mini-
mizes the size of these sets. Optimal answer sets
are achieved when nonconformity scores accurately
reflect the confidence of the predictions.
While calibrating plausibility scores from KGE
models should theoretically improve the naive pre-
dictor and the nonconformity measure for confor-
mal predictor, our results suggest otherwise. As
shown in Table 1, 8, 9 and 10, Platt predictors
yield excessively large answer sets. Further experi-
ments comparing softmax conformal prediction be-
fore and after temperature scaling (Table 7) reveal
that temperature scaling generally increases answer
set sizes. Although smaller sets are observed for
TransE, they are still not competitive with the best
predictors for TransE in Table 1. These observa-
tions contradict our expectations. We next explore
the reasons for these outcomes in KGE models.
First, as detailed in Appendix A.2, temperature
scaling adjusts plausibility scores by dividing by a
temperature parameter T, optimized by minimiz-
ing negative log-likelihood on validation set. This
calibration assumes two key points: (1) uniform
miscalibration , where plausibility scores are con-
sistently miscalibrated across the model (e.g., the
KGE model is uniformly overconfident or under-
confident for all queries); and (2) monotonic cali-
bration , where the relative ordering of plausibility
scores aligns with calibrated probabilities. These
assumptions are overly stringent for KGE mod-
els, which tend to be overconfident with queries
that have many correct answers and underconfident
with those having fewer correct answers. Addition-
ally, the relative ordering of plausibility scores is
highly sensitive to minor hyperparameter changes.
Moreover, applying temperature scaling or other
calibration techniques requires formulating link
prediction as a classification task. However, the
validation set exhibits a long-tail distribution in the
number of triples associated with certain entities,
i.e. many entities have few or even no associated
triples. It leads to insufficient data for effective cal-
ibration for entities associated with fewer triples.
WN18 FB15k
model method coverage size coverage size
TransESoftmax 0.90 112.8 0.90 414.9
Cali 0.90 63.4 0.90 129.0
RotatESoftmax 0.90 1.9 0.90 140.4
Cali 0.90 17.4 0.90 150.6
RESCALSoftmax 0.90 2.1 0.90 72.6
Cali 0.91 247.3 0.90 209.5
DistMultSoftmax 0.90 2.0 0.90 28.4
Cali 0.90 26.8 0.90 240.5
ComplExSoftmax 0.90 1.1 0.90 37.2
Cali 0.90 18.2 0.90 173.6
ConvESoftmax 0.90 1.6 0.90 44.4
Cali 0.90 61.2 0.90 177.7
Table 7: Comparison of the filtered answer sets between
the Softmax conformal predictor (Softmax) and the con-
formal predictor with temperature scaling applied to the
Softmax predictor (Cali). The best predictors, which
meet the coverage desideratum and minimize answer
set size, are highlighted in bold.D Further Results for Coverage & Set
Size Evaluation
D.1 Coverage and Set Size on WN18RR and
FB15k237
We repeated the experiment on WN18RR and
FB15k237, datasets known to be more challeng-
ing than WN18 and FB15k due to the removal
of inverse relations (Toutanova and Chen, 2015;
Dettmers et al., 2018).
The results for the filtered answer sets are pre-
sented in Table 8, while the unfiltered results are
available in Table 10 in Appendix D. The conclu-
sions from Experiment 1 remain consistent; how-
ever, we observe a significant increase in set sizes
for all set predictors, particularly for WN18RR.
This increase is desirable, as it aligns with the adap-
tiveness desideratum, where the set predictor is
expected to output smaller sets for simple queries
and larger sets for harder ones.
E Further Results for Adaptiveness
Evaluation
In Figure 3 - 14, we show the size of answer sets
stratified by the difficulty level of queries for differ-
ent conformal predictors across six representative
KGE models and four benchmark datasets.
F AI Assistants In Writing
We use ChatGPT (OpenAI, 2024) to enhance our
writing skills, abstaining from its use in research
and coding endeavors.
WN18RR FB15k237
model MR methods coverage size model MR methods coverage size
naive 0.92 (0.002) 12592.31 (39.396) naive 0.90 (0.006) 805.70 (38.319)
Platt 0.90 (0.002) 10921.01 (32.441) Platt 0.90 (0.006) 832.14 (36.711)
topk 0.90 (0.002) 3571.51 (144.178) topk 0.90 (0.001) 875.53 (7.835)
NegScore 0.90 (0.002) 9409.77 (252.614) NegScore 0.90 (0.001) 1367.25 (39.240)
Softmax 0.90 (0.001) 4864.10 (160.461) Softmax 0.90 (0.001) 340.67 (3.099)TransE 1849.47 (20.933)
Minmax 0.90 (0.001) 4371.36 (172.089)TransE 206.62 (2.105)
Minmax 0.90 (0.001) 482.96 (8.236)
naive 0.98 (0.003) 29054.22 (78.389) naive 0.99 (0.000) 4564.86 (16.479)
Platt 0.92 (0.003) 23041.24 (67.999) Platt 0.95 (0.001) 1851.22 (12.442)
topk 0.90 (0.003) 7780.12 (1372.505) topk 0.90 (0.001) 786.96 (9.659)
NegScore 0.90 (0.004) 10135.01 (887.572) NegScore 0.90 (0.001) 396.30 (6.841)
Softmax 0.90 (0.003) 8469.82 (1332.540) Softmax 0.90 (0.001) 309.38 (4.527)RotatE 2402.47 (226.057)
Minmax 0.90 (0.003) 8026.50 (691.561)RotatE 167.92 (3.340)
Minmax 0.90 (0.001) 310.32 (5.611)
naive 0.82 (0.004) 19604.12 (54.324) naive 0.75 (0.026) 311.80 (59.631)
Platt 0.91 (0.006) 25156.82 (67.922) Platt 0.85 (0.017) 492.83 (68.264)
topk 0.90 (0.006) 20571.25 (619.329) topk 0.90 (0.001) 810.16 (8.750)
NegScore 0.90 (0.006) 19813.44 (476.890) NegScore 0.90 (0.001) 581.74 (16.583)
Softmax 0.90 (0.006) 25146.85 (397.278) Softmax 0.90 (0.001) 261.58 (5.352)RESCAL 5080.82 (157.027)
Minmax 0.90 (0.005) 18262.03 (484.686)RESCAL 197.71 (7.228)
Minmax 0.90 (0.001) 356.23 (20.744)
naive 0.87 (0.014) 22687.34 (1040.595) naive 0.82 (0.008) 852.93 (110.675)
Platt 0.90 (0.005) 26100.71 (766.341) Platt 0.88 (0.007) 1236.71 (122.667)
topk 0.90 (0.005) 18220.44 (660.313) topk 0.90 (0.001) 785.39 (7.479)
NegScore 0.90 (0.005) 22735.97 (843.241) NegScore 0.90 (0.001) 340.43 (8.278)
Softmax 0.90 (0.004) 24347.85 (1756.093) Softmax 0.90 (0.001) 276.85 (4.932)DistMult 4325.85 (153.189)
Minmax 0.90 (0.005) 17555.05 (822.261)DistMult 194.19 (4.581)
Minmax 0.90 (0.001) 352.42 (31.161)
naive 0.45 (0.008) 5939.57 (192.280) naive 0.85 (0.010) 1027.42 (134.273)
Platt 0.83 (0.008) 15307.46 (374.11) Platt 0.92 (0.010) 1701.31 (145.989)
topk 0.90 (0.006) 19785.19 (410.275) topk 0.90 (0.001) 757.90 (5.512)
NegScore 0.90 (0.007) 19858.11 (221.472) NegScore 0.90 (0.001) 319.42 (6.025)
Softmax 0.90 (0.004) 18194.32 (595.990) Softmax 0.90 (0.001) 271.05 (2.988)ComplEx 4117.56 (127.304)
Minmax 0.90 (0.003) 14101.85 (447.917)ComplEx 183.58 (3.182)
Minmax 0.90 (0.001) 365.28 (72.147)
naive 0.25 (0.006) 1131.72 (88.750) naive 0.95 (0.006) 1072.99 (100.842)
Platt 0.82 (0.006) 10955.50 (800.116) Platt 0.94 (0.005) 814.70 (75.111)
topk 0.90 (0.005) 18270.13 (1047.722) topk 0.90 (0.001) 752.37 (5.652)
NegScore 0.90 (0.004) 21094.54 (687.705) NegScore 0.90 (0.001) 718.24 (44.095)
Softmax 0.93 (0.006) 19851.28 (756.774) Softmax 0.90 (0.001) 270.40 (3.336)ConvE 4635.63 (151.271)
Minmax 0.90 (0.003) 17400.91 (644.163)ConvE 185.19 (1.636)
Minmax 0.90 (0.001) 242.64 (1.843)
Table 8: Quality of the filtered answer sets on WN18RR and FB15k237 datasets. This table presents the mean
rank (MR) of KGE models, along with the coverage and size of answer sets generated using various set predictors.
Conformal predictors are underlined. Means and standard deviations over 15 trials are reported at the 10% level
(ϵ= 0.1). Predictors that fail to meet the coverage threshold of 1−ϵ(0.9) are highlighted in red. The best predictors,
which meet the coverage desideratum and minimize answer set size, are highlighted in bold.
WN18 FB15k
model MR methods coverage size model MR methods coverage size
naive 0.44 (0.004) 26.39 (1.278) naive 0.73 (0.001) 406.43 (0.827)
Platt 0.85(0.002) 4060.21 (89.563) Platt 0.84 (0.002) 1337.54 (44.123)
topk 0.90 (0.000) 54.67 (0.789) topk 0.90 (0.000) 401.00 (1.461)
NegScore 0.90 (0.001) 37.29 (0.721) NegScore 0.90 (0.001) 155.40 (0.623)
Softmax 0.90 (0.001) 129.67 (4.650) Softmax 0.90 (0.000) 569.80 (2.423)TransE 261.27 (6.365)
Minmax 0.90 (0.001) 130.45 (5.100)TransE 188.23 (0.187)
Minmax 0.90 (0.000) 433.99 (3.242)
naive 0.91 (0.003) 17704.98 (117.899) naive 0.71 (0.003) 889.73 (5.109)
Platt 0.90 (0.002) 16966.23 (116.434) Platt 0.88 (0.002) 1292.32 (7.532)
topk 0.90 (0.001) 57.73 (2.594) topk 0.90 (0.000) 479.50 (4.066)
NegScore 0.90 (0.002) 17.87 (0.022) NegScore 0.90 (0.001) 209.36 (0.665)
Softmax 0.90 (0.001) 13.61 (0.401) Softmax 0.90 (0.000) 277.84 (5.434)RotatE 493.17 (44.041)
Minmax 0.90 (0.003) 20.53 (0.693)RotatE 212.70 (1.003)
Minmax 0.90 (0.001) 198.67 (1.117)
naive 0.58 (0.011) 316.68 (24.776) naive 0.58 (0.016) 274.69 (13.802)
Platt 0.80 (0.005) 2035.13 (222.193) Platt 0.87 (0.003) 755.23 (22.263)
topk 0.90 (0.001) 61.60 (1.744) topk 0.90 (0.000) 464.00 (2.556)
NegScore 0.91 (0.001) 55.36 (3.529) NegScore 0.90 (0.001) 327.14 (4.569)
Softmax 0.90 (0.001) 15.16 (0.358) Softmax 0.90 (0.000) 183.69 (3.650)RESCAL 338.24 (21.476)
Minmax 0.90 (0.002) 18.81 (0.080)RESCAL 215.57 (1.548)
Minmax 0.90 (0.001) 237.00 (5.822)
naive 0.47 (0.002) 51.35 (7.023) naive 0.35 (0.013) 162.65 (1.103)
Platt 0.84 (0.001) 1282.45 (204.44) Platt 0.90 (0.001) 625.33 (2.300)
topk 0.90 (0.001) 64.80 (2.587) topk 0.90 (0.000) 430.00 (1.549)
NegScore 0.90 (0.001) 2261.78 (405.035) NegScore 0.90 (0.000) 210.35 (2.876)
Softmax 0.90 (0.001) 9.16 (0.337) Softmax 0.90 (0.000) 143.23 (4.601)DistMult 386.83 (20.312)
Minmax 0.90 (0.002) 18.04 (0.525)DistMult 196.36 (0.746)
Minmax 0.90 (0.000) 197.79 (0.892)
naive 0.94 (0.007) 19984.22 (142.118) naive 0.28 (0.011) 189.44 (1.424)
Platt 0.86 (0.002) 16802.14 (125.322) Platt 0.90 (0.001) 1082.11 (9.211)
topk 0.91 (0.002) 46.73 (1.948) topk 0.90 (0.000) 485.60 (4.800)
NegScore 0.90 (0.003) 18.36 (0.008) NegScore 0.90 (0.001) 257.63 (9.161)
Softmax 0.90 (0.001) 7.63 (0.133) Softmax 0.90 (0.001) 178.62 (3.561)ComplEx 467.12 (27.864)
Minmax 0.90 (0.002) 19.72 (0.172)ComplEx 216.65 (1.698)
Minmax 0.90 (0.001) 278.10 (20.531)
naive 0.50 (0.015) 18.32 (1.536) naive 0.45 (0.026) 932.71 (112.137)
Platt 0.84 (0.007) 95.01 (1.772) Platt 0.88 (0.014) 4984.11 (699.111)
topk 0.90 (0.001) 60.27 (1.569) topk 0.90 (0.000) 455.13 (3.384)
NegScore 0.90 (0.002) 17.47 (0.617) NegScore 0.90 (0.000) 203.47 (2.291)
Softmax 0.90 (0.001) 8.45 (0.666) Softmax 0.90 (0.000) 217.82 (6.516)ConvE 327.52 (12.602)
Minmax 0.90 (0.001) 17.80 (0.161)ConvE 216.37 (1.848)
Minmax 0.90 (0.000) 206.62 (8.665)
Table 9: Quality of the answer sets on WN18 and FB15k datasets. This table presents the mean rank (MR) of
KGE models, along with the coverage and size of answer sets generated using various set predictors. Conformal
predictors are underlined. Means and standard deviations over 15 trials are reported at the 10% level ( ϵ= 0.1).
Predictors that fail to meet the coverage threshold of 1−ϵ(0.9) are highlighted in red. The best predictors, which
meet the coverage desideratum and minimize answer set size, are highlighted in bold.
WN18RR FB15k237
model MR methods coverage size model MR methods coverage size
naive 0.92 (0.002) 12606.42 (39.399) naive 0.90 (0.006) 997.60 (40.772)
Platt 0.90 (0.002) 10935.81 (31.241) Platt 0.90 (0.006) 1022.32 (35.123)
topk 0.90 (0.002) 3585.87 (144.179) topk 0.90 (0.001) 993.33 (8.252)
NegScore 0.90 (0.002) 9424.01 (252.614) NegScore 0.90 (0.001) 1529.21 (38.853)
Softmax 0.90 (0.001) 4878.40 (160.461) Softmax 0.90 (0.001) 480.91 (4.252)TransE 1863.55 (20.933)
Minmax 0.90 (0.001) 4385.71 (172.090)TransE 378.52 (1.570)
Minmax 0.90 (0.001) 608.92 (8.100)
naive 0.98 (0.003) 29068.66 (78.388) naive 0.99 (0.000) 4776.32 (16.527)
Platt 0.92 (0.003) 23065.33 (65.139) Platt 0.95 (0.001) 1992.54 (12.111)
topk 0.90 (0.003) 7794.53 (1372.506) topk 0.90 (0.001) 899.20 (10.186)
NegScore 0.90 (0.004) 10149.42 (887.574) NegScore 0.90 (0.001) 601.35 (6.779)
Softmax 0.90 (0.003) 8484.13 (1332.541) Softmax 0.90 (0.001) 420.48 (5.493)RotatE 2416.60 (226.054)
Minmax 0.90 (0.003) 8040.94 (691.558)RotatE 334.72 (2.449)
Minmax 0.90 (0.001) 494.12 (7.390)
naive 0.82 (0.004) 19617.55 (54.247) naive 0.75 (0.026) 518.49 (60.728)
Platt 0.91 (0.006) 25178.84 (67.922) Platt 0.85 (0.017) 634.23 (67.233)
topk 0.90 (0.006) 20585.67 (619.329) topk 0.90 (0.001) 923.93 (9.205)
NegScore 0.90 (0.006) 19827.86 (476.890) NegScore 0.90 (0.001) 794.21 (16.356)
Softmax 0.90 (0.006) 25161.15 (397.282) Softmax 0.90 (0.001) 441.73 (2.242)RESCAL 5095.01 (157.027)
Minmax 0.90 (0.005) 18276.47 (484.688)RESCAL 361.48 (5.994)
Minmax 0.90 (0.001) 550.94 (20.262)
naive 0.87 (0.014) 22700.68 (1040.718) naive 0.82 (0.008) 1064.07 (111.022)
Platt 0.90 (0.005) 26117.52 (764.112) Platt 0.88 (0.007) 1385.57 (122.190)
topk 0.90 (0.005) 18234.80 (660.315) topk 0.90 (0.001) 895.13 (7.847)
NegScore 0.90 (0.005) 22750.38 (843.239) NegScore 0.90 (0.001) 446.12 (7.461)
Softmax 0.90 (0.004) 24362.11 (1756.095) Softmax 0.90 (0.001) 429.23 (4.660)DistMult 4340.04 (153.190)
Minmax 0.90 (0.005) 17569.49 (822.261)DistMult 343.41 (4.267)
Minmax 0.90 (0.001) 553.92 (30.822)
naive 0.45 (0.008) 5950.18 (192.118) naive 0.85 (0.010) 1239.13 (134.671)
Platt 0.83 (0.008) 15325.22 (372.89) Platt 0.92 (0.010) 1852.47 (142.284)
topk 0.90 (0.006) 19799.60 (410.282) topk 0.90 (0.001) 865.33 (5.839)
NegScore 0.90 (0.007) 19872.52 (221.472) NegScore 0.90 (0.001) 427.18 (5.201)
Softmax 0.90 (0.004) 18208.61 (595.990) Softmax 0.90 (0.001) 404.95 (1.924)ComplEx 4131.71 (127.296)
Minmax 0.90 (0.003) 14116.23 (447.920)ComplEx 329.62 (2.596)
Minmax 0.90 (0.001) 564.83 (71.526)
naive 0.25 (0.006) 1144.71 (88.743) naive 0.95 (0.006) 1286.00 (100.851)
Platt 0.82 (0.006) 10973.44 (801.106) Platt 0.94 (0.005) 964.33 (73.154)
topk 0.90 (0.005) 18284.53 (1047.723) topk 0.90 (0.001) 860.40 (6.141)
NegScore 0.90 (0.004) 21108.92 (687.713) NegScore 0.90 (0.001) 931.44 (44.128)
Softmax 0.93 (0.006) 19865.73 (756.774) Softmax 0.90 (0.001) 369.22 (2.583)ConvE 4649.83 (151.263)
Minmax 0.90 (0.003) 17415.35 (644.162)ConvE 339.42 (2.611)
Minmax 0.90 (0.001) 441.82 (2.828)
Table 10: Quality of the answer sets on WN18RR and FB15k237 datasets. This table presents the mean rank (MR)
of KGE models, along with the coverage and size of answer sets generated using various set predictors. Conformal
predictors are underlined. Means and standard deviations over 15 trials are reported at the 10% level ( ϵ= 0.1).
Predictors that fail to meet the coverage threshold of 1−ϵ(0.9) are highlighted in red. The best predictors, which
meet the coverage desideratum and minimize answer set size, are highlighted in bold.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer01000200030004000Size of Prediction SetsTransE+NegScore on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerTransE+Softmax on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerTransE+Minmax on FB15kFigure 3: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on TransE models) on the FB15k dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer010002000300040005000Size of Prediction SetsTransE+NegScore on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerTransE+Softmax on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerTransE+Minmax on FB15k237
Figure 4: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on TransE models) on the FB15k237 dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer05001000150020002500Size of Prediction SetsRotatE+NegScore on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRotatE+Softmax on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRotatE+Minmax on FB15k
Figure 5: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on RotatE models) on the FB15k dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer0500100015002000250030003500Size of Prediction SetsRotatE+NegScore on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRotatE+Softmax on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRotatE+Minmax on FB15k237
Figure 6: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on RotatE models) on the FB15k237 dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer0500100015002000250030003500Size of Prediction SetsRESCAL+NegScore on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRESCAL+Softmax on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRESCAL+Minmax on FB15kFigure 7: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on RESCAL models) on the FB15k dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer010002000300040005000Size of Prediction SetsRESCAL+NegScore on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRESCAL+Softmax on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerRESCAL+Minmax on FB15k237
Figure 8: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on RESCAL models) on the FB15k237 dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer050010001500200025003000Size of Prediction SetsDistMult+NegScore on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerDistMult+Softmax on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerDistMult+Minmax on FB15k
Figure 9: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on DistMult models) on the FB15k dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer050010001500200025003000Size of Prediction SetsDistMult+NegScore on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerDistMult+Softmax on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerDistMult+Minmax on FB15k237
Figure 10: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on DistMult models) on the FB15k237 dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer01000200030004000Size of Prediction SetsComplEx+NegScore on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerComplEx+Softmax on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerComplEx+Minmax on FB15kFigure 11: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on ComplEx models) on the FB15k dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer05001000150020002500Size of Prediction SetsComplEx+NegScore on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerComplEx+Softmax on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerComplEx+Minmax on FB15k237
Figure 12: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on ComplEx models) on the FB15k237 dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer0500100015002000250030003500Size of Prediction SetsConvE+NegScore on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerConvE+Softmax on FB15k
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerConvE+Minmax on FB15k
Figure 13: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on ConvE models) on the FB15k dataset.
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True Answer01000200030004000500060007000Size of Prediction SetsConvE+NegScore on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerConvE+Softmax on FB15k237
[1, 101)
[101, 201)
[201, 301)
[301, 401)
[401, 501)
[501, 601)
[601, 701)
[701, 801)
[801, 901)
[901, 1001)
[1001, 1101)
[1101, 1201)
[1201, 1301)
[1301, 1401)
[1401, 1501)
[1501, 1601)
[1601, 1701)
[1701, 1801)
[1801, 1901)
[1901, 2001)
[2001, 2101)
[2101, 2201)
[2201, 2301)
[2301, 2401)
[2401, 2501)
[2501, 2601)
[2601, 2701)
[2701, 2801)
[2801, 2901)
[2901, 3001)
Rank of the True AnswerConvE+Minmax on FB15k237
Figure 14: This figure shows the size of answer sets stratified by the difficulty level of queries. It shows the
adaptiveness of different conformal predictors (built on ConvE models) on the FB15k237 dataset.
