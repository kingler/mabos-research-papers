Representing and resolving ambiguities
in ontology-based question answering
Christina Unger
Cognitive Interaction Technology – Center of Excellence (CITEC),
Universität Bielefeld, Germany
{cunger|cimiano}@cit-ec.uni-bielefeld.dePhilipp Cimiano
Abstract
Ambiguities are ubiquitous in natural lan-
guage and pose a major challenge for the au-
tomatic interpretation of natural language ex-
pressions. In this paper we focus on differ-
ent types of lexical ambiguities that play a role
in the context of ontology-based question an-
swering, and explore strategies for capturing
and resolving them. We show that by employ-
ing underspeciﬁcation techniques and by us-
ing ontological reasoning in order to ﬁlter out
inconsistent interpretations as early as possi-
ble, the overall number of interpretations can
be effectively reduced by 44 %.
1 Introduction
Ambiguities are ubiquitous in natural language.
They pose a key challenge for the automatic inter-
pretation of natural language expressions and have
been recognized as a central issue in question an-
swering (e.g. in (Burger et al., 2001)). In gen-
eral, ambiguities comprise all cases in which nat-
ural language expressions (simple or complex) can
have more than one meaning. These cases roughly
fall into two classes: They either concern structural
properties of an expression, e.g. different parses due
to alternative preposition or modiﬁer attachments
and different quantiﬁer scopings, or they concern al-
ternative meanings of lexical items. It is these lat-
ter ambiguities, ambiguities with respect to lexical
meaning, that we are interested in. More speciﬁ-
cally, we will look at ambiguities in the context of
ontology-based interpretation of natural language.The meaning of a natural language expression in
the context of ontology-based interpretation is the
ontology concept that this expression verbalizes. For
example, the expression city can refer to a class
geo:city (where geois the namespace of the corre-
sponding ontology), and the expression inhabitants
can refer to a property geo:population . The cor-
respondence between natural language expressions
and ontology concepts need not be one-to-one. On
the one hand side, different natural language expres-
sions can refer to a single ontology concept, e.g.
ﬂows through ,crosses through andtraverses could
be three ways of expressing an ontological property
geo:flowsThrough . On the other hand, one natu-
ral language expression can refer to different ontol-
ogy concepts. For example, the verb hasis vague
with respect to the relation it expresses – it could
map to geo:flowsThrough (in the case of rivers)
as well as geo:inState (in the case of cities). Such
mismatches between the linguistic meaning of an
expression, i.e. the user’s conceptual model, and the
conceptual model in the ontology give rise to a num-
ber of ambiguities. We will give a detailed overview
of those ambiguities in Section 3, after introducing
preliminaries in Section 2.
For a question answering system, there are mainly
two ways to resolve ambiguities: by interactive clar-
iﬁcation and by means of background knowledge
and the context with respect to which a question is
asked and answered. The former is, for example,
pursued by the question answering system FREyA
(Damljanovic et al., 2010). The latter is incorporated
in some recent work in machine learning. For exam-
ple, (Kate & Mooney, 2007) investigate the task of
learning a semantic parser from a corpus whith sen-
tences annotated with multiple, alternative interpre-
tations, and (Zettlemoyer & Collins, 2009) explore
an unsupervised algorithm for learning mappings
from natural language sentences to logical forms,
with context accounted for by hidden variables in a
perceptron.
In ontology-based question answering, context as
well as domain knowledge is provided by the ontol-
ogy. In this paper we explore how a given ontology
can be exploited for ambiguity resolution. We will
consider two strategies in Section 4. The ﬁrst one
consists in simply enumerating all possible interpre-
tations. Since this is not efﬁcient (and maybe not
even feasible), we will use underspeciﬁcation tech-
niques for representing ambiguities in a much more
compact way and then present a strategy for resolv-
ing ambiguities by means of ontological reasoning,
so that the number of interpretations that have to be
considered in the end is relatively small and does not
comprise inconsistent and therefore undesired inter-
pretations. We will summarize with quantitative re-
sults in Section 5.
2 Preliminaries
All examples throughout the paper will be based on
Raymond Mooney’s GeoBase1dataset and the DB-
pedia question set published in the context of the
1st Workshop on Question Answering Over Linked
Data (QALD-1)2. The former is a relatively small
and well-organized domain, while the latter is con-
siderably larger and much more heterogenous. It is
interesting to note that ontological ambiguituies turn
out to be very wide-spread even in a small and ho-
mogenuous domain like GeoBase (see Section 3 for
speciﬁc results).
For specifying entries of a grammar that a ques-
tion answering system might work with, we will use
the general and principled linguistic representations
that our question answering system Pythia3(Unger
et al., 2010) relies on, as they are suitable for dealing
with a wide range of natural language phenomena.
Syntactic representations will be trees from Lexi-
calized Tree Adjoining Grammar (LTAG (Schabes,
1cs.utexas.edu/users/ml/nldata/geoquery.html
2http://www.sc.cit-ec.uni-bielefeld.de/qald-1
3http://www.sc.cit-ec.uni-bielefeld.de/pythia1990)). The syntactic representation of a lexical
item is a tree constituting an extended projection of
that item, spanning all of its syntactic and semantic
arguments. Argument slots are nodes marked with a
down arrow ( #), for which trees with the same root
category can be substituted. For example, the tree
for a transitive verb like borders looks as follows:
1. S
DP1# VP
V
bordersDP2#
The domain of the verb thus spans a whole sentence,
containing its two nominal arguments – one in sub-
ject position and one in object position. The corre-
sponding nodes, DP 1and DP 2, are slots for which
any DP-tree can be substituted. For example, substi-
tuting the two trees in 2 for subject and object DP,
respectively, yields the tree in 3.
2. (a) DP
DET
noNP
state(b) DP
Hawaii
3. S
DP
DET
noNP
stateVP
V
bordersDP
Hawaii
As semantic representations we take DUDEs
(Cimiano, 2009), representations similar to struc-
tures from Underspeciﬁed Discourse Representation
Theory (UDRT (Reyle, 1993)), extended with some
additional information that allows for ﬂexible mean-
ing composition in parallel to the construction of
LTAG trees. The DUDE for the verb to border , for
example, would be the following (in a slightly sim-
pliﬁed version):
geo:borders (x; y)
(DP1; x);(DP2; y)
It provides the predicate geo:borders correspond-
ing to the intended concept in the ontology. This
correspondence is ensured by using the vocabulary
of the ontology, i.e. by using the URI4of the con-
cept instead of a more generic predicate. The pre-
ﬁxgeospeciﬁes the namespace, in this case the one
of the GeoBase ontology. Furthermore, the seman-
tic representation contains information about which
substitution nodes in the syntactic structure provide
the semantic arguments xandy. That is, the seman-
tic referent provided by the meaning of the tree sub-
stituted for DP 1corresponds to the ﬁrst argument x
of the semantic predicate, while the semantic refer-
ent provided by the meaning of the tree substituted
for DP 2corresponds to the second argument y. The
uppermost row of the box contains the referent that
is introduced by the expression. For example, the
DUDE for Hawaii (paired with the tree in 2b) would
be the following:
h
geo:name (h;`hawaii' )
It introduces a referent hwhich is related to the lit-
eral`hawaii' by means of the relation geo:name .
As it does not have any arguments, the third row
is empty. The bottom-most row, empty in both
DUDEs, is for selectional restrictions of predicates;
we will see those in Section 4.
Parallel to substituting the DP-tree in 2b for the
DP1-slot in 1, the DUDE for Hawaii is combined
with the DUDE for borders , amounting to the satu-
ration of the argument (DP2; y)by unifying the vari-
ables handy, yielding the following DUDE:
h
geo:borders (x; h)
geo:name (h;`hawaii' )
(DP1; x)
Substituting the subject argument no state involves
quantiﬁer representations which we will gloss over
as they do not play a role in this paper. At this point
4URI stands for Uniform Resource Identiﬁer . URIs uniquely
identify resources on the Web. For an overview, see, e.g.,
http://www.w3.org/Addressing/ .it sufﬁces to say that we implement the treatment of
quantiﬁer scope in UDRT without modiﬁcations.
Once a meaning representation for a question is
built, it is translated into a SPARQL query, which
can then be evaluated with respect to a given dataset.
Not a lot hinges on the exact choice of the for-
malisms; we could as well have chosen any other
syntactic and semantic formalism that allows the in-
corporation of underspeciﬁcation mechanisms. The
same holds for the use of SPARQL as formal query
language. The reason for choosing SPARQL is that
it is the standard query language for the Seman-
tic Web5; we therefore feel safe in relying on the
reader’s familiarity with SPARQL and use SPARQL
queries without further explanation.
3 Types of ambiguities
As described in the introduction above, a central task
in ontology-based interpretation is the mapping of
a natural language expression to an ontology con-
cept. And this mapping gives rise to several different
cases of ambiguities.
First, ambiguities can arise due to homonymy of a
natural language expression, i.e. an expression that
has several lexical meanings, where each of these
meanings can be mapped to one ontology concept
unambiguously. The ambiguity is inherent to the ex-
pression and is independent of any domain or ontol-
ogy. This is what in linguistic contexts is called a
lexical ambiguity. A classical example is the noun
bank , which can mean a ﬁnancial institution, a kind
of seating, the edge of a river, and a range of other
disjoint, non-overlapping alternatives. An example
in the geographical domain is New York . It can mean
either New York city, in this case it would be mapped
to the ontological entity geo:new york city , or
New York state, in this case it would be mapped to
the entity geo:new york . Ambiguous names are ac-
tually the only case of such ambiguities that occur in
the GeoBase dataset.
Another kind of ambiguities is due to mismatches
between a user’s concept of the meaning of an
expression and the modelling of this meaning
in the ontology. For example, if the ontology
modelling is more ﬁne-grained than the meaning
5For the W3C reference, see
http://www.w3.org/TR/rdf-sparql-query/ .
of a natural language expression, then an expres-
sion with one meaning can be mapped to several
ontology concepts. These concepts could differ
extensionally as well as intensionally. An example
is the above mentioned expression starring , that
an ontology engineer could want to comprise only
leading roles or also include supporting roles. If
he decides to model this distinction and introduces
two properties, then the ontological model is
more ﬁne-grained than the meaning of the natural
language expression, which could be seen as corre-
sponding to the union of both ontology properties.
Another example is the expression inhabitants
in question 4, which can be mapped either to
<http://dbpedia.org/property/population>
or to <http://dbpedia.org/ontology/popula-
tionUrban> . For most cities, both alternatives give
a result, but they differ slightly, as one captures only
the core urban area while the other also includes
the outskirts. For some city, even only one of them
might be speciﬁed in the dataset.
4.Which cities have more than two million inhab-
itants?
Such ambiguities occur in larger datasets like DB-
pedia with a wide range of common nouns and tran-
sitive verbs. In the QALD-1 training questions for
DBpedia, for example, at least 16 % of the questions
contain expressions that do not have a unique onto-
logical correspondent.
Another source for ambiguities is the large num-
ber of vague and context-dependent expressions in
natural language. While it is not possible to pin-
point such expressions to a fully speciﬁed lexical
meaning, a question answering system needs to map
them to one (or more) speciﬁc concept(s) in the on-
tology. Often there are several mapping possibili-
ties, sometimes depending on the linguistic context
of the expression.
An example for context-dependent expressions
in the geographical domain is the adjective big: it
refers to size (of a city or a state) either with respect
to population or with respect to area. For the ques-
tion 5a, for example, two queries could be intended
– one refering to population and one refering to area.
They are given in 5b and 5c.
5. (a) What is the biggest city?(b)SELECT ?s WHERE {
?s a geo:city .
?s geo:population ?p . }
ORDER BY DESC ?p LIMIT 1
(c)SELECT ?s WHERE {
?s a geo:city .
?s geo:area ?a . }
ORDER BY DESC ?a LIMIT 1
Without further clariﬁcation – either by means of
a clariﬁcation dialog with the user (e.g. employed
by FREyA (Damljanovic et al., 2010)) or an ex-
plicit disambiguation as in What is the biggest city
by area? – both interpretations are possible and ade-
quate. That is, the adjective bigintroduces two map-
ping alternatives that both lead to a consistent inter-
pretation.
A slightly different example are vague expres-
sions. Consider the questions 6a and 7a. The
verb has refers either to the object property
flowsThrough , when relating states and rivers, or
to the object property inState , when relating states
and cities. The corresponding queries are given in
6b and 7b.
6. (a) Which state has the most rivers?
(b)SELECT COUNT(?s) AS ?n WHERE {
?s a geo:state .
?r a geo:river .
?r geo:flowsThrough ?s. }
ORDER BY DESC ?n LIMIT 1
7. (a) Which state has the most cities?
(b)SELECT COUNT(?s) AS ?n WHERE {
?s a geo:state .
?c a geo:city .
?c geo:inState ?s. }
ORDER BY DESC ?n LIMIT 1
In contrast to the example of bigabove, these two
interpretations, flowsThrough andinState , are
exclusive alternatives: only one of them is admis-
sible, depending on the linguistic context. This
is due to the sortal restrictions of those proper-
ties: flowsThrough only allows rivers as domain,
whereas inState only allows cities as domain.
This kind of ambiguities are very frequent, as a
lot of user questions contain semantically light ex-
pressions, e.g. the copula verb be, the verb have ,
and prepositions like of,inandwith (cf. (Cimiano
& Minock, 2009)) – expressions which are vague
and do not specify the exact relation they are de-
noting. In the 880 user questions that Mooney pro-
vides, there are 1278 occurences of the light expres-
sions is/are ,has/have ,with,in, and of, in addition
to 151 ocurrences of the context-dependent expres-
sions big,small , and major .
4 Capturing and resolving ambiguities
When constructing a semantic representation and
a formal query, all possible alternative meanings
have to be considered. We will look at two strate-
gies to do so: simply enumerating all interpretations
(constructing a different semantic representation and
query for every possible interpretation), and under-
speciﬁcation (constructing only one underspeciﬁed
representation that subsumes all different interpreta-
tions).
4.1 Enumeration
Consider the example of a lexically ambiguous
question in 8a. It contains two ambiguous expres-
sions: New York can refer either to the city or the
state, and bigcan refer to size either with respect
to area or with respect to population. This leads to
four possible interpretations of the questions, given
in 8b–8e.
8. (a) How big is New York?
(b)SELECT ?a WHERE {
geo:new york city geo:area ?a . }
(c)SELECT ?p WHERE {
geo:new york city geo:population ?p.}
(d)SELECT ?a WHERE {
geo:new york geo:area ?a . }
(e)SELECT ?p WHERE {
geo:new york geo:population ?p . }
Since the question in 8a can indeed have all four in-
terpretations, all of them should be captured. The
enumeration strategy amounts to constructing all
four queries. In order to do so, we specify two
lexical entries for New York and two lexical en-
tries for the adjective big– one for each reading.
Forbig, these two entries are given in 9 and 10.
The syntactic tree is the same for both, while the
semantic representations differ: one refers to theproperty geo:area and one refers to the property
geo:population .
9. N
ADJ
bigN#a
geo:area (x; a)
(N; x)
10. N
ADJ
bigN#p
geo:population (x; p)
(N; x)
When parsing the question How big is New York ,
both entries for bigare found during lexical lookup,
and analogously two entries for New York are found.
The interpretation process will use all of them and
therefore construct four queries, 8b–8e.
Vague and context-dependent expressions can be
treated similarly. The verb to have , for example,
can map either to the property flowsThrough , in
the case of rivers, or to the property inState , in
the case of cities. Now we could simply spec-
ify two lexical entries to have – one using the
meaning flowsThrough and one using the mean-
inginState . However, contrary to lexical ambigu-
ities, these are not real alternatives in the sense that
both lead to consistent readings. The former is only
possible if the relevant argument is a river, the lat-
ter is only relevant if the relevant argument is a city.
So in order not to derive inconsistent interpretations,
we need to capture the sortal restrictions attached to
such exclusive alternatives. This will be discussed
in the next section.
4.2 Adding sortal restrictions
A straightforward way to capture ambiguities con-
sists in enumerating all possible interpretations
and thus in constructing all corresponding formal
queries. We did this by specifying a separate lex-
ical entry for every interpretation. The only difﬁ-
culty that arises is that we have to capture the sor-
tal restrictions that come with some natural language
expressions. In order to do so, we add sortal restric-
tions to our semantic representation format.
Sortal restrictions will be of the general form
variable ˆclass . For example, the sortal restriction
that instances of the variable xmust belong to the
class river in our domain would be represented as
xˆgeo:river . Such sortal restrictions are added as
a list to our DUDEs. For example, for the verb has
we specify two lexical entries. One maps hasto
the property flowThrough , specifying the sortal re-
striction that the ﬁrst argument of this property must
belong to the class river . This entry looks as fol-
lows:
S
DP1# VP
V
hasDP2#geo:flowsThrough (y; x)
(DP1; x);(DP2; y)
xˆgeo:river
The other lexical entry for hasconsists of the
same syntactic tree and a semantic representation
that maps hasto the property inState and contains
the restriction that the ﬁrst argument of this property
must belong to the class city . It looks as follows:
S
DP1# VP
V
hasDP2#geo:inState (y; x)
(DP1; x);(DP2; y)
xˆgeo:city
When a question containg the verb has, like 11a,
is parsed, both interpretations for hasare found dur-
ing lexical lookup and two semantic representations
are constructed, both containing a sortal restriction.
When translating the semantic representations into a
formal query, the sortal restriction is simply added as
a condition. For 11a, the two corresponding queries
are given in 11b (mapping hastoflowsThrough )
and 11c (mapping hasinState ). The contribution
of the sortal restriction is boxed.
11. (a) Which state has the most rivers?
(b)SELECT COUNT(?r) as ?c WHERE {
?s a geo:state .
?r a geo:river .
?r geo:flowsThrough ?s .
?r a geo:river . }
ORDER BY ?c DESC LIMIT 1
(c)SELECT COUNT(?r) as ?c WHERE {
?s a geo:state .
?r a geo:river .
?r geo:inState ?s .
?r a geo:city . }
ORDER BY ?c DESC LIMIT 1In the ﬁrst case, 11b, the sortal restriction adds a
redundant condition and will have no effect. We can
say that the sortal restriction is satisﬁed. In the sec-
ond case, in 11c, however, the sortal restriction adds
a condition that is inconsistent with the other condi-
tions, assuming that the classes river andcity are
properly speciﬁed as disjoint. The query will there-
fore not yield any results, as no instantiiation of r
can be found that belongs to both classes. That is,
in the context of rivers only the interpretation using
flowsThrough leads to results.
Actually, the sortal restriction in 11c is al-
ready implicitly speciﬁed in the ontological relation
inState : there is no river that is related to a state
with this property. However, this is not necessar-
ily the case and there are indeed queries where the
sortal restriction has to be included explicitly. One
example is the interpretation of the adjective major
in noun phrases like major city andmajor state . Al-
though with respect to the geographical domain ma-
joralways expresses the property of having a pop-
ulation greater than a certain threshold, this thresh-
old differs for cities and states: major with respect
to cities is interpreted as having a population greater
than, say, 150 000, while major with respect to states
is interpreted as having a population greater than,
say, 10 000 000. Treating major as ambiguous be-
tween those two readings without specifying a sortal
restriction would lead to two readings for the noun
phrase major city , sketched in 12. Both would yield
non-empty results and there is no way to tell which
one is the correct one.
12. (a) SELECT ?c WHERE {
?c a geo:city .
?c geo:population ?p .
FILTER ( ?p > 150000 ) }
(b)SELECT ?c WHERE {
?c a geo:city .
?c geo:population ?p .
FILTER ( ?p > 10000000 ) }
Specifying sortal restrictions, on the other hand,
would add the boxed material in 13, thereby caus-
ing the wrong reading in 13b to return no results.
13. (a) SELECT ?c WHERE {
?c a geo:city .
?c geo:population ?p .
FILTER ( ?p > 150000 ) .
?c a geo:city . }
(b)SELECT ?c WHERE {
?c a geo:city .
?c geo:population ?p .
FILTER ( ?p > 10000000 ) .
?c a geo:state . }
The enumeration strategy thus relies on a conﬂict
that results in queries which return no result. Un-
wanted interpretations are thereby ﬁltered out auto-
matically. But two problems arise here. The ﬁrst
one is that we have no way to distinguish between
queries that return no result due to an inconsistency
introduced by a sortal restriction, and queries that
return no result, because there is none, as in the case
ofWhich states border Hawaii? . The second prob-
lem concerns the number of readings that are con-
structed. In view of the large number of ambiguities,
even in the restricted geographical domain we used,
user questions easily lead to 20 or 30 different pos-
sible interpretations. In cases in which several natu-
ral language terms can be mapped to many different
ontological concepts, this number rises. Enumerat-
ing all alternative interpretations is therefore not ef-
ﬁcient. A more practical alternative is to construct
one underspeciﬁed representation instead and then
infer a speciﬁc interpretation in a given context. We
will explore this strategy in the next section.
4.3 Underspeciﬁcation
In the following, we will explore a strategy for rep-
resenting and resolving ambiguities that uses under-
speciﬁcation and ontological reasoning in order to
keep the number of constructed interpretations to a
minimum. For a general overview of underspeciﬁca-
tion formalisms and their applicability to linguistic
phenomena see (Bunt, 2007).
In order not to construct a different query for
every interpretation, we do not any longer specify
separate lexical entries for each mapping but rather
combine them by using an underspeciﬁed semantic
representation. In the case of has, for example, we
do not specify two lexical entries – one with a se-
mantic representation using flowsThrough and one
entry with a representation using inState – but in-
stead specify only one lexical entry with a represen-
tation using a metavariable, and additionally specifywhich properties this metavariable stands for under
which conditions.
So ﬁrst we extend DUDEs such that they now can
contain metavariables, and instead of a list of sor-
tal restrictions contain a list of metavariable speci-
ﬁcations , i.e. possible instantiations of a metavari-
able given that certain sortal restrictions are satis-
ﬁed, where sortal restrictions can concern any of the
property’s arguments. Metavariable speciﬁcations
take the following general form:
P ! p1(x=class 1; : : : ; y =class 2)
jp2(x=class 3; : : : ; y =class 4)
j: : :
jpn(x=class i; : : : ; y =class j)
This expresses that some metavariable Pstands for
a property p1if the types of the arguments x; : : : ; y
are equal to or a subset of class 1,. . . ,class 2, and
stands for some other property if the types of the
arguments correspond to some other classes. For
example, as interpretation of has, we would chose
a metavariable Pwith a speciﬁcation stating that P
stands for the property flowsThrough if the ﬁrst ar-
gument belongs to class river , and stands for the
property inState if the ﬁrst argument belongs to
the class city . Thus, the lexical entry for haswould
contain the following underspeciﬁed semantic repre-
sentation.
14.Lexical meaning of ‘has’:
P(y; x)
(DP1; x);(DP2; y)
P ! geo:flowsThrough (y=geo:river )
jgeo:inState (y=geo:city )
Now this underspeciﬁed semantic representation has
to be speciﬁed in order to lead to a SPARQL query
that can be evaluated w.r.t. the knowledge base.
That means, in the course of interpretation we need
to determine which class an instantiation of ybe-
longs to and accordingly substitute Pby the prop-
ertyflowsThrough orinState . In the following
section, we sketch a way of exploiting the ontology
to this end.
4.4 Reducing alternatives with ontological
reasoning
In order to ﬁlter out interpretations that are inconsis-
tent as early as possible and thereby reduce the num-
ber of interpretations during the course of a deriva-
tion, we check whether the type information of a
variable that is uniﬁed is consistent with the sor-
tal restrictions connected to the metavariables. This
check is performed at every relevant step in a deriva-
tion, so that inconsistent readings are not allowed to
percolate and multiply. Let us demonstrate this strat-
egy by means of the example Which state has the
biggest city? .
In order to build the noun phrase the biggest
city, the meaning representation of the superlative
biggest , given in 15, is combined with that of the
noun city, which simply contributes the predication
geo:city (y), by means of uniﬁcation.
15.
z
Q(y; z)
(N; y)
Q ! geo:area (y=geo:city tgeo:state )
jgeo:population (y=geo:city tgeo:state )
The exact details of combining meaning represen-
tations do not matter here. What we want to fo-
cus on is the metavariable Qthatbiggest introduces.
When combining 15 with the meaning of city, we
can check whether the type information connected
to the uniﬁed referent yis compatible with the do-
main restrictions of Q0sinterpretations. One way
to do this is by integrating an OWL reasoner and
checking the satisﬁability of
geo:city u(geo:city tgeo:state )
(for both interpretations of Q, as the restrictions on
yare the same). Since this is indeed satisﬁable,
both interpretations are possible, thus cannot be dis-
carded, and the resulting meaning representation of
the biggest city is the following:y z
geo:city (y)
Q(y; z)
max(z)
Q ! geo:area (y=geo:city tgeo:state )
jgeo:population (y=geo:city tgeo:state )
This is desired, as the ambiguity of biggest is a lexi-
cal ambiguity that could only be resolved by the user
specifying which reading s/he intended.
In a next step, the above representation is com-
bined with the semantic representation of the verb
has, given in 14. Now the type information of the
uniﬁed variable yhas to be checked for compati-
bility with instantiations of an additional metavari-
able,P. The OWL reasoner would therefore have to
check the satisﬁability of the following two expres-
sions:
16. (a) geo:city ugeo:river
(b)geo:city ugeo:city
While 16b succeeds trivially, 16a fails, assuming
that the two classes geo:river andgeo:city are
speciﬁed as disjoint in the ontology. Therefore
the instantiation of Pasgeo:flowsThrough is
not consistent and can be discarded, leading to the
following combined meaning representation, where
Pis replaced by its only remaining instantiation
geo:inState :
y z
geo:city (y)
geo:inState (y; x)
Q(y; z)
(DP1; x)
Q ! geo:area (y=geo:city tgeo:state )
jgeo:population (y=geo:city tgeo:state )
Finally, this meaning representation is com-
bined with the meaning representation of which
state , which simply contributes the predication
geo:state (x). As the uniﬁed variable xdoes not
occur in any metavariable speciﬁcation, nothing fur-
ther needs to be checked. The ﬁnal meaning repre-
sentation thus leaves one metavariable with two pos-
sible instantiations and will lead to the following two
corresponding SPARQL queries:
17. (a) SELECT ?x WHERE {
?x a geo:city .
?y a geo:state.
?x geo:population ?z .
?x geo:inState ?y . }
ORDER BY DESC(?z) LIMIT 1
(b)SELECT ?x WHERE {
?x a geo:city .
?y a geo:state.
?x geo:area ?z .
?x geo:inState ?y . }
ORDER BY DESC(?z) LIMIT 1
Note that if the ambiguity of the metavariable
Pwere not resolved, we would have ended up
with four SPARQL queries, where two of them use
the relation geo:flowsThrough and therefore yield
empty results. So in this case, we reduced the num-
ber of constructed queries by half by discarding in-
consistent readings. We therefore solved the prob-
lems mentioned at the end of 4.2: The number of
constructed queries is reduced, and since we discard
inconsistent readings, null answers can only be due
to the lack of data in the knowledge base but not can-
not anymore be due to inconsistencies in the gener-
ated queries.
5 Implementation and results
In order to see that the possibility of reducing the
number of interpretations during a derivation does
not only exist in a small number of cases, we ap-
plied Pythia to Mooney’s 880 user questions, imple-
menting the underspeciﬁcation strategy in 4.3 and
the reduction strategy in 4.4. Since Pythia does not
yet integrate a reasoner, it approximates satisﬁabil-
ity checks by means of SPARQL queries. When-
ever meaning representations are combined, it ag-
gregates type information for the uniﬁed variable,
together with selectional information connected to
the occuring metavariables, and uses both to con-
struct a SPARQL query. This query is then evalu-
ated against the underlying knowledge base. If the
query returns results, the interpetations are taken to
be compatible, if it does not return results, the in-
terpretations are taken to be incompatible and the
according instantiation possibility of the metavari-
able is discarded. Note that those SPARQL queries
are only an approximation for the OWL expressionsused in 4.4. Furthermore, the results they return are
only an approximation of satisﬁability, as the reason
for not returning results does not necessarily need to
be unsatisﬁability of the construction but could also
be due the absence of data in the knowledge base.
In order to overcome these shortcomings, we plan to
integrate a full-ﬂedged OWL reasoner in the future.
Out of the 880 user questions, 624 can be parsed
by Pythia (for an evaluation on this dataset and rea-
sons for failing with the remaining 256 questions,
see (Unger & Cimiano, 2011)). Implementing the
enumeration strategy, i.e. not using disambiguation
mechanisms, there was a total of 3180 constructed
queries. With a mechanism for removing scope am-
biguities by means of simulating a linear scope pref-
erence, a total of 2936 queries was built. Addi-
tionally using the underspeciﬁcation and resolution
strategies described in the previous section, by ex-
ploiting the ontology with respect to which natural
language expressions are interpreted in order to dis-
card inconsistent interpretations as early as possible
in the course of a derivation, the number of total
queries was further reduced to 2100. This amounts
to a reduction of the overall number of queries by
44 %. The average and maximum number of queries
per question are summarized in the following table.
Avg. # queries Max. # queries
Enumeration 5.1 96
Linear scope 4.7 (-8%) 46 (-52%)
Reasoning 3.4 (-44%) 24 (-75%)
6 Conclusion
We investigated ambiguities arising from mis-
matches between a natural language expressions’
lexical meaning and its conceptual modelling in an
ontology. Employing ontological reasoning for dis-
ambiguation allowed us to signiﬁcantly reduce the
number of constructed interpretations: the average
number of constructed queries per question can be
reduced by 44 %, the maximum number of queries
per question can be reduced even by 75 %.
References
Bunt, H.: Semantic Underspeciﬁcation: Which Tech-
nique For What Purpose? In: Computing Meaning,
vol. 83, pp. 55–85. Springer Netherlands (2007)
Cimiano, P.: Flexible semantic composition with
DUDES. In: Proceedings of the 8th International Con-
ference on Computational Semantics (IWCS). Tilburg
(2009)
Unger, C., Hieber, F., Cimiano, P.: Generating LTAG
grammars from a lexicon-ontology interface. In: S.
Bangalore, R. Frank, and M. Romero (eds.): 10th In-
ternational Workshop on Tree Adjoining Grammars
and Related Formalisms (TAG+10), Yale University
(2010)
Unger, C., Cimiano, P.: Pythia: Compositional mean-
ing construction for ontology-based question answer-
ing on the Semantic Web. In: Proceedings of the 16th
International Conference on Applications of Natural
Language to Information Systems (NLDB) (2011)
Schabes, Y .: Mathematical and Computational Aspects
of Lexicalized Grammars. Ph. D. thesis, University of
Pennsylvania (1990)
Reyle, U.: Dealing with ambiguities by underspeciﬁca-
tion: Construction, representation and deduction. Jour-
nal of Semantics 10, 123–179 (1993)
Kamp, H., Reyle, U.: From Discourse to Logic. Kluwer,
Dordrecht (1993)
Cimiano, P., Minock, M.: Natural Language Interfaces:
What’s the Problem? – A Data-driven Quantitative
Analysis. In: Proceedings of the International Confer-
ence on Applications of Natural Language to Informa-
tion Systems (NLDB), pp. 192–206 (2009)
Damljanovic, D., Agatonovic, M., Cunningham, H.:
Natural Language Interfaces to Ontologies: Combin-
ing Syntactic Analysis and Ontology-based Lookup
through the User Interaction. In: Proceedings of the
7th Extended Semantic Web Conference, Springer
Verlag (2010)
Zettlemoyer, L., Collins, M.: Learning Context-
dependent Mappings from Sentences to Logical Form.
In: Proceedings of the Joint Conference of the As-
sociation for Computational Linguistics and Interna-
tional Joint Conference on Natural Language Process-
ing (ACL-IJCNLP), pp. 976–984 (2009)
Burger, J., Cardie, C., Chaudhri, V ., Gaizauskas,
R., Israel, D., Jacquemin, C., Lin, C.-Y ., Maio-
rano, S., Miller, G., Moldovan, D., Ogden,
B., Prager, J., Riloff, E., Singhal, A., Shrihari,
R., Strzalkowski, T., V oorhees, E., Weischedel,
R.: Issues, tasks, and program structures to
roadmap research in question & answering (Q & A).
http://www-nlpir.nist.gov/projects/duc/
papers/qa.Roadmap-paper v2.doc (2001)Kate, R., Mooney, R.: Learning Language Semantics
from Ambiguous Supervision. In: Proceedings of the
22nd Conference on Artiﬁcial Intelligence (AAAI-07),
pp. 895–900 (2007)
